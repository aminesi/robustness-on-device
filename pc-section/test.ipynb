{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: PYDEVD_USE_CYTHON environment variable is set to 'NO'. Frame evaluator will be also disabled because it requires Cython extensions to be enabled in order to operate correctly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         1281000     global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 3,538,984\n",
      "Trainable params: 3,504,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-2d774f58a02f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mconverter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTFLiteConverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_keras_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizations\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOptimize\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDEFAULT\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mquant\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    827\u001B[0m         \u001B[0mInvalid\u001B[0m \u001B[0mquantization\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    828\u001B[0m     \"\"\"\n\u001B[0;32m--> 829\u001B[0;31m     \u001B[0msaved_model_convert_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_convert_as_saved_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    830\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0msaved_model_convert_result\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    831\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0msaved_model_convert_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/lite/python/lite.py\u001B[0m in \u001B[0;36m_convert_as_saved_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    780\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    781\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 782\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_keras_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_format\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tf\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    783\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    784\u001B[0m         \u001B[0;31m# When storing the given keras model to a saved model is failed, let's\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m   1999\u001B[0m     \"\"\"\n\u001B[1;32m   2000\u001B[0m     \u001B[0;31m# pylint: enable=line-too-long\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2001\u001B[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001B[0m\u001B[1;32m   2002\u001B[0m                     signatures, options, save_traces)\n\u001B[1;32m   2003\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001B[0m in \u001B[0;36msave_model\u001B[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m    154\u001B[0m         model, filepath, overwrite, include_optimizer)\n\u001B[1;32m    155\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 156\u001B[0;31m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001B[0m\u001B[1;32m    157\u001B[0m                           signatures, options, save_traces)\n\u001B[1;32m    158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001B[0m\n\u001B[1;32m     87\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mdistribution_strategy_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_default_replica_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras_option_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msave_traces\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m         \u001B[0msave_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilepath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minclude_optimizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(obj, export_dir, signatures, options)\u001B[0m\n\u001B[1;32m   1030\u001B[0m   \u001B[0mmeta_graph_def\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msaved_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmeta_graphs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1031\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1032\u001B[0;31m   _, exported_graph, object_saver, asset_info = _build_meta_graph(\n\u001B[0m\u001B[1;32m   1033\u001B[0m       obj, signatures, options, meta_graph_def)\n\u001B[1;32m   1034\u001B[0m   \u001B[0msaved_model\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msaved_model_schema_version\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconstants\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSAVED_MODEL_SCHEMA_VERSION\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001B[0m in \u001B[0;36m_build_meta_graph\u001B[0;34m(obj, signatures, options, meta_graph_def)\u001B[0m\n\u001B[1;32m   1196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1197\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0msave_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1198\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_build_meta_graph_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignatures\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeta_graph_def\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001B[0m in \u001B[0;36m_build_meta_graph_impl\u001B[0;34m(obj, signatures, options, meta_graph_def)\u001B[0m\n\u001B[1;32m   1145\u001B[0m   \u001B[0;31m# Note we run this twice since, while constructing the view the first time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m   \u001B[0;31m# there can be side effects of creating variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m   \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_SaveableView\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcheckpoint_graph_view\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m   saveable_view = _SaveableView(checkpoint_graph_view, options,\n\u001B[1;32m   1149\u001B[0m                                 wrapped_functions)\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, checkpoint_view, options, wrapped_functions)\u001B[0m\n\u001B[1;32m    223\u001B[0m           \u001B[0;31m#  variables on first run.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m           concrete_functions = (\n\u001B[0;32m--> 225\u001B[0;31m               function._list_all_concrete_functions_for_serialization())  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m    226\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m           \u001B[0mconcrete_functions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_list_all_concrete_functions_for_serialization\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m     \u001B[0mconcrete_functions\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1180\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mseen_signatures\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1181\u001B[0;31m       \u001B[0mconcrete_functions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1182\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mconcrete_functions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1183\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001B[0m in \u001B[0;36mget_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    547\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    548\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_collection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtracing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 549\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_collection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_trace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    550\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mLayerCall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001B[0m in \u001B[0;36madd_trace\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    420\u001B[0m         \u001B[0mtrace_with_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 421\u001B[0;31m         \u001B[0mtrace_with_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    422\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m         \u001B[0mfn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001B[0m in \u001B[0;36mtrace_with_training\u001B[0;34m(value, fn)\u001B[0m\n\u001B[1;32m    416\u001B[0m           \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_training_arg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_training_arg_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m           \u001B[0;32mwith\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeprecated_internal_learning_phase_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 418\u001B[0;31m             \u001B[0mfn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    420\u001B[0m         \u001B[0mtrace_with_training\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001B[0m in \u001B[0;36mget_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_collection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtracing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    549\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall_collection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_trace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mLayerCall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mget_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1297\u001B[0m       \u001B[0mValueError\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthis\u001B[0m \u001B[0mobject\u001B[0m \u001B[0mhas\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0myet\u001B[0m \u001B[0mbeen\u001B[0m \u001B[0mcalled\u001B[0m \u001B[0mon\u001B[0m \u001B[0mconcrete\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m     \"\"\"\n\u001B[0;32m-> 1299\u001B[0;31m     \u001B[0mconcrete\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_concrete_function_garbage_collected\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1300\u001B[0m     \u001B[0mconcrete\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_garbage_collector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelease\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1301\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mconcrete\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1214\u001B[0m       \u001B[0;31m# In this case we have not created variables on the first call. So we can\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1215\u001B[0m       \u001B[0;31m# run the first trace but we should fail if variables are created.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1216\u001B[0;31m       concrete = self._stateful_fn._get_concrete_function_garbage_collected(  # pylint: disable=protected-access\n\u001B[0m\u001B[1;32m   1217\u001B[0m           *args, **kwargs)\n\u001B[1;32m   1218\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_created_variables\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   3017\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3018\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3019\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3020\u001B[0m       \u001B[0mseen_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3021\u001B[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3359\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3360\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3361\u001B[0;31m           \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3362\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3363\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3194\u001B[0m     \u001B[0marg_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbase_arg_names\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mmissing_arg_names\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3195\u001B[0m     graph_function = ConcreteFunction(\n\u001B[0;32m-> 3196\u001B[0;31m         func_graph_module.func_graph_from_py_func(\n\u001B[0m\u001B[1;32m   3197\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3198\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_python_function\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 990\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    992\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    632\u001B[0m             \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 634\u001B[0;31m           \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    635\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    636\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    525\u001B[0m       with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m    526\u001B[0m           layer._compute_dtype_object):  # pylint: disable=protected-access\n\u001B[0;32m--> 527\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    528\u001B[0m     \u001B[0m_restore_layer_losses\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal_losses\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py\u001B[0m in \u001B[0;36mwrap_with_training_arg\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    155\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrap_with_training_arg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m     \u001B[0;34m\"\"\"Wrap the `wrapped_call` function, and set training argument.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m     \u001B[0mtraining_arg_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_training_arg_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moriginal_call\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m     \u001B[0mtraining\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_training_arg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_arg_index\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtraining\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py\u001B[0m in \u001B[0;36mget_training_arg_index\u001B[0;34m(call_fn)\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;34m-\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mlayer\u001B[0m \u001B[0mdoesn\u001B[0m\u001B[0;31m'\u001B[0m\u001B[0mt\u001B[0m \u001B[0mexpect\u001B[0m \u001B[0ma\u001B[0m \u001B[0mtraining\u001B[0m \u001B[0margument\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m   \"\"\"\n\u001B[0;32m--> 215\u001B[0;31m   \u001B[0marg_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_inspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetfullargspec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    216\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mtf_inspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0marg_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marg_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/ase/venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_inspect.py\u001B[0m in \u001B[0;36mgetfullargspec\u001B[0;34m(obj)\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecorator_argspec\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_convert_maybe_argspec_to_fullargspec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecorator_argspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0m_getfullargspec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.8/inspect.py\u001B[0m in \u001B[0;36mgetfullargspec\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m   1145\u001B[0m         \u001B[0mannotations\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'return'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturn_annotation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mparam\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m         \u001B[0mkind\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkind\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m         \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparam\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "\n",
    "model = mobilenet_v2.MobileNetV2(weights='image_net/weights/tf/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5')\n",
    "model.summary()\n",
    "#\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quant = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "3.7457733154296875"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quant)/2**20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'name': 'input_1',\n  'index': 0,\n  'shape': array([  1, 224, 224,   3], dtype=int32),\n  'shape_signature': array([ -1, 224, 224,   3], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_pad/Pad/paddings',\n  'index': 1,\n  'shape': array([4, 2], dtype=int32),\n  'shape_signature': array([4, 2], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/global_average_pooling2d/Mean/reduction_indices',\n  'index': 2,\n  'shape': array([2], dtype=int32),\n  'shape_signature': array([2], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/predictions/BiasAdd/ReadVariableOp/resource',\n  'index': 3,\n  'shape': array([1000], dtype=int32),\n  'shape_signature': array([1000], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3',\n  'index': 4,\n  'shape': array([1280], dtype=int32),\n  'shape_signature': array([1280], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3',\n  'index': 5,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_expand_BN/FusedBatchNormV3',\n  'index': 6,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3',\n  'index': 7,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_expand_BN/FusedBatchNormV3',\n  'index': 8,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_depthwise_BN/FusedBatchNormV3',\n  'index': 9,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_expand_BN/FusedBatchNormV3',\n  'index': 10,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3',\n  'index': 11,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_expand_BN/FusedBatchNormV3',\n  'index': 12,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3',\n  'index': 13,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_expand_BN/FusedBatchNormV3',\n  'index': 14,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_depthwise_BN/FusedBatchNormV3',\n  'index': 15,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_expand_BN/FusedBatchNormV3',\n  'index': 16,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3',\n  'index': 17,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_expand_BN/FusedBatchNormV3',\n  'index': 18,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3',\n  'index': 19,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3',\n  'index': 20,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3',\n  'index': 21,\n  'shape': array([144], dtype=int32),\n  'shape_signature': array([144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3',\n  'index': 22,\n  'shape': array([144], dtype=int32),\n  'shape_signature': array([144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3',\n  'index': 23,\n  'shape': array([144], dtype=int32),\n  'shape_signature': array([144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3',\n  'index': 24,\n  'shape': array([144], dtype=int32),\n  'shape_signature': array([144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3',\n  'index': 25,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3',\n  'index': 26,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_depthwise_BN/FusedBatchNormV3',\n  'index': 27,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3',\n  'index': 28,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3',\n  'index': 29,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3',\n  'index': 30,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_depthwise_BN/FusedBatchNormV3',\n  'index': 31,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_expand_BN/FusedBatchNormV3',\n  'index': 32,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_depthwise_BN/FusedBatchNormV3',\n  'index': 33,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_expand_BN/FusedBatchNormV3',\n  'index': 34,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_depthwise_BN/FusedBatchNormV3',\n  'index': 35,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_expand_BN/FusedBatchNormV3',\n  'index': 36,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3',\n  'index': 37,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/expanded_conv_depthwise_BN/FusedBatchNormV3',\n  'index': 38,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/predictions/MatMul',\n  'index': 39,\n  'shape': array([1000, 1280], dtype=int32),\n  'shape_signature': array([1000, 1280], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0018739686347544193, 0),\n  'quantization_parameters': {'scales': array([0.00187397], dtype=float32),\n   'zero_points': array([0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/Conv1/Conv2D',\n  'index': 40,\n  'shape': array([32,  3,  3,  3], dtype=int32),\n  'shape_signature': array([32,  3,  3,  3], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/expanded_conv_project/Conv2D',\n  'index': 41,\n  'shape': array([16,  1,  1, 32], dtype=int32),\n  'shape_signature': array([16,  1,  1, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_expand/Conv2D',\n  'index': 42,\n  'shape': array([96,  1,  1, 16], dtype=int32),\n  'shape_signature': array([96,  1,  1, 16], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00100364, 0.00192509, 0.00106218, 0.0019315 , 0.00177578,\n          0.000258  , 0.00127793, 0.00062879, 0.00057707, 0.00110085,\n          0.00086761, 0.00059673, 0.00214091, 0.00060251, 0.00035413,\n          0.00140353, 0.00053981, 0.00031921, 0.0021318 , 0.00498837,\n          0.00083709, 0.00093763, 0.00697045, 0.00255832, 0.00050557,\n          0.00039987, 0.00082533, 0.00037447, 0.00060723, 0.0096146 ,\n          0.00090518, 0.00107778, 0.00420072, 0.00068694, 0.00111013,\n          0.00159861, 0.00350275, 0.00077035, 0.00662943, 0.00436285,\n          0.00489299, 0.00360021, 0.00063656, 0.00051344, 0.00024331,\n          0.00206576, 0.00073004, 0.00386916, 0.00080862, 0.00180953,\n          0.00095831, 0.00132692, 0.00086369, 0.0004884 , 0.00066771,\n          0.0005361 , 0.0008718 , 0.00401825, 0.00316501, 0.00225741,\n          0.00207489, 0.00271339, 0.0033958 , 0.00151391, 0.00109651,\n          0.00064622, 0.00057783, 0.00483071, 0.00147156, 0.00099421,\n          0.00527372, 0.00074662, 0.00034539, 0.00030476, 0.00316998,\n          0.00045074, 0.00084142, 0.00103683, 0.00053435, 0.00975601,\n          0.00102402, 0.00062164, 0.00741872, 0.00713357, 0.00160977,\n          0.00527548, 0.00336585, 0.00503343, 0.00031707, 0.00057694,\n          0.00059299, 0.00309381, 0.00348811, 0.00056374, 0.00654544,\n          0.00028714], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_project/Conv2D',\n  'index': 43,\n  'shape': array([24,  1,  1, 96], dtype=int32),\n  'shape_signature': array([24,  1,  1, 96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01043679, 0.01270814, 0.01480798, 0.0120533 , 0.00926374,\n          0.00847496, 0.01162226, 0.01106209, 0.01269781, 0.01082082,\n          0.02123817, 0.01324021, 0.01234719, 0.01715817, 0.02827104,\n          0.01030951, 0.01565128, 0.01459634, 0.01260941, 0.01881279,\n          0.02081138, 0.01535638, 0.00881729, 0.01269114], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_expand/Conv2D',\n  'index': 44,\n  'shape': array([144,   1,   1,  24], dtype=int32),\n  'shape_signature': array([144,   1,   1,  24], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([9.8359701e-04, 1.5687125e-03, 8.1802742e-04, 1.1475569e-03,\n          1.6486101e-03, 6.1262271e-04, 1.6591552e-03, 1.6307939e-03,\n          2.1351078e-03, 1.3711356e-03, 1.2775538e-03, 1.8120897e-03,\n          7.3035836e-04, 1.6403445e-03, 5.5176939e-04, 3.0393052e-04,\n          2.1281170e-03, 1.0398820e-03, 8.6884870e-04, 1.6766860e-03,\n          5.3100003e-04, 1.5550399e-03, 6.6469761e-04, 8.1286160e-04,\n          1.7993719e-03, 9.2009566e-04, 1.9160461e-03, 1.1712541e-03,\n          1.0815079e-03, 2.5342025e-03, 8.0619397e-04, 7.0553372e-04,\n          1.7324885e-03, 2.8463879e-03, 7.9348555e-04, 8.5353339e-04,\n          2.5124468e-03, 3.2415797e-03, 2.2889993e-03, 6.7820959e-04,\n          1.1459531e-04, 2.1039301e-03, 1.8238471e-03, 2.8282841e-04,\n          1.1750519e-03, 5.8588065e-04, 1.2373441e-03, 1.5006284e-03,\n          1.0640506e-03, 5.6873774e-04, 1.1602170e-03, 8.6403481e-04,\n          8.5828063e-04, 4.2744130e-03, 9.0692751e-04, 1.5894161e-03,\n          1.7314596e-03, 1.7918635e-03, 1.0534583e-03, 1.0488097e-03,\n          1.2350189e-03, 1.4774264e-03, 7.6332834e-04, 1.2848850e-03,\n          1.4890716e-03, 5.2118761e-04, 1.1708145e-03, 1.0673244e-03,\n          1.1512191e-03, 1.7227277e-03, 4.8384271e-04, 1.1769658e-03,\n          7.4657163e-04, 2.4894865e-03, 2.0814354e-03, 2.2070928e-04,\n          1.1933843e-03, 4.9802463e-04, 2.6494544e-04, 1.4272247e-03,\n          1.7930962e-03, 1.2759282e-03, 1.1747422e-03, 1.4921173e-03,\n          2.2337204e-03, 1.0391703e-03, 6.7932694e-04, 1.4619950e-03,\n          8.7844714e-04, 8.0665626e-04, 7.3825620e-04, 1.4217544e-03,\n          1.1203792e-03, 1.5677268e-03, 1.1182270e-03, 9.9506846e-04,\n          4.5845367e-04, 1.3915373e-03, 5.2630395e-04, 1.1400197e-03,\n          1.5913498e-03, 8.9787389e-04, 1.4790320e-03, 1.0986914e-03,\n          1.7898935e-03, 1.4643578e-03, 1.0585784e-03, 4.2977440e-04,\n          1.1189604e-03, 2.2037670e-03, 4.5885274e-04, 2.9316924e-03,\n          1.0243692e-03, 1.5763472e-03, 6.6171278e-04, 6.3681079e-04,\n          1.2091007e-03, 6.9512200e-04, 1.0821177e-03, 2.5190522e-03,\n          1.1307428e-03, 1.1794518e-03, 2.1801570e-03, 1.6658739e-03,\n          4.4954589e-04, 1.5193818e-03, 5.9730734e-04, 1.2690752e-03,\n          8.9118141e-04, 8.8258705e-04, 1.7820964e-19, 2.0750209e-03,\n          1.1974225e-03, 2.4715089e-04, 9.4936590e-04, 1.5021475e-03,\n          1.0261273e-03, 2.7180745e-03, 7.6672650e-04, 5.6011556e-04,\n          1.8967580e-03, 1.4377926e-03, 1.4789096e-03, 1.8876283e-03],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_project/Conv2D',\n  'index': 45,\n  'shape': array([ 24,   1,   1, 144], dtype=int32),\n  'shape_signature': array([ 24,   1,   1, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01284328, 0.00680885, 0.01876943, 0.00640288, 0.02607209,\n          0.02824995, 0.013698  , 0.01110379, 0.01982305, 0.02843312,\n          0.00508783, 0.00723663, 0.02149443, 0.00894355, 0.0062442 ,\n          0.02388029, 0.01026907, 0.02355889, 0.00778538, 0.01081664,\n          0.01382643, 0.00759939, 0.01748506, 0.01198277], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_expand/Conv2D',\n  'index': 46,\n  'shape': array([144,   1,   1,  24], dtype=int32),\n  'shape_signature': array([144,   1,   1,  24], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00083919, 0.00117475, 0.0013973 , 0.00132543, 0.00164676,\n          0.00075777, 0.00190089, 0.00108726, 0.00197538, 0.00347768,\n          0.00184474, 0.0010568 , 0.00154975, 0.00102981, 0.00053341,\n          0.00031303, 0.00089195, 0.00054971, 0.00094622, 0.00025055,\n          0.00098273, 0.00052045, 0.0006419 , 0.00057523, 0.00237534,\n          0.00032286, 0.00070013, 0.0018193 , 0.00118828, 0.00019641,\n          0.00130274, 0.00171013, 0.0005797 , 0.00105335, 0.00189914,\n          0.00058703, 0.00059264, 0.00292944, 0.00097203, 0.00076031,\n          0.0007202 , 0.00035649, 0.00091029, 0.00165026, 0.00105869,\n          0.00075675, 0.00148102, 0.00079594, 0.00168063, 0.00046938,\n          0.00249826, 0.00241192, 0.00107775, 0.00090977, 0.00026002,\n          0.00090332, 0.0007735 , 0.00111434, 0.00084242, 0.00082054,\n          0.00059789, 0.00147087, 0.00126752, 0.0008801 , 0.00072023,\n          0.00170501, 0.00085187, 0.00220269, 0.00226663, 0.00118816,\n          0.00100507, 0.0008435 , 0.00066013, 0.00107718, 0.00037452,\n          0.00096964, 0.0013256 , 0.00081616, 0.00077965, 0.00081651,\n          0.00204564, 0.00051033, 0.00194959, 0.00042737, 0.00090996,\n          0.00073117, 0.00150722, 0.00242744, 0.00057819, 0.00038166,\n          0.00085388, 0.00098738, 0.00202921, 0.00055552, 0.001266  ,\n          0.00229195, 0.0014702 , 0.0017802 , 0.00052065, 0.00083201,\n          0.00148805, 0.00089215, 0.00104856, 0.00035625, 0.00257946,\n          0.00083683, 0.00080704, 0.00117149, 0.00076686, 0.00034372,\n          0.00076805, 0.00056806, 0.00036554, 0.00171359, 0.00015521,\n          0.00111338, 0.00029468, 0.00054998, 0.00022943, 0.00055422,\n          0.00188729, 0.00133975, 0.00198379, 0.00163809, 0.00059859,\n          0.00047139, 0.00105802, 0.00235108, 0.00030591, 0.00097424,\n          0.00242588, 0.00054187, 0.00015809, 0.00131842, 0.00160621,\n          0.00146453, 0.0021734 , 0.0007739 , 0.00079977, 0.0015685 ,\n          0.00068022, 0.00067393, 0.00090803, 0.00091651], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_project/Conv2D',\n  'index': 47,\n  'shape': array([ 32,   1,   1, 144], dtype=int32),\n  'shape_signature': array([ 32,   1,   1, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01367412, 0.01492903, 0.00985135, 0.00988087, 0.01077025,\n          0.01160533, 0.01236563, 0.01198763, 0.01478999, 0.00729143,\n          0.01329236, 0.00941197, 0.01071243, 0.00893054, 0.00903736,\n          0.01265648, 0.00678416, 0.00784617, 0.00897945, 0.00934668,\n          0.01023498, 0.01912935, 0.01232614, 0.01058751, 0.01004776,\n          0.00919926, 0.01277648, 0.0108194 , 0.00694626, 0.0095484 ,\n          0.01286396, 0.01728297], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_expand/Conv2D',\n  'index': 48,\n  'shape': array([192,   1,   1,  32], dtype=int32),\n  'shape_signature': array([192,   1,   1,  32], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.0007927 , 0.00036446, 0.00080538, 0.00071017, 0.00059249,\n          0.00044122, 0.00053981, 0.00052042, 0.00100216, 0.00046827,\n          0.00185711, 0.00073529, 0.00088326, 0.00107314, 0.00103526,\n          0.00065508, 0.00051871, 0.0017944 , 0.00072462, 0.00030282,\n          0.00188809, 0.00042037, 0.0004163 , 0.00069427, 0.00019278,\n          0.00059287, 0.00028542, 0.00071723, 0.00017665, 0.00049045,\n          0.00035169, 0.00056218, 0.00103056, 0.00110079, 0.00074429,\n          0.00124046, 0.00105895, 0.00076083, 0.00061287, 0.00059426,\n          0.00025717, 0.00079392, 0.00054633, 0.00056613, 0.00035832,\n          0.00058064, 0.00027705, 0.00073947, 0.00076806, 0.00068728,\n          0.0008793 , 0.00026562, 0.00076132, 0.00075038, 0.00081919,\n          0.00041568, 0.00098635, 0.00117129, 0.00071602, 0.00096973,\n          0.00064861, 0.0006842 , 0.00123953, 0.00052839, 0.00096702,\n          0.00045692, 0.00070668, 0.00112881, 0.00037741, 0.00056095,\n          0.00180094, 0.00052289, 0.0012877 , 0.00063075, 0.00075125,\n          0.00049409, 0.00107342, 0.00066808, 0.00075925, 0.00073092,\n          0.00035931, 0.00172755, 0.00063346, 0.00085203, 0.00123318,\n          0.00059033, 0.00057694, 0.00045182, 0.00048771, 0.00031437,\n          0.00024395, 0.00035111, 0.00086333, 0.00072865, 0.00137197,\n          0.00050434, 0.00091694, 0.00066442, 0.00063436, 0.00082981,\n          0.00034752, 0.0009049 , 0.00086732, 0.0018455 , 0.00068635,\n          0.00079238, 0.00062696, 0.00087386, 0.00074415, 0.0004837 ,\n          0.00052004, 0.00070277, 0.00157381, 0.00096305, 0.00080096,\n          0.00084626, 0.00024991, 0.00091012, 0.00043305, 0.00123076,\n          0.00089298, 0.00111789, 0.00050772, 0.00122862, 0.00034945,\n          0.00053221, 0.0009236 , 0.0003979 , 0.00061605, 0.00062284,\n          0.0005482 , 0.00035053, 0.00052471, 0.00103777, 0.00016946,\n          0.00038178, 0.00038627, 0.00082534, 0.00033481, 0.00037094,\n          0.00039112, 0.00050856, 0.00124627, 0.00073489, 0.00040609,\n          0.0005207 , 0.00047706, 0.00061539, 0.00050742, 0.00067826,\n          0.00059212, 0.00083452, 0.00040634, 0.00083836, 0.0004446 ,\n          0.00089314, 0.00066242, 0.00049755, 0.00158748, 0.00088533,\n          0.00032315, 0.00096977, 0.00069992, 0.00030774, 0.00047305,\n          0.00147253, 0.0007752 , 0.00077185, 0.00049715, 0.00135244,\n          0.0007096 , 0.00072607, 0.00050128, 0.00077262, 0.00057644,\n          0.00040967, 0.00053922, 0.00052866, 0.00052167, 0.00105373,\n          0.00022632, 0.0010023 , 0.00073364, 0.0009781 , 0.00109152,\n          0.00098978, 0.00046615, 0.00136784, 0.00047922, 0.00056136,\n          0.00043378, 0.00054273], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_project/Conv2D',\n  'index': 49,\n  'shape': array([ 32,   1,   1, 192], dtype=int32),\n  'shape_signature': array([ 32,   1,   1, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01009813, 0.00875302, 0.00549079, 0.00735443, 0.01774597,\n          0.00666149, 0.00943547, 0.00494622, 0.00778989, 0.01574745,\n          0.00679379, 0.00753597, 0.00822386, 0.00570065, 0.0037911 ,\n          0.00913309, 0.00568719, 0.02172978, 0.0048086 , 0.01363544,\n          0.00623042, 0.00464253, 0.00547272, 0.00703198, 0.00557213,\n          0.00559523, 0.00533979, 0.00681608, 0.01287952, 0.00717561,\n          0.0037314 , 0.00887256], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_expand/Conv2D',\n  'index': 50,\n  'shape': array([192,   1,   1,  32], dtype=int32),\n  'shape_signature': array([192,   1,   1,  32], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([9.4751938e-04, 4.0874930e-04, 5.4945197e-04, 5.8701483e-04,\n          1.8128651e-04, 9.3045522e-04, 2.8674226e-04, 4.2944556e-04,\n          6.3851586e-04, 5.6305219e-04, 1.0139381e-03, 9.3100942e-04,\n          9.2853972e-04, 7.2177727e-04, 7.6142006e-04, 6.5563607e-04,\n          9.3993306e-04, 1.0114718e-03, 3.4702371e-04, 2.7057491e-04,\n          8.7289349e-04, 1.2482454e-03, 7.6520891e-04, 5.6638464e-04,\n          6.9374603e-04, 3.2668293e-04, 5.0131342e-04, 5.1947718e-04,\n          1.1765986e-03, 4.9591239e-04, 3.0362196e-04, 7.5438374e-04,\n          8.5046986e-04, 6.8981940e-04, 6.1968586e-04, 7.8681979e-04,\n          2.2016501e-04, 5.9136498e-04, 7.8921398e-04, 5.2509870e-04,\n          6.9653400e-04, 8.9746737e-04, 5.4734829e-04, 6.4693787e-04,\n          1.5064898e-03, 6.8016525e-04, 5.8041909e-04, 3.3486277e-04,\n          5.3335051e-04, 4.6898038e-04, 4.9068307e-04, 3.2696989e-04,\n          1.1470377e-03, 1.0123146e-03, 5.9844076e-04, 3.1930715e-04,\n          3.6516305e-04, 9.4808632e-04, 4.4591975e-04, 4.3937730e-04,\n          7.4269046e-04, 2.3743387e-04, 6.2519644e-04, 7.1499433e-04,\n          1.2903168e-03, 8.3853689e-04, 4.8863637e-04, 2.3420736e-04,\n          5.3790456e-04, 4.6910578e-04, 3.0057665e-04, 4.6998158e-04,\n          3.3465444e-04, 6.1665045e-04, 4.2889500e-04, 8.4978569e-04,\n          4.7749979e-04, 8.1209006e-04, 9.7571913e-04, 7.0192263e-04,\n          5.7376764e-04, 1.0181577e-03, 6.8049598e-04, 8.4835821e-04,\n          1.1333427e-03, 6.0461537e-04, 6.4204872e-04, 8.7578804e-04,\n          9.8105404e-04, 7.0774643e-04, 5.8420637e-04, 4.6185250e-04,\n          2.2183674e-04, 6.7875831e-04, 4.5368745e-04, 4.7686920e-04,\n          9.9520083e-04, 9.3090488e-04, 5.6148041e-04, 1.2965624e-03,\n          7.6366891e-04, 1.1909700e-03, 8.5415592e-04, 8.5601083e-04,\n          7.4658729e-04, 1.1098691e-03, 6.7962130e-04, 4.0365270e-04,\n          8.3208934e-04, 4.0828349e-04, 2.6153951e-04, 2.4053147e-04,\n          5.1805383e-04, 1.3947418e-03, 6.9097889e-04, 1.3541017e-03,\n          4.7844899e-04, 6.7113998e-04, 8.2690595e-04, 6.3126691e-04,\n          1.0823500e-03, 8.5417047e-04, 6.9430406e-04, 8.5934164e-04,\n          1.0070397e-03, 4.6081821e-04, 2.1540791e-04, 5.3224800e-04,\n          3.5219261e-04, 4.5057124e-04, 6.2166335e-04, 8.4621710e-04,\n          1.1080907e-03, 7.6368178e-04, 5.6994963e-04, 3.4040201e-04,\n          8.4317109e-04, 8.3687098e-04, 1.1550462e-03, 4.2137460e-04,\n          4.2871881e-04, 6.1285862e-04, 5.5752852e-04, 3.6937153e-04,\n          1.0321330e-03, 2.2727123e-04, 4.7159102e-04, 4.2347939e-04,\n          1.9384688e-04, 4.8797231e-04, 3.4898170e-04, 1.1823787e-03,\n          8.2614372e-04, 4.3606490e-04, 5.5248651e-04, 3.9676315e-04,\n          8.7684504e-04, 6.9166039e-04, 3.3297483e-04, 7.6910242e-04,\n          4.7436362e-04, 7.8425219e-04, 4.9857056e-04, 1.4471493e-04,\n          8.3861838e-04, 3.6750335e-04, 6.2381884e-04, 7.8185229e-04,\n          7.7050366e-04, 7.1416544e-05, 3.3873317e-04, 8.1974192e-04,\n          7.0335885e-04, 3.1142717e-04, 3.9345276e-04, 4.3553597e-04,\n          1.2529193e-03, 2.2813379e-04, 5.6269317e-04, 4.8201988e-04,\n          7.6787453e-04, 9.3348813e-04, 5.9416296e-04, 3.6570668e-04,\n          3.1191632e-04, 3.7904846e-04, 8.2544575e-04, 2.9469791e-04,\n          8.5526065e-04, 5.6924130e-04, 4.7148421e-04, 7.4459799e-04],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_project/Conv2D',\n  'index': 51,\n  'shape': array([ 32,   1,   1, 192], dtype=int32),\n  'shape_signature': array([ 32,   1,   1, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.0084929 , 0.00328423, 0.00940927, 0.0135053 , 0.00932015,\n          0.00413504, 0.00558106, 0.00414433, 0.00581853, 0.01190232,\n          0.00580845, 0.00708401, 0.00458475, 0.00527979, 0.00369842,\n          0.00706626, 0.00521597, 0.010488  , 0.00634339, 0.01442998,\n          0.00542744, 0.00386939, 0.00498541, 0.00442014, 0.00673932,\n          0.00640561, 0.00487849, 0.00531215, 0.01889828, 0.00525763,\n          0.00294758, 0.00645202], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_expand/Conv2D',\n  'index': 52,\n  'shape': array([192,   1,   1,  32], dtype=int32),\n  'shape_signature': array([192,   1,   1,  32], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00058403, 0.00031836, 0.00084934, 0.00049646, 0.00056251,\n          0.00037994, 0.00067986, 0.0007038 , 0.00068687, 0.00130414,\n          0.00073174, 0.00035905, 0.00055118, 0.00090253, 0.00188309,\n          0.00075715, 0.00092123, 0.00086339, 0.00088333, 0.00081331,\n          0.00119116, 0.0005375 , 0.00059039, 0.00056771, 0.0007621 ,\n          0.00125533, 0.0008301 , 0.00087727, 0.00161938, 0.00088092,\n          0.00105502, 0.0008822 , 0.0009244 , 0.00076092, 0.00081021,\n          0.00074934, 0.00045034, 0.00061748, 0.00128984, 0.00032648,\n          0.00081583, 0.00106216, 0.00071223, 0.00058574, 0.00091297,\n          0.0010433 , 0.00036205, 0.00052167, 0.00082863, 0.00103795,\n          0.00039661, 0.00068213, 0.00085336, 0.00076017, 0.00040163,\n          0.00102242, 0.00098742, 0.00089534, 0.00078827, 0.00063237,\n          0.00072359, 0.00070746, 0.00037764, 0.00055899, 0.00095771,\n          0.00070184, 0.00085027, 0.00088413, 0.00076958, 0.00060962,\n          0.00166886, 0.00032293, 0.00055704, 0.00104954, 0.00067777,\n          0.00104412, 0.00051668, 0.00079225, 0.0006421 , 0.00101001,\n          0.0002186 , 0.00070987, 0.00087454, 0.00059583, 0.00085669,\n          0.00061914, 0.0013448 , 0.00091567, 0.00092703, 0.00101396,\n          0.00151874, 0.0006608 , 0.00065475, 0.00065638, 0.00082277,\n          0.0013953 , 0.00112518, 0.00084629, 0.00091558, 0.00136016,\n          0.00056313, 0.00083881, 0.00095037, 0.00115599, 0.0010258 ,\n          0.00086743, 0.00073956, 0.00142875, 0.00073718, 0.00060788,\n          0.00068432, 0.00084262, 0.00057321, 0.00053637, 0.00134234,\n          0.00119865, 0.00054386, 0.00074889, 0.00081167, 0.00083321,\n          0.00108293, 0.00093156, 0.00077967, 0.00094356, 0.00063752,\n          0.00052017, 0.00101366, 0.0008314 , 0.0007423 , 0.00064951,\n          0.00102015, 0.00054215, 0.00024961, 0.0009955 , 0.00077953,\n          0.00109518, 0.00092183, 0.00105336, 0.0004671 , 0.00075702,\n          0.00063317, 0.00192724, 0.00076866, 0.0011181 , 0.00073133,\n          0.0008727 , 0.00051456, 0.00071174, 0.00053291, 0.00103368,\n          0.00108718, 0.00090263, 0.00044919, 0.00160426, 0.00022678,\n          0.00055607, 0.00079496, 0.00043049, 0.00086599, 0.00083349,\n          0.0006924 , 0.00087376, 0.00161353, 0.00052087, 0.00086664,\n          0.00091953, 0.00081608, 0.00094614, 0.00055064, 0.00051424,\n          0.00124204, 0.00073196, 0.00045928, 0.00069936, 0.00162407,\n          0.00019326, 0.0008305 , 0.00055213, 0.00043049, 0.00064901,\n          0.0009654 , 0.00086011, 0.00049157, 0.00080895, 0.00049179,\n          0.00086919, 0.00061352, 0.0003988 , 0.00085657, 0.00091711,\n          0.00111427, 0.00181225], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_project/Conv2D',\n  'index': 53,\n  'shape': array([ 64,   1,   1, 192], dtype=int32),\n  'shape_signature': array([ 64,   1,   1, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00728777, 0.0113963 , 0.00787854, 0.00705073, 0.00754391,\n          0.01290473, 0.00706266, 0.00874566, 0.00994877, 0.00835097,\n          0.00925747, 0.00694529, 0.00929   , 0.0060562 , 0.00573402,\n          0.0077548 , 0.00720186, 0.00652422, 0.00716789, 0.00286335,\n          0.01083688, 0.00852631, 0.00811872, 0.00817316, 0.01189397,\n          0.00740789, 0.00682419, 0.01186769, 0.00683173, 0.00638776,\n          0.00377334, 0.00626473, 0.007419  , 0.01199605, 0.00677625,\n          0.00681698, 0.01126769, 0.00766378, 0.00772187, 0.00770281,\n          0.0078893 , 0.00267068, 0.00697996, 0.00744692, 0.00743867,\n          0.01023951, 0.00835522, 0.00815826, 0.00698869, 0.00952673,\n          0.00525178, 0.00922487, 0.00600397, 0.00522063, 0.01616041,\n          0.00756861, 0.00518554, 0.00676571, 0.00659419, 0.00758137,\n          0.0098305 , 0.00479762, 0.00726272, 0.00599663], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_expand/Conv2D',\n  'index': 54,\n  'shape': array([384,   1,   1,  64], dtype=int32),\n  'shape_signature': array([384,   1,   1,  64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([7.6411857e-04, 9.7808253e-04, 6.1720866e-04, 7.2133960e-04,\n          3.7334507e-04, 9.7774272e-04, 8.1011263e-04, 4.1183224e-04,\n          7.4834534e-04, 5.2272377e-04, 8.5374597e-04, 1.0002817e-03,\n          9.0114260e-04, 5.3839321e-04, 1.6324437e-04, 5.3706218e-04,\n          6.6135020e-04, 7.7621720e-04, 8.0281770e-04, 7.2626420e-04,\n          1.3870600e-03, 1.5916373e-03, 3.3377809e-04, 2.1165611e-04,\n          6.6249183e-04, 5.7871372e-04, 4.7496174e-04, 7.7871978e-04,\n          4.1340294e-04, 4.5532387e-04, 5.4286729e-04, 7.8438938e-04,\n          7.7641488e-04, 5.7862728e-04, 4.2163947e-04, 4.4672753e-04,\n          7.0114824e-04, 8.0351013e-04, 6.0834020e-04, 7.1738765e-04,\n          6.7746959e-04, 8.0009532e-04, 8.2253123e-04, 8.0763211e-04,\n          8.4999908e-04, 6.9199526e-04, 1.8156061e-04, 7.2521355e-04,\n          7.0021901e-04, 5.1618367e-04, 4.9813453e-04, 3.2093440e-04,\n          6.0377602e-04, 2.7150198e-04, 8.4013608e-04, 3.5692935e-04,\n          7.2676415e-04, 6.2262197e-04, 6.2850321e-04, 8.0497476e-04,\n          8.9500716e-04, 5.6163000e-04, 5.1010645e-04, 6.9505570e-04,\n          6.2596379e-04, 2.4644641e-04, 3.5192975e-04, 2.9351009e-04,\n          5.5029144e-04, 6.0136238e-04, 3.4062820e-04, 5.7737890e-04,\n          1.5174781e-04, 5.1264081e-04, 4.3346258e-04, 7.6334819e-04,\n          8.0403645e-04, 5.6517182e-04, 7.5743970e-04, 4.0415212e-04,\n          2.6321039e-04, 6.5627857e-04, 7.5386069e-04, 6.5601227e-04,\n          7.8388437e-04, 8.0530101e-04, 8.6236146e-04, 2.2239132e-04,\n          5.7514239e-04, 5.9025967e-04, 6.9763663e-04, 7.2040281e-04,\n          1.1428873e-03, 1.2751756e-03, 7.7118742e-04, 2.7737839e-04,\n          7.0047402e-04, 6.8238896e-04, 3.3078698e-04, 4.5143097e-04,\n          2.4818783e-04, 5.0334097e-04, 3.7871089e-04, 6.0840615e-04,\n          7.8776880e-04, 6.1430543e-04, 5.7950616e-04, 3.4939544e-04,\n          6.1050354e-04, 5.7724514e-04, 4.2589405e-04, 3.4560281e-04,\n          7.2593061e-04, 3.9791019e-04, 5.4269406e-04, 3.1862524e-04,\n          8.3277549e-04, 9.5254707e-04, 5.4501655e-04, 2.7550623e-04,\n          9.4123289e-04, 8.3761051e-04, 3.4198852e-04, 3.6888343e-04,\n          8.5081358e-04, 5.4911146e-04, 6.1758811e-04, 3.8341249e-04,\n          6.9169782e-04, 4.5087980e-04, 5.0458161e-04, 4.0507084e-04,\n          8.4026367e-04, 5.3878955e-04, 6.0499413e-04, 8.6535740e-04,\n          5.2383775e-04, 2.5141795e-04, 6.3570199e-04, 5.9788715e-04,\n          9.2982961e-04, 8.2798424e-04, 4.1928803e-04, 4.4204746e-04,\n          7.7169365e-04, 4.3018610e-04, 4.0181770e-04, 5.6892668e-04,\n          4.2510877e-04, 1.0435992e-03, 6.9930189e-04, 4.1959694e-04,\n          7.9585210e-04, 3.4175487e-04, 4.2848146e-04, 2.3376374e-04,\n          4.5616552e-04, 4.7271646e-04, 3.8223719e-04, 3.3155849e-04,\n          5.8069278e-04, 4.4483741e-04, 2.6129573e-04, 6.5031170e-04,\n          4.4741697e-04, 3.1171576e-04, 5.0401961e-04, 8.2289724e-04,\n          6.4874836e-04, 4.8015994e-04, 6.4168242e-04, 2.4481484e-04,\n          9.6252235e-04, 8.5535867e-04, 3.9143572e-04, 1.1007421e-03,\n          3.6656379e-04, 6.2863494e-04, 4.0734938e-04, 5.0691341e-04,\n          2.6883953e-04, 5.0824264e-04, 8.5091859e-04, 3.5373322e-04,\n          3.9027852e-04, 8.8388770e-04, 8.2513504e-04, 1.1628633e-03,\n          3.7361518e-04, 2.1347305e-04, 4.0849662e-04, 3.7404074e-04,\n          1.2300512e-03, 3.1240901e-04, 9.4614719e-04, 7.1697502e-04,\n          5.1144627e-04, 3.5289224e-04, 6.3741306e-04, 6.0655514e-04,\n          8.3870662e-04, 6.5726595e-04, 1.2367346e-03, 3.4656448e-04,\n          5.4666906e-04, 4.6152394e-04, 5.2849180e-04, 6.2305818e-04,\n          4.0402726e-04, 4.3811917e-04, 6.8902748e-04, 3.4731711e-04,\n          5.6998158e-04, 6.3580071e-04, 9.0451160e-04, 1.0554092e-03,\n          1.1483618e-04, 9.0482039e-04, 5.3766172e-04, 6.0032931e-04,\n          1.9970028e-04, 1.2885566e-03, 3.6755475e-04, 6.5741781e-04,\n          6.7302922e-04, 5.6967133e-04, 3.5597046e-04, 5.4241240e-04,\n          4.5930440e-04, 1.7537699e-04, 6.5916660e-04, 8.7848626e-04,\n          5.4175121e-04, 6.3216436e-04, 8.1474381e-04, 3.5025983e-04,\n          5.6201784e-04, 4.4478712e-04, 7.6809002e-04, 3.2405523e-04,\n          4.1902016e-04, 1.0000066e-03, 4.9995916e-04, 6.5154448e-04,\n          3.3701948e-04, 8.3276088e-04, 7.9796725e-04, 1.1994635e-03,\n          5.4030446e-04, 5.8242818e-04, 3.4874416e-04, 7.2696334e-04,\n          7.3153753e-04, 8.0014073e-04, 5.6174182e-04, 8.7417917e-05,\n          1.5845152e-03, 7.1966194e-04, 7.4879918e-04, 7.0559664e-04,\n          5.1136321e-04, 5.3862401e-04, 6.5368245e-04, 5.7060336e-04,\n          7.8624266e-04, 5.0061039e-04, 5.7219289e-04, 6.1441318e-04,\n          4.7385602e-04, 5.7161291e-04, 6.7908608e-04, 3.4427969e-04,\n          9.5219549e-04, 8.0253679e-04, 5.2779249e-04, 7.6416112e-04,\n          5.4118875e-04, 5.4417667e-04, 5.2229542e-04, 2.8965506e-04,\n          9.3995885e-04, 4.4370172e-04, 3.3059338e-04, 2.9451057e-04,\n          6.3701207e-04, 6.7745254e-04, 3.5714981e-04, 6.7303918e-04,\n          5.0841027e-04, 2.0682317e-04, 5.1465264e-04, 6.1352405e-04,\n          5.4435217e-04, 5.9877621e-04, 1.2216705e-03, 5.9588905e-04,\n          1.0590705e-03, 8.9912786e-04, 8.7569526e-04, 3.0881233e-04,\n          3.8142025e-04, 5.9336430e-04, 3.9031019e-04, 5.4872927e-04,\n          7.2397332e-04, 9.8131539e-04, 3.3882304e-04, 3.0885031e-04,\n          5.1056565e-04, 3.7479002e-04, 9.2576357e-04, 6.6387025e-04,\n          7.2821905e-04, 9.4702531e-04, 6.1956624e-04, 4.8953138e-04,\n          9.0141041e-04, 4.9983553e-04, 4.8432045e-04, 7.2297297e-04,\n          8.0417190e-04, 4.1428264e-04, 3.0820019e-04, 3.8850502e-04,\n          6.9462060e-04, 5.3723907e-04, 3.4906567e-04, 7.4625685e-04,\n          6.0540182e-04, 5.6362065e-04, 1.8088262e-04, 4.2541817e-04,\n          7.5617246e-04, 9.7925821e-04, 5.5957271e-04, 5.3020375e-04,\n          5.0398964e-04, 3.1897990e-04, 3.3371299e-04, 5.0384563e-04,\n          5.0580548e-04, 7.9461694e-04, 5.3333666e-04, 9.0855540e-04,\n          4.5418667e-04, 3.3114394e-04, 3.4282164e-04, 7.8983209e-04,\n          6.4268417e-04, 5.0250575e-04, 8.5562444e-04, 5.3911563e-04,\n          4.5783987e-04, 4.3954578e-04, 6.3036842e-04, 7.0096779e-04,\n          6.8104779e-04, 2.0886718e-04, 5.2590837e-04, 7.4799190e-04,\n          3.8542631e-04, 3.8710161e-04, 3.4765000e-04, 1.2518346e-03,\n          5.5782951e-04, 4.9775094e-04, 3.7137794e-04, 4.9431459e-04,\n          8.0062856e-04, 1.0988261e-03, 6.3239189e-04, 8.5082254e-04,\n          6.3631154e-04, 7.2148931e-04, 9.2824007e-04, 7.5841439e-04,\n          7.6233398e-04, 9.3268428e-04, 7.4083079e-04, 3.1165496e-04,\n          4.1568576e-04, 7.6439272e-04, 7.5756345e-04, 3.4526232e-04],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_project/Conv2D',\n  'index': 55,\n  'shape': array([ 64,   1,   1, 384], dtype=int32),\n  'shape_signature': array([ 64,   1,   1, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00343115, 0.00419969, 0.0020569 , 0.00249744, 0.00312509,\n          0.00173717, 0.00602043, 0.00237975, 0.00447212, 0.00336515,\n          0.00500207, 0.00555352, 0.00249308, 0.00422978, 0.00846796,\n          0.00696543, 0.00229871, 0.00318082, 0.00582678, 0.01687335,\n          0.00347675, 0.00281658, 0.00406047, 0.00301539, 0.00274503,\n          0.00656393, 0.00449298, 0.00447519, 0.00527911, 0.00312521,\n          0.0178817 , 0.00608305, 0.00326715, 0.00216381, 0.00424813,\n          0.01231685, 0.00182343, 0.00404598, 0.00213781, 0.00805082,\n          0.00454187, 0.01789785, 0.00249856, 0.00362874, 0.00321476,\n          0.00446045, 0.00342558, 0.00196872, 0.00921736, 0.00276731,\n          0.01043785, 0.00250274, 0.00228564, 0.00965059, 0.00219954,\n          0.0064782 , 0.00706795, 0.00456043, 0.0032099 , 0.00151355,\n          0.0033532 , 0.00612037, 0.00235668, 0.00629335], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_expand/Conv2D',\n  'index': 56,\n  'shape': array([384,   1,   1,  64], dtype=int32),\n  'shape_signature': array([384,   1,   1,  64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([5.1123311e-04, 3.7047212e-04, 8.1616681e-04, 6.2551041e-04,\n          2.4945437e-04, 4.4096092e-04, 7.0438086e-04, 1.3103801e-03,\n          6.1818032e-04, 5.7610869e-04, 5.0079520e-04, 7.3002529e-04,\n          3.2381710e-04, 4.5977964e-04, 9.3784981e-04, 7.5031194e-04,\n          2.7574503e-04, 5.3620216e-04, 6.2346668e-04, 7.4273860e-04,\n          7.6420786e-04, 8.0036180e-04, 7.0765847e-04, 8.4174308e-04,\n          5.6159648e-04, 5.1265513e-04, 5.2847300e-04, 6.9776562e-04,\n          4.0319096e-04, 6.4663892e-04, 8.0593844e-04, 4.4896363e-04,\n          9.6448080e-04, 3.8938649e-04, 3.9405754e-04, 1.1276907e-03,\n          7.2820735e-04, 5.3813646e-04, 7.3319994e-04, 5.4003485e-04,\n          6.0464256e-04, 9.8277477e-04, 3.7482704e-04, 6.4352120e-04,\n          4.9241749e-04, 6.7105598e-04, 7.0712029e-04, 8.0080336e-04,\n          5.7207013e-04, 5.4326019e-04, 5.5646134e-04, 2.5090927e-04,\n          2.7826402e-04, 5.9926132e-04, 6.8460969e-04, 6.0626835e-04,\n          2.1132018e-04, 4.6879819e-04, 5.3557486e-04, 5.5916159e-04,\n          4.0804371e-04, 8.1720215e-04, 2.6398740e-04, 5.2023208e-04,\n          1.0988837e-03, 5.4899527e-04, 4.9645372e-04, 4.5591657e-04,\n          4.0608359e-04, 2.5993906e-04, 4.6710405e-04, 2.1456573e-04,\n          4.2805940e-04, 6.0438644e-04, 5.2748329e-04, 9.8771800e-04,\n          3.2723162e-04, 1.0580773e-03, 7.4721233e-04, 7.6318404e-04,\n          4.7418420e-04, 5.6853791e-04, 4.5864398e-04, 3.8222602e-04,\n          3.3819707e-04, 5.3962169e-04, 1.1257166e-03, 3.4199568e-04,\n          2.7248790e-04, 2.8686650e-04, 4.5290333e-04, 6.5927708e-04,\n          1.9663091e-04, 2.4764490e-04, 5.7443010e-04, 7.8035879e-04,\n          1.9995261e-04, 8.3069509e-04, 3.1294901e-04, 5.0045224e-04,\n          4.5458946e-04, 5.1680463e-04, 4.3978661e-04, 4.1223055e-04,\n          8.6171296e-04, 8.6108444e-04, 3.9107297e-04, 7.2609534e-04,\n          3.8722259e-04, 4.9118145e-04, 4.7751056e-04, 8.2660269e-04,\n          8.3026593e-04, 4.9451081e-04, 4.6655443e-04, 5.7603404e-05,\n          3.4154701e-04, 4.8864842e-04, 6.2889990e-04, 5.3056102e-04,\n          4.5635729e-04, 4.5638561e-04, 4.1603140e-04, 4.4781942e-04,\n          3.6942941e-04, 2.0455572e-04, 7.2892581e-04, 8.1136113e-04,\n          3.2484086e-04, 7.6127873e-04, 5.5492052e-04, 4.1103174e-04,\n          3.8315562e-04, 4.3060695e-04, 5.8545684e-04, 6.3780550e-04,\n          3.8234345e-04, 8.4689778e-04, 5.6501193e-04, 5.2053208e-04,\n          4.9556850e-04, 6.5128051e-04, 2.7847773e-04, 5.9855299e-04,\n          3.7191380e-04, 2.5872549e-04, 3.1724540e-04, 5.9281429e-04,\n          2.4229973e-04, 4.3266217e-04, 7.5446803e-04, 3.3733220e-04,\n          1.3271325e-04, 5.6883146e-04, 5.7863822e-04, 8.9997938e-04,\n          8.1756635e-04, 6.0032884e-04, 4.7950860e-04, 5.1564095e-04,\n          1.0830510e-03, 6.8176736e-04, 6.0870108e-04, 1.1765976e-03,\n          7.0689473e-04, 5.5392453e-04, 6.4770057e-04, 8.3526637e-04,\n          8.4036519e-04, 6.2962261e-04, 6.0154550e-04, 2.5289421e-04,\n          7.4724678e-04, 5.2288384e-04, 3.5330583e-04, 5.0591963e-04,\n          3.8742350e-04, 3.4440609e-04, 4.3657448e-04, 9.7553048e-04,\n          5.5778190e-04, 6.8539998e-04, 6.1127206e-04, 3.3492112e-04,\n          2.7490212e-04, 3.0731285e-04, 7.1330147e-04, 4.7729496e-04,\n          5.7615916e-04, 4.6208358e-04, 7.2048896e-04, 4.6491995e-04,\n          1.8409982e-04, 8.5157395e-04, 7.2897872e-04, 9.9421153e-04,\n          3.0169866e-04, 6.9931761e-04, 8.9985359e-04, 6.8666140e-04,\n          3.4957836e-04, 3.3320423e-04, 6.2745967e-04, 8.1683189e-04,\n          6.4012519e-04, 2.7247303e-04, 3.9765521e-04, 1.8451150e-04,\n          5.8843399e-04, 2.9667345e-04, 6.1571517e-04, 6.9484673e-04,\n          8.6056901e-04, 7.2992046e-04, 3.9986710e-04, 7.4325071e-04,\n          4.8606668e-04, 8.6575991e-04, 4.2401670e-04, 4.0602547e-04,\n          5.2411173e-04, 6.8623910e-04, 2.3531723e-04, 5.5543159e-04,\n          5.1609334e-04, 3.2875332e-04, 3.7058751e-04, 5.4706726e-04,\n          2.3244058e-04, 8.4650127e-04, 4.4455644e-04, 3.0227646e-04,\n          3.7931948e-04, 2.8690140e-04, 4.5512701e-04, 2.8884303e-04,\n          5.3740438e-04, 4.7470114e-04, 3.9588913e-04, 7.1869022e-04,\n          2.9386426e-04, 7.3747156e-04, 4.7954597e-04, 6.2445964e-04,\n          3.1822291e-04, 7.6587481e-04, 5.3652108e-04, 1.0300747e-03,\n          6.7871640e-04, 6.7318964e-04, 7.7295670e-04, 2.4027548e-04,\n          7.8023167e-04, 5.0078635e-04, 7.8675011e-04, 8.4920099e-04,\n          5.1777129e-04, 5.1088672e-04, 3.3881862e-04, 4.7402334e-04,\n          5.8710552e-04, 5.9579988e-04, 8.6365466e-04, 6.3165656e-04,\n          5.5703823e-04, 5.4242538e-04, 7.7532080e-04, 3.4807483e-04,\n          8.5974217e-04, 5.2936084e-04, 6.5452582e-04, 4.5216098e-04,\n          5.2221544e-04, 4.5552765e-04, 2.9611803e-04, 9.0799475e-04,\n          6.3849124e-04, 6.8200816e-04, 5.1192282e-04, 3.9744074e-04,\n          7.7387999e-04, 7.8252272e-04, 5.4850045e-04, 1.9858373e-04,\n          6.4797513e-04, 8.8493305e-04, 6.3136319e-04, 8.0891832e-04,\n          3.8522889e-04, 2.2751457e-04, 6.0898351e-04, 6.3213881e-04,\n          1.1354487e-03, 1.5517840e-03, 9.3537127e-04, 4.5606447e-04,\n          5.9421320e-04, 3.2649600e-04, 4.0926030e-04, 5.9995893e-04,\n          3.4463391e-04, 3.2161979e-04, 5.4039090e-04, 3.0535241e-04,\n          4.9792149e-04, 6.2025152e-04, 2.8565727e-04, 2.5725053e-04,\n          5.2920426e-04, 7.6027680e-04, 3.3088677e-04, 7.1335945e-04,\n          6.7005929e-04, 3.1320739e-04, 3.7748640e-04, 7.3630537e-04,\n          2.5703810e-04, 4.6927773e-04, 3.2542876e-04, 3.6834925e-04,\n          6.2866503e-04, 3.6473863e-04, 3.6862594e-04, 9.6764695e-04,\n          6.5425283e-04, 1.8876005e-04, 3.0670976e-04, 2.9234390e-04,\n          3.0252890e-04, 6.9166877e-04, 3.9799741e-04, 1.4273991e-03,\n          6.5742602e-04, 2.9980272e-04, 6.8023184e-04, 5.9850590e-04,\n          5.6832051e-04, 7.5439044e-04, 4.5055881e-04, 2.1698435e-04,\n          6.7522115e-04, 4.7358236e-04, 2.5365554e-04, 6.4078683e-04,\n          4.9611932e-04, 6.6594401e-04, 9.8637852e-04, 3.8206347e-04,\n          7.8210304e-04, 5.0484785e-04, 4.4833584e-04, 1.7256037e-04,\n          3.5235891e-04, 8.6051313e-04, 5.1404722e-04, 3.9470178e-04,\n          5.8193138e-04, 7.0638960e-04, 5.0972821e-04, 7.0916308e-04,\n          7.4356311e-04, 6.3544628e-04, 3.9956247e-04, 4.4610540e-04,\n          6.9865695e-04, 1.7353756e-04, 4.0248586e-04, 3.5307618e-04,\n          8.0586923e-04, 7.8045565e-04, 1.0081430e-03, 6.1720476e-04,\n          2.1431514e-04, 6.9161737e-04, 7.9512270e-04, 1.2139849e-04,\n          6.0297397e-04, 4.7005023e-04, 5.0712249e-04, 3.2072552e-04,\n          5.2117422e-04, 7.1436330e-04, 3.7030654e-04, 4.9849087e-04],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_project/Conv2D',\n  'index': 57,\n  'shape': array([ 64,   1,   1, 384], dtype=int32),\n  'shape_signature': array([ 64,   1,   1, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00250545, 0.00807351, 0.00258696, 0.00324288, 0.00655009,\n          0.00307754, 0.00717668, 0.00279125, 0.00687271, 0.00554836,\n          0.00734307, 0.00585987, 0.00258097, 0.0029523 , 0.01276898,\n          0.00841969, 0.0022332 , 0.00460413, 0.01043109, 0.01159598,\n          0.00481623, 0.00391751, 0.00536108, 0.0022848 , 0.00283116,\n          0.00933096, 0.00764495, 0.00418918, 0.00508491, 0.00516753,\n          0.00765767, 0.00754062, 0.0041979 , 0.00213076, 0.00731371,\n          0.01080668, 0.00206955, 0.00499905, 0.00348084, 0.00961774,\n          0.00551932, 0.01034754, 0.00303945, 0.00403475, 0.00314304,\n          0.00448433, 0.0042105 , 0.00272888, 0.00903772, 0.00269568,\n          0.01240321, 0.00248529, 0.0044391 , 0.01201903, 0.0023366 ,\n          0.00937109, 0.00810156, 0.00376952, 0.00531893, 0.00282323,\n          0.00625873, 0.00971542, 0.00279134, 0.00790666], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_expand/Conv2D',\n  'index': 58,\n  'shape': array([384,   1,   1,  64], dtype=int32),\n  'shape_signature': array([384,   1,   1,  64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00050376, 0.00133215, 0.00051939, 0.00036851, 0.00051706,\n          0.00066522, 0.00049361, 0.00022166, 0.00060434, 0.00093653,\n          0.0006548 , 0.00032106, 0.00067102, 0.00050285, 0.00045163,\n          0.00052262, 0.00021194, 0.00053022, 0.00051682, 0.00063037,\n          0.00079462, 0.00070231, 0.00072047, 0.00020073, 0.00073736,\n          0.00074566, 0.00060872, 0.00030703, 0.00106246, 0.00045592,\n          0.00079946, 0.00052597, 0.00031343, 0.00132701, 0.0003796 ,\n          0.00071321, 0.00069888, 0.00026226, 0.00063069, 0.00029288,\n          0.00018915, 0.00031683, 0.00024862, 0.00047182, 0.00056459,\n          0.00057079, 0.00070537, 0.00058811, 0.00045502, 0.00063617,\n          0.00081563, 0.00104307, 0.00056524, 0.00067032, 0.00061593,\n          0.00046577, 0.00057941, 0.00085876, 0.00021404, 0.00069643,\n          0.00046933, 0.00064061, 0.00046735, 0.00072641, 0.00034289,\n          0.00050346, 0.00050119, 0.00042114, 0.00021382, 0.0005004 ,\n          0.00050028, 0.00067209, 0.00028062, 0.00024321, 0.00064556,\n          0.00049642, 0.00017252, 0.00074423, 0.00045772, 0.00036114,\n          0.00074481, 0.00060214, 0.00064207, 0.00046151, 0.00055975,\n          0.00041414, 0.00055531, 0.00069505, 0.00055785, 0.00067346,\n          0.00059003, 0.00056887, 0.00042509, 0.00059303, 0.00047645,\n          0.0006002 , 0.00034999, 0.00111838, 0.00042899, 0.0003857 ,\n          0.00058277, 0.00035798, 0.00047841, 0.00117191, 0.00069422,\n          0.00039963, 0.00077342, 0.00061872, 0.00054444, 0.00075955,\n          0.00055229, 0.00114778, 0.00024794, 0.000809  , 0.00051968,\n          0.00061275, 0.00084024, 0.00050905, 0.0003772 , 0.00060611,\n          0.00061294, 0.0007938 , 0.00037272, 0.00031478, 0.00042401,\n          0.00018459, 0.00054703, 0.00043055, 0.00051691, 0.00076137,\n          0.00076481, 0.00049437, 0.00027951, 0.00043555, 0.0004126 ,\n          0.00052466, 0.00045469, 0.00048573, 0.00066281, 0.00070581,\n          0.00072978, 0.00070944, 0.00100613, 0.00016127, 0.00024434,\n          0.00056568, 0.00060343, 0.00052086, 0.00039722, 0.0005656 ,\n          0.0004464 , 0.00051752, 0.00051867, 0.00067071, 0.00082495,\n          0.00053264, 0.00056026, 0.00029753, 0.00045432, 0.00059457,\n          0.00030328, 0.00063748, 0.00054322, 0.00013014, 0.00044641,\n          0.00025302, 0.0003367 , 0.00081356, 0.00055408, 0.00067203,\n          0.00060261, 0.00039452, 0.00105289, 0.00029957, 0.00048352,\n          0.00062497, 0.00048439, 0.00068934, 0.00058135, 0.00065015,\n          0.00060688, 0.00073583, 0.00039407, 0.0005077 , 0.00043691,\n          0.00062575, 0.00048955, 0.00084682, 0.00050661, 0.00056718,\n          0.00051941, 0.00027641, 0.00056524, 0.00022519, 0.00062767,\n          0.00064935, 0.00045773, 0.00081056, 0.00046352, 0.00031666,\n          0.00050461, 0.00052979, 0.00053722, 0.00050654, 0.00064466,\n          0.00058713, 0.00055641, 0.00060986, 0.00104444, 0.00026379,\n          0.00024873, 0.00048916, 0.0003252 , 0.0002989 , 0.0005924 ,\n          0.00064511, 0.00039189, 0.00049376, 0.00060638, 0.00021291,\n          0.00052763, 0.00016404, 0.0005248 , 0.00035834, 0.00056505,\n          0.00037935, 0.0005281 , 0.00063998, 0.00061012, 0.00042483,\n          0.00048261, 0.00030499, 0.0002155 , 0.00129862, 0.00019655,\n          0.00050174, 0.00044557, 0.00090293, 0.0004579 , 0.00073363,\n          0.00080605, 0.00037507, 0.00083834, 0.00063079, 0.00051748,\n          0.00020652, 0.00057471, 0.00073464, 0.00049671, 0.00097196,\n          0.00072279, 0.00047619, 0.00036384, 0.00031778, 0.00044845,\n          0.00045553, 0.00062174, 0.00048765, 0.00068746, 0.00022111,\n          0.00085002, 0.00037377, 0.00064429, 0.00078969, 0.00049725,\n          0.00061225, 0.00046725, 0.0003527 , 0.00048092, 0.00028069,\n          0.0005621 , 0.00046291, 0.00073038, 0.00015343, 0.00057626,\n          0.0005621 , 0.00027122, 0.00079406, 0.00096227, 0.00036544,\n          0.0006769 , 0.00051679, 0.00035088, 0.00068685, 0.00075804,\n          0.00067804, 0.0008879 , 0.00058124, 0.00033618, 0.00034726,\n          0.00074144, 0.00032331, 0.00064272, 0.00066719, 0.00053054,\n          0.00057476, 0.00078821, 0.00050973, 0.00079347, 0.00070361,\n          0.00023632, 0.00047191, 0.00101182, 0.00050877, 0.00070301,\n          0.00054528, 0.00045876, 0.0003603 , 0.00089276, 0.00131973,\n          0.00020363, 0.00043085, 0.00049489, 0.00051323, 0.00050677,\n          0.00054077, 0.00044738, 0.00019052, 0.00054707, 0.00073879,\n          0.00075733, 0.00066271, 0.00038768, 0.00024205, 0.00027818,\n          0.00046743, 0.00066432, 0.00031787, 0.00091451, 0.00055532,\n          0.00017618, 0.00062156, 0.00113918, 0.00054642, 0.00086403,\n          0.00061015, 0.00044425, 0.00046058, 0.00042832, 0.00070483,\n          0.00049203, 0.00023508, 0.00044971, 0.00061359, 0.00064008,\n          0.00060238, 0.00023816, 0.00049284, 0.00051019, 0.00089425,\n          0.00107957, 0.0008236 , 0.00024915, 0.00022065, 0.00072296,\n          0.00042259, 0.00062873, 0.00047289, 0.00098965, 0.00086139,\n          0.00064784, 0.00065159, 0.00036676, 0.00065023, 0.00081109,\n          0.00027582, 0.00051655, 0.00062686, 0.00094017, 0.00044867,\n          0.00105921, 0.00048833, 0.00044943, 0.00028422, 0.00041702,\n          0.00030569, 0.00074666, 0.00037591, 0.00085574, 0.00042677,\n          0.00043682, 0.000841  , 0.00112642, 0.00015609], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_project/Conv2D',\n  'index': 59,\n  'shape': array([ 64,   1,   1, 384], dtype=int32),\n  'shape_signature': array([ 64,   1,   1, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00348319, 0.00729581, 0.00314856, 0.00344054, 0.00482389,\n          0.00484977, 0.00628325, 0.00299587, 0.00721537, 0.00478819,\n          0.00661629, 0.00985638, 0.00421486, 0.00475642, 0.01338061,\n          0.0103243 , 0.00343338, 0.00340113, 0.01055653, 0.01212427,\n          0.00361896, 0.00367026, 0.00477207, 0.00313357, 0.00273928,\n          0.0075482 , 0.01153457, 0.00419204, 0.00520505, 0.00345956,\n          0.00931108, 0.00561789, 0.00397237, 0.00276268, 0.01151519,\n          0.01257413, 0.00350799, 0.00502084, 0.00329123, 0.00667062,\n          0.00664277, 0.00897051, 0.00400261, 0.00367076, 0.00322728,\n          0.00435104, 0.00281581, 0.00289921, 0.01592598, 0.00334759,\n          0.02206887, 0.0039618 , 0.0035986 , 0.0089285 , 0.00244314,\n          0.00823424, 0.00908301, 0.00427879, 0.00792718, 0.00283884,\n          0.00280538, 0.01624379, 0.00240649, 0.00675125], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n         dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_expand/Conv2D',\n  'index': 60,\n  'shape': array([384,   1,   1,  64], dtype=int32),\n  'shape_signature': array([384,   1,   1,  64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00146583, 0.0005469 , 0.00099606, 0.00028695, 0.00084689,\n          0.00093057, 0.0008165 , 0.00076336, 0.00088375, 0.00068127,\n          0.0009261 , 0.00069592, 0.00082371, 0.00056744, 0.00036003,\n          0.00081145, 0.00066535, 0.00071003, 0.00048115, 0.00100687,\n          0.00074542, 0.00071834, 0.00070866, 0.00040078, 0.00071528,\n          0.00093463, 0.00076224, 0.00168068, 0.00063284, 0.0008247 ,\n          0.00042057, 0.00122235, 0.00161759, 0.00081355, 0.00084207,\n          0.00068329, 0.00055898, 0.00059841, 0.00025103, 0.00080075,\n          0.00023132, 0.00126955, 0.00097113, 0.00037671, 0.00046939,\n          0.00055742, 0.00079654, 0.00088859, 0.00086427, 0.00064762,\n          0.00070417, 0.00073769, 0.00057323, 0.0007102 , 0.0007737 ,\n          0.00084227, 0.00017201, 0.00074354, 0.0007782 , 0.00037751,\n          0.00070813, 0.00033415, 0.00103282, 0.00094842, 0.00032195,\n          0.00071156, 0.00024933, 0.00100922, 0.00106008, 0.0005942 ,\n          0.0006038 , 0.00067211, 0.0015704 , 0.00111168, 0.00068584,\n          0.00099277, 0.0006825 , 0.00070828, 0.00061183, 0.00080156,\n          0.00079275, 0.00085985, 0.00081632, 0.00075204, 0.00071426,\n          0.00118401, 0.00093286, 0.00047548, 0.00088807, 0.00059149,\n          0.00087226, 0.00054078, 0.00075308, 0.00017132, 0.00106641,\n          0.00039186, 0.00051586, 0.00064912, 0.00086871, 0.00058416,\n          0.00068946, 0.00066591, 0.00070799, 0.00064665, 0.0009612 ,\n          0.00085782, 0.00034325, 0.0009936 , 0.00030157, 0.00082442,\n          0.00054885, 0.00041316, 0.00079236, 0.00028267, 0.00060579,\n          0.00053726, 0.00042624, 0.00084797, 0.0010285 , 0.00038072,\n          0.00073336, 0.00078029, 0.00055929, 0.00070658, 0.00064203,\n          0.0008779 , 0.000634  , 0.00106904, 0.00046103, 0.00059253,\n          0.00129787, 0.00046079, 0.00073417, 0.00104694, 0.00073342,\n          0.00072318, 0.00098159, 0.00049194, 0.00051482, 0.00049036,\n          0.0007897 , 0.0001917 , 0.00091982, 0.00084652, 0.00046251,\n          0.00057348, 0.00069932, 0.00080037, 0.00031934, 0.00086878,\n          0.00055586, 0.00066658, 0.00106798, 0.00053334, 0.0006582 ,\n          0.0006475 , 0.00038232, 0.00059462, 0.000624  , 0.00032458,\n          0.00026083, 0.00146494, 0.00053918, 0.00066532, 0.00095805,\n          0.00055681, 0.00064325, 0.00074163, 0.00035588, 0.0007328 ,\n          0.00088238, 0.00070236, 0.00057754, 0.00072119, 0.00063732,\n          0.00050686, 0.00050618, 0.00065015, 0.00059497, 0.00064099,\n          0.0009612 , 0.00096342, 0.00085016, 0.00053109, 0.00061408,\n          0.00059308, 0.00071224, 0.00050753, 0.00089639, 0.00104922,\n          0.00092615, 0.00056773, 0.00051351, 0.00039098, 0.00072326,\n          0.00065521, 0.00066267, 0.00048242, 0.00060059, 0.00081172,\n          0.00041385, 0.00092112, 0.00065233, 0.00083684, 0.00089575,\n          0.00045795, 0.00097103, 0.0004319 , 0.00072882, 0.0013015 ,\n          0.00063071, 0.00024223, 0.00082286, 0.00111231, 0.00063858,\n          0.00106896, 0.000647  , 0.00070477, 0.00065727, 0.00076322,\n          0.00066637, 0.00022798, 0.00051599, 0.00045429, 0.00084114,\n          0.00074823, 0.00109688, 0.00101159, 0.00058494, 0.00048515,\n          0.00030257, 0.00070404, 0.00087121, 0.0003751 , 0.0004474 ,\n          0.00124629, 0.00076427, 0.00046585, 0.0005717 , 0.00059501,\n          0.00072063, 0.00063299, 0.00066408, 0.00025062, 0.00057   ,\n          0.00023951, 0.00084808, 0.00082261, 0.00078526, 0.00060193,\n          0.00026747, 0.00062813, 0.00087881, 0.00094246, 0.00067066,\n          0.00086562, 0.00052217, 0.00049157, 0.0008416 , 0.00087374,\n          0.00053189, 0.00056245, 0.00076274, 0.00118361, 0.00067887,\n          0.00054146, 0.00058029, 0.00046747, 0.00105426, 0.00025503,\n          0.00024167, 0.00061321, 0.00058903, 0.00102456, 0.0012528 ,\n          0.00088478, 0.00056847, 0.00085012, 0.00051547, 0.00048791,\n          0.00077281, 0.00078974, 0.00076335, 0.00108229, 0.00050378,\n          0.00123542, 0.0009125 , 0.0003515 , 0.00055331, 0.00068429,\n          0.00050636, 0.00062379, 0.0008496 , 0.00035408, 0.00040078,\n          0.00035969, 0.00056411, 0.00081771, 0.00039847, 0.00082372,\n          0.00093588, 0.00077189, 0.00063935, 0.00085335, 0.00054057,\n          0.00094007, 0.0005615 , 0.00040815, 0.00063674, 0.00099233,\n          0.00084444, 0.00032278, 0.00071473, 0.00090774, 0.00034857,\n          0.00068898, 0.00112892, 0.00066384, 0.00099982, 0.00034736,\n          0.00078367, 0.00145471, 0.00092291, 0.00060926, 0.00059496,\n          0.00035699, 0.00094243, 0.00082924, 0.00069363, 0.00046281,\n          0.00065553, 0.00048729, 0.00103356, 0.00062301, 0.00060764,\n          0.00068036, 0.00058809, 0.00073144, 0.00066755, 0.00088534,\n          0.00105683, 0.00060973, 0.00074726, 0.0010935 , 0.00050866,\n          0.00093525, 0.00084142, 0.00061579, 0.00072625, 0.00069265,\n          0.00032346, 0.00103559, 0.00057753, 0.00075029, 0.00044569,\n          0.00071217, 0.00032034, 0.00114392, 0.00025516, 0.00070328,\n          0.00066275, 0.00020581, 0.00053957, 0.0004664 , 0.00058051,\n          0.00096496, 0.0006618 , 0.00066447, 0.00069172, 0.00046474,\n          0.00084127, 0.00066709, 0.00027027, 0.00123404, 0.00075   ,\n          0.00024787, 0.00059319, 0.00049894, 0.00082333, 0.00080632,\n          0.00063892, 0.00043502, 0.00076856, 0.00058839], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_project/Conv2D',\n  'index': 61,\n  'shape': array([ 96,   1,   1, 384], dtype=int32),\n  'shape_signature': array([ 96,   1,   1, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00420549, 0.00454294, 0.00585678, 0.00415004, 0.00591523,\n          0.00447858, 0.00458025, 0.00392312, 0.00418577, 0.00400773,\n          0.00461156, 0.00526324, 0.00530528, 0.00456136, 0.00420162,\n          0.00453763, 0.00444229, 0.00408465, 0.00411265, 0.00464659,\n          0.00582813, 0.00384195, 0.00651985, 0.00452728, 0.00478409,\n          0.0044024 , 0.0039251 , 0.00483297, 0.00612563, 0.00522118,\n          0.00460351, 0.00547364, 0.00469475, 0.00435079, 0.00492214,\n          0.00471855, 0.00429664, 0.00349928, 0.00456283, 0.00384937,\n          0.00553533, 0.0049276 , 0.00435265, 0.00406632, 0.00474821,\n          0.00476779, 0.00424742, 0.00477394, 0.00431615, 0.0045851 ,\n          0.00454679, 0.00432966, 0.00404276, 0.00503789, 0.00424311,\n          0.00644944, 0.00385993, 0.00356221, 0.00449784, 0.00679945,\n          0.00455575, 0.00503367, 0.00504156, 0.00547679, 0.00568754,\n          0.00508722, 0.00470911, 0.00402972, 0.00460729, 0.00430797,\n          0.00589826, 0.00381037, 0.00406327, 0.00683049, 0.00483581,\n          0.00465743, 0.00409323, 0.00464881, 0.00462641, 0.00461662,\n          0.00371929, 0.004124  , 0.00519344, 0.00722899, 0.00521915,\n          0.00709212, 0.00536417, 0.00389603, 0.00350676, 0.00717627,\n          0.00496362, 0.00464481, 0.00521459, 0.00403868, 0.00444439,\n          0.00403524], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_expand/Conv2D',\n  'index': 62,\n  'shape': array([576,   1,   1,  96], dtype=int32),\n  'shape_signature': array([576,   1,   1,  96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([9.1001915e-04, 7.4939273e-04, 6.6616019e-04, 5.1390065e-04,\n          6.1358861e-04, 5.1044778e-04, 6.6969742e-04, 6.1369012e-04,\n          8.8955124e-04, 4.0739879e-04, 9.7505085e-04, 6.3729985e-04,\n          1.2120531e-03, 7.1347936e-04, 6.5500964e-04, 7.4003369e-04,\n          5.6654582e-04, 1.2743711e-03, 9.2541176e-04, 5.7080964e-04,\n          7.2357361e-04, 3.9412754e-04, 3.9929140e-04, 1.0638258e-03,\n          9.5602701e-04, 6.0546765e-04, 1.1383708e-03, 4.6920078e-04,\n          4.3997940e-04, 6.0998165e-04, 8.2942192e-04, 2.9381600e-04,\n          7.8894314e-04, 6.6373736e-04, 5.3704734e-04, 7.4446591e-04,\n          5.8047578e-04, 7.8189268e-04, 8.4553420e-04, 8.9044718e-04,\n          9.8187476e-04, 1.1253478e-03, 9.7514724e-04, 6.6693127e-04,\n          5.4104713e-04, 1.1267308e-03, 4.5191776e-04, 6.0847419e-04,\n          7.4599963e-04, 7.6937623e-04, 7.0775737e-04, 6.9909700e-04,\n          6.0145481e-04, 7.0878625e-04, 1.0580230e-03, 9.0452010e-04,\n          1.0408025e-03, 1.5867376e-04, 7.4162078e-04, 8.6339179e-04,\n          7.4380956e-04, 8.0591353e-04, 6.2823109e-04, 8.4580586e-04,\n          5.6902284e-04, 7.4425340e-04, 8.0657133e-04, 1.6060612e-03,\n          3.2207023e-04, 8.4140938e-04, 4.2185656e-04, 7.9098629e-04,\n          1.0178414e-03, 4.5796475e-04, 6.0455932e-04, 6.3717231e-04,\n          2.7509234e-04, 1.1010582e-03, 4.5223327e-04, 5.0032261e-04,\n          6.4291834e-04, 5.8591622e-04, 7.7498687e-04, 1.9730713e-04,\n          1.0331299e-03, 6.6221005e-04, 7.2010874e-04, 8.7455154e-04,\n          3.9022518e-04, 8.6194853e-04, 7.7621522e-04, 7.1728142e-04,\n          4.7784444e-04, 3.5594826e-04, 8.2308555e-04, 7.1881770e-04,\n          5.9212977e-04, 8.0367300e-04, 6.3013402e-04, 8.0220605e-04,\n          5.6837429e-04, 9.9261454e-04, 2.8348775e-04, 6.0106796e-04,\n          7.1208412e-04, 8.4409676e-04, 3.8022755e-04, 8.6528138e-04,\n          6.2611373e-04, 3.7438894e-04, 1.1378882e-03, 3.9972187e-04,\n          9.7227859e-04, 8.1292237e-04, 5.0246518e-04, 1.0045514e-03,\n          8.1661751e-04, 6.5382745e-04, 8.8551466e-04, 5.8132684e-04,\n          6.5961806e-04, 9.0288161e-04, 8.7500585e-04, 8.4123382e-04,\n          6.9304410e-04, 7.3043961e-04, 1.0046411e-03, 7.5350964e-04,\n          8.5656252e-04, 6.9988513e-04, 8.6013123e-04, 8.4596837e-04,\n          6.7078177e-04, 3.3661819e-04, 2.1931410e-04, 3.2177841e-04,\n          7.1437581e-04, 8.6353300e-04, 7.6610065e-04, 1.0658099e-03,\n          8.5296918e-04, 9.5658936e-04, 1.2899122e-03, 5.7989563e-04,\n          7.8556052e-04, 6.3063868e-04, 1.0552881e-03, 9.4804249e-04,\n          5.5813231e-04, 1.0949972e-03, 5.5834500e-04, 7.6878158e-04,\n          9.0538425e-04, 5.4773089e-04, 5.8930140e-04, 5.4850045e-04,\n          7.2269613e-04, 7.7602995e-04, 7.2797068e-04, 8.2370092e-04,\n          1.6407496e-03, 8.3016785e-04, 5.7214312e-04, 4.8614401e-04,\n          5.4892100e-04, 5.7647249e-04, 2.4319605e-04, 7.8066008e-04,\n          3.8153998e-04, 5.4621365e-04, 6.4645591e-04, 5.6678051e-04,\n          9.2220318e-04, 8.5834006e-04, 5.4193271e-04, 5.3459732e-04,\n          6.5658643e-04, 4.0566392e-04, 3.5023974e-04, 5.2684196e-04,\n          8.1182213e-04, 2.6475635e-04, 7.0137088e-04, 7.3021458e-04,\n          5.2902137e-04, 6.5421150e-04, 8.1211602e-04, 2.8437050e-04,\n          5.4908858e-04, 6.0432527e-04, 1.1106466e-03, 3.8870965e-04,\n          9.0640550e-04, 6.3111761e-04, 9.2561782e-04, 9.7518443e-04,\n          6.7495444e-04, 7.9503178e-04, 6.4306956e-04, 8.8967313e-04,\n          7.0120487e-04, 3.7590714e-04, 5.9358933e-04, 4.7103257e-04,\n          4.4546498e-04, 6.1054085e-04, 4.8249259e-04, 5.9558620e-04,\n          1.0385485e-03, 7.6365989e-04, 4.1705582e-04, 1.0229792e-03,\n          6.0675509e-04, 8.2234200e-04, 4.4162635e-04, 7.1929814e-04,\n          5.6644320e-04, 2.3125843e-04, 4.3927314e-04, 9.4769441e-04,\n          8.6806819e-04, 3.3569767e-04, 9.5512933e-04, 5.7660218e-04,\n          6.8238546e-04, 2.3157813e-04, 7.0287392e-04, 6.7319145e-04,\n          7.7117136e-04, 1.1940516e-03, 6.0513231e-04, 4.3411361e-04,\n          9.4179698e-04, 8.0640265e-04, 1.0952256e-03, 1.1221431e-03,\n          6.9935876e-04, 6.9040339e-04, 4.7634449e-04, 7.6631841e-04,\n          7.5061125e-04, 1.1347493e-03, 8.7809842e-04, 7.6445454e-04,\n          4.8984919e-04, 1.2004598e-03, 5.3058419e-04, 5.7756511e-04,\n          6.5484748e-04, 4.9057225e-04, 6.6127820e-04, 6.8146380e-04,\n          5.7622959e-04, 8.6940412e-04, 3.9476497e-04, 7.1841187e-04,\n          5.1232200e-04, 5.1278266e-04, 7.3854008e-04, 8.0137234e-12,\n          6.8869279e-04, 6.6699350e-04, 7.0090574e-04, 6.1907416e-04,\n          1.4585245e-03, 7.5067120e-04, 3.9099104e-04, 6.8731711e-04,\n          6.1454560e-04, 5.9339538e-04, 7.7218516e-04, 8.9524861e-04,\n          6.3703454e-04, 3.8353173e-04, 4.9854122e-04, 5.9611339e-04,\n          4.7567789e-04, 4.4687491e-04, 7.0407771e-04, 1.0197221e-03,\n          4.8525026e-04, 1.0295341e-03, 5.5940106e-04, 3.2914252e-04,\n          8.5019704e-04, 8.5276412e-04, 8.9026865e-04, 9.4351050e-04,\n          7.4638752e-04, 4.9784279e-04, 6.1815768e-04, 9.0324046e-04,\n          4.3900346e-04, 1.0105341e-03, 4.5544413e-04, 6.5638032e-04,\n          8.5078523e-04, 8.1228575e-04, 1.1093463e-03, 7.4696413e-04,\n          6.6294044e-04, 7.8129239e-04, 7.6399918e-04, 7.7627134e-04,\n          6.1546365e-04, 1.1296029e-03, 4.1350402e-04, 1.0881446e-03,\n          3.4698230e-04, 8.5869775e-04, 6.6946249e-04, 6.3090667e-04,\n          7.1205775e-04, 6.0190319e-04, 7.7197142e-04, 6.3590944e-04,\n          7.1269739e-04, 6.2462443e-04, 1.0069750e-03, 6.3373282e-04,\n          8.2052662e-04, 8.3422061e-04, 6.4335670e-04, 6.6694757e-04,\n          6.5011892e-04, 1.0745354e-03, 5.6716363e-04, 9.3720743e-04,\n          2.8221586e-04, 1.2919814e-03, 6.7384192e-04, 6.3915545e-04,\n          7.6094782e-04, 7.1461097e-04, 8.0919877e-04, 1.0942408e-03,\n          2.9308654e-04, 7.0395385e-04, 2.5189749e-04, 2.7086475e-04,\n          4.5340974e-04, 1.0045533e-03, 8.3960313e-04, 9.7100582e-04,\n          7.7058526e-04, 3.6453659e-04, 7.9784374e-04, 2.8801765e-04,\n          1.0143471e-03, 7.5542094e-04, 1.1006300e-03, 1.0949092e-03,\n          7.4695767e-04, 7.9692120e-04, 5.5416796e-04, 6.4301695e-04,\n          6.5841130e-04, 6.0799613e-04, 4.5255560e-04, 8.2322257e-04,\n          7.3181791e-04, 6.6347298e-04, 9.1622950e-04, 1.0122545e-03,\n          9.8889251e-04, 5.0524570e-04, 6.5088336e-04, 7.1360968e-04,\n          7.7836501e-04, 9.9062070e-04, 4.1975189e-04, 3.3031043e-04,\n          8.5922307e-04, 9.1482187e-04, 6.2052708e-04, 6.0724939e-04,\n          4.2486729e-04, 7.9418119e-04, 7.6723058e-04, 7.0447993e-04,\n          8.2942378e-04, 8.2395459e-04, 8.6485397e-04, 6.4315775e-04,\n          8.2894339e-04, 9.2229788e-04, 3.2445550e-04, 7.6678704e-04,\n          5.3693075e-04, 4.4538645e-04, 7.3520740e-04, 8.8948297e-04,\n          7.1691774e-04, 5.8744731e-04, 6.1751349e-04, 8.5898815e-04,\n          1.0345697e-03, 6.7386054e-04, 8.5007981e-04, 7.4248429e-04,\n          3.3769890e-04, 1.0540133e-03, 6.4243551e-04, 5.9986248e-04,\n          9.3967980e-04, 9.1105927e-04, 5.1925442e-04, 7.0667249e-04,\n          6.1780389e-04, 8.0839236e-04, 6.9040101e-04, 5.3993601e-04,\n          1.1811017e-03, 7.3074992e-04, 5.3970813e-04, 3.4103380e-04,\n          7.9457898e-04, 7.0613541e-04, 6.3860120e-04, 7.4989244e-04,\n          7.4994401e-04, 4.8138318e-04, 6.7662791e-04, 1.1273354e-03,\n          6.6122471e-04, 8.3055295e-04, 5.2395114e-04, 5.2196998e-04,\n          7.4806338e-04, 4.5599582e-04, 8.2215481e-04, 7.8459841e-04,\n          5.0954631e-04, 4.8799376e-04, 9.2509476e-04, 3.8256688e-04,\n          7.0809765e-04, 5.2585214e-04, 5.7815149e-04, 3.1582851e-04,\n          7.5208279e-04, 6.9198391e-04, 7.8593544e-04, 6.7791779e-04,\n          1.1898715e-03, 5.5131881e-04, 1.3219146e-03, 7.8779942e-04,\n          6.6245400e-04, 5.4469699e-04, 8.2629442e-04, 9.0442691e-04,\n          8.3641091e-04, 4.5846510e-04, 6.7310588e-04, 7.9943979e-04,\n          7.2754914e-04, 8.8065985e-04, 7.0893351e-04, 4.9914455e-04,\n          1.6801169e-03, 4.8066783e-04, 7.0281368e-04, 7.8493881e-04,\n          1.1172214e-03, 6.5235497e-04, 5.3515483e-04, 8.1914657e-04,\n          9.5345342e-04, 6.8788184e-04, 8.5108454e-04, 7.0360629e-04,\n          9.9904079e-04, 7.5419695e-04, 9.2059904e-04, 8.7549532e-04,\n          8.7494828e-04, 6.9813651e-04, 1.1355007e-03, 1.0270344e-03,\n          1.1047750e-03, 7.8389543e-04, 7.2684948e-04, 6.7921000e-04,\n          7.4488908e-04, 6.9742487e-04, 4.6912141e-04, 8.5424568e-04,\n          4.8022179e-04, 6.0623721e-04, 8.2910853e-04, 6.9867290e-04,\n          6.7777571e-04, 8.2666968e-04, 1.2452314e-03, 2.9990514e-04,\n          5.4052507e-04, 8.2700537e-04, 5.9732492e-04, 6.6330447e-04,\n          6.3023251e-04, 7.1909383e-04, 7.0308364e-04, 8.0354582e-04,\n          4.5328290e-04, 8.3209469e-04, 1.0621996e-03, 5.9946300e-04,\n          6.9383509e-04, 1.1593252e-03, 8.8806683e-04, 5.7354884e-04,\n          5.7253480e-04, 1.1305350e-03, 4.9533747e-04, 8.2141405e-04,\n          5.9241214e-04, 7.2842918e-04, 3.5378581e-04, 3.3932141e-04,\n          3.1778624e-04, 1.1599376e-03, 7.7597349e-04, 6.7790051e-04,\n          3.0187587e-04, 6.8117637e-04, 5.6454382e-04, 9.9913462e-04,\n          6.8156037e-04, 6.8748026e-04, 9.0847467e-04, 1.1109745e-03,\n          8.2259835e-04, 5.2787230e-04, 1.9665445e-04, 6.5543741e-04,\n          8.5884699e-04, 3.5166860e-04, 6.3853257e-04, 5.0076854e-04,\n          2.6136616e-04, 8.3110470e-04, 6.9762144e-04, 4.4892522e-04,\n          1.0456705e-03, 6.5232540e-04, 6.0145638e-04, 9.3261717e-04,\n          5.4620585e-04, 8.8039611e-04, 7.9651043e-04, 7.1074686e-04,\n          7.5193582e-04, 2.9461607e-04, 5.3032296e-04, 7.1081461e-04,\n          5.3212338e-04, 8.8210934e-04, 7.7791524e-04, 8.2799984e-04,\n          6.9706934e-04, 6.2854099e-04, 8.8192971e-04, 1.1534723e-03,\n          7.4519846e-04, 4.2132090e-04, 8.1170903e-04, 3.2247091e-04,\n          5.6903390e-04, 5.4690492e-04, 2.4480626e-04, 4.9105607e-04,\n          7.3590613e-04, 6.4832828e-04, 7.3535653e-04, 3.1691979e-04],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_project/Conv2D',\n  'index': 63,\n  'shape': array([ 96,   1,   1, 576], dtype=int32),\n  'shape_signature': array([ 96,   1,   1, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00583599, 0.00417952, 0.00343898, 0.00298   , 0.00780929,\n          0.00752555, 0.00485217, 0.00646992, 0.00545162, 0.00518129,\n          0.00657937, 0.00698034, 0.00781831, 0.00256087, 0.00398464,\n          0.00627468, 0.00374661, 0.00510065, 0.00248757, 0.00450244,\n          0.00231641, 0.00876574, 0.00277509, 0.00535093, 0.00318492,\n          0.00605735, 0.00483158, 0.00261343, 0.00309319, 0.00593926,\n          0.00552198, 0.00541333, 0.0063096 , 0.00612471, 0.00725728,\n          0.00520504, 0.00535038, 0.00547002, 0.00669157, 0.00538803,\n          0.00481716, 0.00250047, 0.00851722, 0.00504006, 0.00429208,\n          0.00659918, 0.00580109, 0.00609092, 0.00401825, 0.00253583,\n          0.00225817, 0.00528198, 0.00767986, 0.00755059, 0.00378262,\n          0.00226142, 0.00576058, 0.0034813 , 0.00631764, 0.00237532,\n          0.00418004, 0.00283489, 0.00632256, 0.00267777, 0.00588911,\n          0.00222253, 0.00457881, 0.00562837, 0.00495671, 0.00586321,\n          0.00201986, 0.00496409, 0.00485144, 0.00279913, 0.00312067,\n          0.00401766, 0.00584821, 0.00487085, 0.00526672, 0.00474894,\n          0.00487246, 0.00837141, 0.00291736, 0.00383064, 0.00328343,\n          0.00294762, 0.00581624, 0.00500501, 0.0061387 , 0.00268231,\n          0.00282869, 0.00249833, 0.00624992, 0.00481249, 0.00632799,\n          0.00704459], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_expand/Conv2D',\n  'index': 64,\n  'shape': array([576,   1,   1,  96], dtype=int32),\n  'shape_signature': array([576,   1,   1,  96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00033815, 0.0005528 , 0.0007443 , 0.00057021, 0.00054546,\n          0.00055879, 0.00057872, 0.000559  , 0.00088554, 0.00053082,\n          0.00073053, 0.00073664, 0.00105961, 0.00058331, 0.00049187,\n          0.00086507, 0.0006239 , 0.0005142 , 0.00026972, 0.00051444,\n          0.00044177, 0.00062991, 0.00090383, 0.00067056, 0.00061244,\n          0.00060413, 0.00050628, 0.0007079 , 0.00053656, 0.00024525,\n          0.00088023, 0.00052386, 0.00061183, 0.00032622, 0.00057382,\n          0.00051391, 0.00101033, 0.00075544, 0.00042764, 0.00078656,\n          0.00101119, 0.00055439, 0.0006493 , 0.00046651, 0.00059951,\n          0.00059176, 0.00092893, 0.00037232, 0.00056449, 0.00068724,\n          0.00077987, 0.00055064, 0.00032935, 0.00057306, 0.00072273,\n          0.00062571, 0.00072666, 0.00048643, 0.00088774, 0.00065575,\n          0.00079732, 0.00074544, 0.00077868, 0.0005644 , 0.00061352,\n          0.00080623, 0.00077433, 0.00036978, 0.0007318 , 0.00020081,\n          0.00066728, 0.00059283, 0.00069434, 0.00067265, 0.00077442,\n          0.00058321, 0.00048394, 0.00109624, 0.00040972, 0.00050249,\n          0.000586  , 0.00055649, 0.00067518, 0.00041432, 0.00044637,\n          0.00049095, 0.00024036, 0.00016782, 0.00046481, 0.00027251,\n          0.0003508 , 0.00052143, 0.00060673, 0.00073985, 0.00074911,\n          0.00067504, 0.00058638, 0.0001556 , 0.00067881, 0.00049129,\n          0.0003505 , 0.00073663, 0.00069779, 0.0007261 , 0.0007165 ,\n          0.00059026, 0.00060241, 0.0002167 , 0.0004796 , 0.00059749,\n          0.00116768, 0.00070171, 0.00061483, 0.00060399, 0.00037772,\n          0.00019142, 0.00026249, 0.00050832, 0.00075789, 0.00033604,\n          0.0005382 , 0.00072623, 0.00074231, 0.00067772, 0.00047917,\n          0.00038946, 0.00072009, 0.00083944, 0.00079347, 0.00075385,\n          0.00035388, 0.00064636, 0.00073281, 0.00062373, 0.00064587,\n          0.00049722, 0.00041423, 0.0004423 , 0.00052081, 0.0004034 ,\n          0.00055695, 0.00032732, 0.00047415, 0.00094225, 0.00040621,\n          0.00062877, 0.00031162, 0.00082871, 0.00062764, 0.00078627,\n          0.00035501, 0.00046048, 0.00057886, 0.00077566, 0.00034202,\n          0.00071525, 0.00056711, 0.00065447, 0.00075108, 0.0006716 ,\n          0.00041695, 0.00080471, 0.00043349, 0.00029729, 0.00053791,\n          0.00045069, 0.00026073, 0.00053749, 0.00047115, 0.00054618,\n          0.00062142, 0.00076983, 0.00034408, 0.00062449, 0.00034193,\n          0.00027753, 0.00079524, 0.00054874, 0.00054669, 0.00066353,\n          0.00062813, 0.0007692 , 0.00076262, 0.00069275, 0.00065155,\n          0.00026725, 0.00040202, 0.00045621, 0.00080854, 0.00056558,\n          0.00049334, 0.00037777, 0.00062915, 0.00025356, 0.00066379,\n          0.00056287, 0.00081018, 0.00087232, 0.00062797, 0.00073583,\n          0.00084395, 0.00083918, 0.00086732, 0.00050753, 0.0006404 ,\n          0.00032272, 0.00066334, 0.0007645 , 0.00073745, 0.0007377 ,\n          0.00046391, 0.00081776, 0.00053229, 0.00065527, 0.00066124,\n          0.0006607 , 0.00049618, 0.00054827, 0.00040589, 0.00061454,\n          0.00073622, 0.00054234, 0.000518  , 0.00052615, 0.00061682,\n          0.0001902 , 0.00062015, 0.00084925, 0.00062931, 0.00040475,\n          0.00096925, 0.00070323, 0.00053034, 0.00047954, 0.00046354,\n          0.00057884, 0.00066097, 0.00110359, 0.00053446, 0.00058095,\n          0.00077185, 0.00065   , 0.0007359 , 0.00064198, 0.00033935,\n          0.00065221, 0.00031779, 0.00069995, 0.00058428, 0.00065745,\n          0.0007899 , 0.00084514, 0.00073488, 0.00082787, 0.00092105,\n          0.00048854, 0.0007862 , 0.00078791, 0.00047905, 0.00073391,\n          0.00051204, 0.00036593, 0.00052692, 0.00045809, 0.00054761,\n          0.00064682, 0.00057353, 0.00043421, 0.00061326, 0.00028934,\n          0.00060241, 0.00066078, 0.00071647, 0.00068057, 0.00064851,\n          0.00080284, 0.00076323, 0.00053016, 0.00074573, 0.00053027,\n          0.00067113, 0.00075462, 0.00080617, 0.00098601, 0.00051856,\n          0.0008304 , 0.00052063, 0.00047006, 0.00028964, 0.00060432,\n          0.00091557, 0.00055862, 0.00053865, 0.00091   , 0.00021276,\n          0.00069914, 0.00051743, 0.00056955, 0.00066986, 0.00059682,\n          0.00060821, 0.00111009, 0.00056759, 0.0006068 , 0.00078347,\n          0.00082262, 0.00073233, 0.00039963, 0.00052755, 0.0003009 ,\n          0.00079923, 0.00057494, 0.0005893 , 0.00058253, 0.00067452,\n          0.00075268, 0.00064511, 0.00064538, 0.00024205, 0.00067694,\n          0.00071232, 0.00044506, 0.00091145, 0.00081753, 0.00202734,\n          0.00048697, 0.00069027, 0.00054234, 0.0006116 , 0.00093783,\n          0.00057894, 0.00063741, 0.00069577, 0.00051671, 0.00073218,\n          0.00054811, 0.0005984 , 0.00072195, 0.00053901, 0.00067267,\n          0.00057659, 0.0006634 , 0.00067201, 0.00048457, 0.00052655,\n          0.00051093, 0.00054348, 0.00069892, 0.00046873, 0.00083606,\n          0.00041449, 0.00066324, 0.00075711, 0.00063269, 0.00020882,\n          0.00045175, 0.00056772, 0.00027025, 0.00066617, 0.00058847,\n          0.00076425, 0.00047791, 0.00049947, 0.00060286, 0.00074756,\n          0.0004079 , 0.00057691, 0.00061491, 0.00034055, 0.00031659,\n          0.0008857 , 0.00049721, 0.00080542, 0.00062482, 0.00069807,\n          0.00089653, 0.00055421, 0.00026553, 0.00015048, 0.00093419,\n          0.00039735, 0.00045642, 0.00054578, 0.00085237, 0.00077243,\n          0.0004368 , 0.0006859 , 0.00032788, 0.00023003, 0.00027795,\n          0.00053971, 0.00074583, 0.00051456, 0.00045938, 0.00083512,\n          0.00051999, 0.00029714, 0.00044655, 0.00067506, 0.00057911,\n          0.00031284, 0.00058994, 0.00066981, 0.00070875, 0.00045106,\n          0.00074025, 0.00060033, 0.000688  , 0.00036716, 0.00044557,\n          0.00071002, 0.00105326, 0.00042931, 0.00052228, 0.00074748,\n          0.00058401, 0.00110965, 0.00077144, 0.00097756, 0.00059931,\n          0.00046561, 0.00067669, 0.00065955, 0.00044919, 0.00056766,\n          0.0008202 , 0.00059779, 0.00050303, 0.00062127, 0.00082509,\n          0.00083568, 0.00119377, 0.00018552, 0.00019531, 0.00060204,\n          0.00061722, 0.00038092, 0.00055088, 0.00053348, 0.00078071,\n          0.00050345, 0.00065509, 0.00064028, 0.00064103, 0.00067404,\n          0.00030558, 0.00051668, 0.00068716, 0.00054324, 0.00053439,\n          0.00064299, 0.00076817, 0.00061656, 0.00064417, 0.000497  ,\n          0.00076384, 0.00058207, 0.00038469, 0.00074469, 0.0003775 ,\n          0.00028871, 0.00064549, 0.00079717, 0.00041859, 0.00033907,\n          0.00033916, 0.0005909 , 0.00056324, 0.00058818, 0.0006041 ,\n          0.00057364, 0.00066472, 0.00059785, 0.00039312, 0.00052576,\n          0.00080959, 0.00051394, 0.00092681, 0.00055139, 0.00056087,\n          0.00063149, 0.00040979, 0.0006271 , 0.00069772, 0.00070099,\n          0.00081749, 0.0003687 , 0.0008485 , 0.00069644, 0.00051663,\n          0.00055843, 0.00077835, 0.00030802, 0.00092056, 0.00044761,\n          0.00069016, 0.00017658, 0.00061625, 0.00044765, 0.00088864,\n          0.00062948, 0.00057219, 0.00024527, 0.0004371 , 0.00074234,\n          0.00075226, 0.0007581 , 0.00036982, 0.00052509, 0.00043226,\n          0.00032768, 0.00042836, 0.00049023, 0.00056005, 0.00032281,\n          0.00057152, 0.00061642, 0.00045048, 0.00056934, 0.00069162,\n          0.00054711, 0.00056001, 0.00055259, 0.00031407, 0.00060575,\n          0.00098611, 0.00095499, 0.00068232, 0.00069242, 0.00059688,\n          0.00071226, 0.0004018 , 0.00065462, 0.00068659, 0.00071458,\n          0.00064721, 0.00070172, 0.00055492, 0.00073819, 0.00062716,\n          0.00044665, 0.00086753, 0.00063917, 0.0007787 , 0.00088901,\n          0.00059948, 0.00061026, 0.00081295, 0.00034464, 0.00063106,\n          0.00059376, 0.00054931, 0.00055466, 0.00029245, 0.00033583,\n          0.00058999, 0.00066256, 0.0010185 , 0.00070189, 0.00050398,\n          0.0005933 , 0.00057625, 0.0004674 , 0.00085243, 0.0006894 ,\n          0.00051043, 0.00063198, 0.00057947, 0.00051684, 0.00046781,\n          0.00069741, 0.00054238, 0.00068117, 0.00049656, 0.00041975,\n          0.00073219], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_project/Conv2D',\n  'index': 65,\n  'shape': array([ 96,   1,   1, 576], dtype=int32),\n  'shape_signature': array([ 96,   1,   1, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01058105, 0.00600636, 0.00491062, 0.00403399, 0.01797116,\n          0.00791335, 0.01424355, 0.00989286, 0.00632865, 0.0101998 ,\n          0.00775848, 0.00553914, 0.00951226, 0.00477706, 0.0082213 ,\n          0.00675359, 0.00605107, 0.0093015 , 0.00512553, 0.00404073,\n          0.00313634, 0.01312378, 0.00552754, 0.00880351, 0.00421464,\n          0.00870661, 0.0091144 , 0.0029696 , 0.00765556, 0.01168943,\n          0.01345163, 0.00979867, 0.0080022 , 0.01057016, 0.00976033,\n          0.00848379, 0.02875375, 0.00815348, 0.02155324, 0.00602236,\n          0.01245468, 0.00441178, 0.01879687, 0.008192  , 0.00584925,\n          0.00871908, 0.00830153, 0.01355873, 0.00456596, 0.00414024,\n          0.00256099, 0.00973071, 0.00938874, 0.00775294, 0.00617697,\n          0.00291914, 0.01377431, 0.00507874, 0.00748113, 0.00359076,\n          0.00531446, 0.00523318, 0.01291988, 0.00501207, 0.00922318,\n          0.00286194, 0.00906818, 0.00714329, 0.0084333 , 0.01181824,\n          0.0046436 , 0.01584324, 0.00614287, 0.00474452, 0.00509748,\n          0.00654784, 0.01023551, 0.00570123, 0.00639985, 0.00563173,\n          0.00857048, 0.00870919, 0.00276867, 0.01236129, 0.00454511,\n          0.00456915, 0.00904879, 0.00847721, 0.00756207, 0.00423121,\n          0.0041665 , 0.00355965, 0.00717649, 0.0064578 , 0.01649306,\n          0.01692649], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_expand/Conv2D',\n  'index': 66,\n  'shape': array([576,   1,   1,  96], dtype=int32),\n  'shape_signature': array([576,   1,   1,  96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([7.8421982e-04, 6.5121916e-04, 5.4760295e-04, 1.4774160e-03,\n          7.7962497e-04, 8.7843608e-04, 7.0804934e-04, 6.0039404e-04,\n          8.2690129e-04, 8.5818733e-04, 7.8356010e-04, 7.1015698e-04,\n          1.0031174e-03, 3.4165164e-04, 9.7908103e-04, 4.4352439e-04,\n          7.8399520e-04, 1.1354501e-03, 4.8975059e-04, 4.7196026e-04,\n          6.8761344e-04, 5.9893297e-04, 6.4854213e-04, 5.8062986e-04,\n          6.7900843e-04, 5.9052266e-04, 6.4159825e-04, 3.3758482e-04,\n          3.1755172e-04, 8.4523729e-04, 6.4386532e-04, 5.7545287e-04,\n          5.1207864e-04, 7.2012830e-04, 3.9417032e-04, 7.9445710e-04,\n          4.9301074e-04, 3.5904156e-04, 7.2177313e-04, 4.2784895e-04,\n          5.7190395e-04, 6.4983976e-04, 6.3521246e-04, 1.0227466e-03,\n          1.1091057e-03, 8.9223601e-04, 8.1710971e-04, 8.9122506e-04,\n          5.8051193e-04, 7.8314380e-04, 6.5334252e-04, 9.1160566e-04,\n          1.0157202e-03, 7.3140941e-04, 8.0773665e-04, 5.3465099e-04,\n          6.6665554e-04, 6.6769222e-04, 4.0041064e-04, 6.2328338e-04,\n          7.8673119e-04, 3.6735495e-04, 8.4829301e-04, 4.6388712e-04,\n          8.1405422e-04, 5.7568797e-04, 7.6013402e-04, 7.3753129e-04,\n          1.1706405e-03, 5.6503987e-04, 7.6061167e-04, 1.1555209e-03,\n          5.3134986e-04, 7.1963907e-04, 8.5303833e-04, 1.0432316e-03,\n          1.2961825e-03, 6.5208564e-04, 5.4922543e-04, 8.0653612e-04,\n          6.7889830e-04, 6.3096936e-04, 7.3484366e-04, 8.4375241e-04,\n          7.0935022e-04, 1.2411786e-03, 9.0199744e-04, 7.7613548e-04,\n          6.0536555e-04, 6.4509764e-04, 1.0486182e-03, 7.5672125e-04,\n          1.0026554e-03, 6.4243161e-04, 8.1335456e-04, 4.0437005e-04,\n          7.3078956e-04, 4.9752888e-04, 4.6916949e-04, 6.9269846e-04,\n          8.0337474e-04, 1.0037902e-03, 5.1853742e-04, 7.1416458e-04,\n          6.8008801e-04, 1.2061609e-03, 1.1134334e-03, 9.6916524e-04,\n          2.2892869e-04, 7.0375903e-04, 5.6582101e-04, 6.9528277e-04,\n          7.4930169e-04, 1.3374647e-03, 8.6540333e-04, 9.1499841e-04,\n          1.0483584e-03, 9.7311905e-04, 6.3134433e-04, 4.4968043e-04,\n          6.9000060e-04, 6.5723702e-04, 5.5048568e-04, 7.6868094e-04,\n          6.6878460e-04, 5.4477248e-04, 7.4570440e-04, 7.2600943e-04,\n          5.6497508e-04, 7.5060740e-04, 1.0537084e-03, 4.8422415e-04,\n          6.0536235e-04, 7.1045582e-04, 6.8457116e-04, 6.7598722e-04,\n          1.0675638e-03, 3.9880929e-04, 3.9308731e-04, 3.9830594e-04,\n          6.8983727e-04, 6.7765114e-04, 5.5362389e-04, 7.0683495e-04,\n          4.9931515e-04, 5.2243774e-04, 8.8983658e-04, 6.8148138e-04,\n          1.0239469e-03, 7.7288732e-04, 5.3979876e-04, 4.7990476e-04,\n          6.9483474e-04, 6.9278112e-04, 8.8595081e-04, 6.8465032e-04,\n          8.9594931e-04, 2.6948363e-04, 5.6358706e-04, 6.8111270e-04,\n          6.2754087e-04, 8.7708893e-04, 6.9856294e-04, 6.5274379e-04,\n          8.7262125e-04, 1.2269574e-03, 6.7900220e-04, 1.2666729e-03,\n          6.7899452e-04, 5.8618060e-04, 7.3096686e-04, 6.1172206e-04,\n          4.2134232e-04, 4.8552980e-04, 4.9858296e-04, 4.5006847e-05,\n          1.0343267e-03, 2.4206071e-04, 5.7753443e-04, 9.3476748e-04,\n          1.0448047e-03, 4.0253613e-04, 8.9377793e-04, 9.9234283e-04,\n          6.3009997e-04, 9.5481396e-04, 6.9501676e-04, 6.1454263e-04,\n          8.1787462e-04, 9.1759069e-04, 5.5246335e-04, 1.0282685e-03,\n          4.8755395e-04, 8.5325335e-04, 6.1080582e-04, 8.0616324e-04,\n          5.0598627e-04, 5.1738450e-04, 1.3299676e-03, 4.8537552e-04,\n          6.3891656e-04, 7.2187302e-04, 8.6102879e-04, 6.4308313e-04,\n          1.0498087e-03, 9.8916632e-04, 4.6695056e-04, 1.0193423e-03,\n          6.6563621e-04, 6.9438410e-04, 7.6790684e-04, 5.6271185e-04,\n          1.1492828e-03, 5.0809653e-04, 5.2934897e-04, 1.1967964e-03,\n          7.9576188e-04, 5.3736055e-04, 6.1808573e-04, 6.4111786e-04,\n          5.2198587e-04, 7.3906087e-04, 5.3463440e-04, 6.7579240e-04,\n          7.1875146e-04, 1.1168729e-03, 4.1406640e-04, 6.2146463e-04,\n          7.5465272e-04, 5.4688187e-04, 7.8397547e-04, 6.1403576e-04,\n          5.0810666e-04, 4.8276817e-04, 1.0232140e-03, 1.0354394e-03,\n          7.9131417e-04, 1.7770854e-04, 6.5140158e-04, 4.8646989e-04,\n          2.9971290e-04, 7.7975239e-04, 7.3484395e-04, 8.5503818e-04,\n          4.9459824e-04, 5.3903996e-04, 5.7811139e-04, 6.6259253e-04,\n          5.2735111e-04, 7.1654329e-04, 9.8663138e-04, 7.5726706e-04,\n          7.6501275e-04, 5.5376161e-04, 7.9129991e-04, 5.9554004e-04,\n          7.3697552e-04, 1.1843134e-03, 9.0090506e-04, 6.8906078e-04,\n          6.7764008e-04, 8.0425187e-04, 5.8570603e-04, 9.7281754e-04,\n          9.8776422e-04, 8.8345789e-04, 8.2047604e-04, 4.8126295e-04,\n          8.5375772e-04, 6.4277649e-04, 4.7868991e-04, 9.0134353e-04,\n          8.9981226e-04, 8.6085446e-04, 9.7707193e-04, 7.0601562e-04,\n          5.4171326e-04, 5.9961184e-04, 1.1758215e-03, 7.3577842e-04,\n          7.2344398e-04, 5.5389490e-04, 4.5441449e-04, 8.8274200e-04,\n          9.9447113e-04, 8.2791242e-04, 6.9320115e-04, 7.1280415e-04,\n          4.1593891e-04, 3.2675188e-04, 6.2299438e-04, 6.7205884e-04,\n          3.1512865e-04, 5.6047854e-04, 2.1872086e-04, 5.5618532e-04,\n          5.9404899e-04, 4.6608763e-04, 1.1878816e-03, 8.4988552e-04,\n          5.3391047e-04, 5.0438353e-04, 6.0340122e-04, 7.3689281e-04,\n          3.8737629e-04, 7.5279240e-04, 9.3816925e-04, 8.6149859e-04,\n          8.7812758e-04, 7.4125431e-04, 9.7393885e-04, 8.2137570e-04,\n          8.1788824e-04, 5.7865994e-04, 5.5514323e-04, 4.0793215e-04,\n          8.7173755e-04, 7.2078907e-04, 5.0576765e-04, 5.2546640e-04,\n          4.8507811e-04, 9.8131585e-04, 5.5987650e-04, 7.8659895e-04,\n          9.3304174e-04, 9.8732172e-04, 6.6682138e-04, 4.9406965e-04,\n          7.4977154e-04, 8.3919085e-04, 7.5276889e-04, 6.8183558e-04,\n          6.1916036e-04, 1.1591176e-03, 6.7618280e-04, 4.9492106e-04,\n          7.3126040e-04, 5.9341721e-04, 8.2403212e-04, 7.8800024e-04,\n          7.7145145e-04, 1.2506468e-03, 8.2760502e-04, 8.7941351e-04,\n          8.5304445e-04, 8.5381354e-04, 4.6774212e-04, 1.0333552e-03,\n          1.2547855e-03, 5.9752678e-04, 7.6851319e-04, 8.5450563e-04,\n          5.8731937e-04, 3.0848884e-04, 6.0788816e-04, 8.5832202e-04,\n          8.7794231e-04, 7.2525098e-04, 8.6908473e-04, 4.9803260e-04,\n          5.3640141e-04, 5.8977545e-04, 7.4112642e-04, 1.0277011e-03,\n          6.3289935e-04, 5.5460882e-04, 7.1932020e-04, 6.4820453e-04,\n          6.6670502e-04, 4.4926026e-04, 7.1867934e-04, 6.9296616e-04,\n          6.0264010e-04, 6.9959974e-04, 8.8556099e-04, 7.5625814e-04,\n          8.8898867e-04, 7.7402272e-04, 5.8175693e-04, 8.8301394e-04,\n          8.7699789e-04, 7.0231099e-04, 6.9041329e-04, 7.4131327e-04,\n          7.9914380e-04, 8.8031415e-04, 9.3534659e-04, 5.0880783e-04,\n          7.5783138e-04, 6.9489039e-04, 4.5637673e-04, 5.7501753e-04,\n          3.4195249e-04, 8.1238459e-04, 6.1943399e-04, 7.2371296e-04,\n          7.1785820e-04, 6.9115439e-04, 7.3975016e-04, 8.0796663e-04,\n          5.1751843e-04, 5.5020431e-04, 6.5768685e-04, 5.2771298e-04,\n          7.7282457e-04, 6.9089112e-04, 2.0667017e-04, 6.0269638e-04,\n          7.1620068e-04, 8.3814957e-04, 4.8893754e-04, 8.4101892e-04,\n          5.8102253e-04, 5.4285553e-04, 1.2200905e-03, 5.0511578e-04,\n          7.9877884e-04, 7.1063760e-04, 1.0970411e-03, 1.0943545e-03,\n          1.2192256e-03, 7.8702945e-04, 1.1023156e-03, 5.6293973e-04,\n          8.0051133e-04, 9.7202900e-04, 8.4841612e-04, 6.8465207e-04,\n          8.7089557e-04, 6.0226233e-04, 2.1046029e-04, 7.0851401e-04,\n          9.8188757e-04, 8.9443469e-04, 6.6941371e-04, 8.9330290e-04,\n          7.4406562e-04, 7.4168103e-04, 1.0281602e-03, 6.3165039e-04,\n          4.4478432e-04, 4.8026399e-04, 5.3495006e-04, 7.0882816e-04,\n          6.7926635e-04, 7.5360690e-04, 7.1402336e-04, 7.2311528e-04,\n          6.2565424e-04, 1.1593217e-03, 6.3425332e-04, 6.2655867e-04,\n          6.0562690e-04, 5.7600159e-04, 6.2211970e-04, 6.5993232e-04,\n          5.6887261e-04, 5.4949155e-04, 4.3960713e-04, 5.4168788e-04,\n          8.6264295e-04, 5.6490710e-04, 8.3561451e-04, 8.7784475e-04,\n          6.2483648e-04, 7.2614633e-04, 5.9644104e-04, 5.2164454e-04,\n          1.0313084e-03, 7.3000393e-04, 7.9224881e-04, 3.0978661e-04,\n          7.2301086e-04, 7.1353448e-04, 1.0209426e-03, 5.8435014e-04,\n          4.9622724e-04, 4.5867413e-04, 7.6982391e-04, 4.0219582e-04,\n          4.7660226e-04, 5.7725969e-04, 7.7516231e-04, 8.0774562e-04,\n          1.0157471e-03, 8.3068915e-04, 7.8859390e-04, 1.0399875e-03,\n          6.8126479e-04, 6.0249667e-04, 6.7412958e-04, 6.4111833e-04,\n          6.7872665e-04, 9.4370538e-04, 5.5671629e-04, 8.6954713e-04,\n          8.3440659e-04, 5.9511792e-04, 6.5390609e-04, 6.1018305e-04,\n          5.9601775e-04, 7.8192324e-04, 5.9649197e-04, 4.4191835e-04,\n          6.0006365e-04, 7.4281660e-04, 6.7455851e-04, 6.6201563e-04,\n          6.1261974e-04, 8.0938818e-04, 4.8352868e-04, 7.4618956e-04,\n          4.9195508e-04, 5.2838470e-04, 7.4898044e-04, 7.2485290e-04,\n          7.4963301e-04, 4.7443894e-04, 1.1156376e-03, 5.3629739e-04,\n          5.7201961e-04, 6.5731391e-04, 9.9607755e-04, 8.4882113e-04,\n          7.6970214e-04, 7.9765636e-04, 6.2354928e-04, 5.8456918e-04,\n          7.2499691e-04, 5.7618512e-04, 7.2947401e-04, 8.2780368e-04,\n          4.8731387e-04, 6.0913572e-04, 6.0196128e-04, 7.1776769e-04,\n          5.1480206e-04, 7.5030926e-04, 5.6674279e-04, 8.2831609e-04,\n          1.0717445e-03, 6.9976581e-04, 9.6983567e-04, 7.3308730e-04,\n          7.5718941e-04, 5.6345307e-04, 9.5554930e-04, 9.8752487e-04,\n          1.1726784e-03, 5.4391247e-04, 1.0112206e-03, 5.8820721e-04,\n          2.9589690e-04, 8.1764918e-04, 1.0440565e-03, 6.5365981e-04,\n          1.1415026e-03, 8.9222903e-04, 6.2615605e-04, 8.9550705e-04,\n          7.0130412e-04, 7.4586255e-04, 5.5626786e-04, 6.2425353e-04,\n          6.2256586e-04, 4.6893416e-04, 7.6469895e-04, 9.8204298e-04,\n          6.8667426e-04, 5.5603421e-04, 6.7424239e-04, 7.3218835e-04,\n          3.9281326e-04, 1.1030363e-04, 4.6159446e-04, 5.7138462e-04],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_project/Conv2D',\n  'index': 67,\n  'shape': array([160,   1,   1, 576], dtype=int32),\n  'shape_signature': array([160,   1,   1, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00492511, 0.00434134, 0.0048522 , 0.00522022, 0.00542425,\n          0.0045297 , 0.00409809, 0.00530987, 0.00486544, 0.00571181,\n          0.00419919, 0.00464041, 0.00493843, 0.0055934 , 0.00417156,\n          0.00463822, 0.0041976 , 0.00428458, 0.00405573, 0.00497285,\n          0.00365884, 0.00550642, 0.00418195, 0.00446727, 0.00495727,\n          0.00419383, 0.00441827, 0.00485721, 0.00425716, 0.00497071,\n          0.00555861, 0.00499178, 0.00466191, 0.00470203, 0.00570025,\n          0.00573959, 0.00470784, 0.00513117, 0.00405878, 0.00545842,\n          0.00721212, 0.00335305, 0.00402426, 0.00503504, 0.00375203,\n          0.00458354, 0.00439987, 0.00521581, 0.00420691, 0.00379795,\n          0.00499586, 0.0044916 , 0.00520421, 0.00412675, 0.00475829,\n          0.00555475, 0.00469813, 0.00423438, 0.00655246, 0.0046315 ,\n          0.00544707, 0.00514927, 0.00446866, 0.00493231, 0.00542416,\n          0.00400316, 0.00473352, 0.00418804, 0.00384225, 0.00345646,\n          0.00541021, 0.00410048, 0.00497237, 0.00516846, 0.00817494,\n          0.00599807, 0.00438993, 0.0041414 , 0.00678241, 0.00439735,\n          0.00448773, 0.00996344, 0.00380822, 0.00500472, 0.00697274,\n          0.00616878, 0.0048091 , 0.00586956, 0.00475813, 0.00470957,\n          0.00416335, 0.00526315, 0.0045137 , 0.00772782, 0.00401452,\n          0.00636062, 0.00454791, 0.00439442, 0.00403593, 0.00537712,\n          0.00472026, 0.00509979, 0.00471158, 0.00462657, 0.00520289,\n          0.00425682, 0.00319362, 0.00612469, 0.00455328, 0.00398012,\n          0.00499381, 0.00469833, 0.00596318, 0.00503143, 0.00503727,\n          0.00460153, 0.00435632, 0.00429668, 0.00523853, 0.00611062,\n          0.0052768 , 0.00674159, 0.0041397 , 0.00497628, 0.00471192,\n          0.00399486, 0.00420608, 0.00585388, 0.00501258, 0.00522748,\n          0.00456331, 0.00770783, 0.00525949, 0.00851545, 0.00498464,\n          0.00439663, 0.00451788, 0.00659047, 0.0046973 , 0.00460113,\n          0.00411917, 0.00530839, 0.00467033, 0.00453836, 0.00544812,\n          0.00539049, 0.00659754, 0.00419869, 0.00590598, 0.00416216,\n          0.00485725, 0.0051136 , 0.00474233, 0.00431117, 0.00452059,\n          0.00571609, 0.00501937, 0.00491069, 0.00497419, 0.00479563],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_expand/Conv2D',\n  'index': 68,\n  'shape': array([960,   1,   1, 160], dtype=int32),\n  'shape_signature': array([960,   1,   1, 160], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00095066, 0.00081637, 0.00070641, 0.00042304, 0.00114956,\n          0.00056262, 0.00068142, 0.00083998, 0.00066951, 0.00078305,\n          0.00060662, 0.00116809, 0.00062779, 0.00106657, 0.00093238,\n          0.00099237, 0.00101228, 0.00040226, 0.00085895, 0.0009323 ,\n          0.00061523, 0.00076659, 0.00063137, 0.00105746, 0.00052002,\n          0.00116709, 0.00040671, 0.00093588, 0.00072863, 0.00071858,\n          0.00092061, 0.0009941 , 0.00049921, 0.00083791, 0.00051956,\n          0.00057896, 0.00064854, 0.00057969, 0.00078783, 0.00060981,\n          0.00062584, 0.000705  , 0.00060592, 0.00061933, 0.00105295,\n          0.00075954, 0.00076109, 0.00041871, 0.0003772 , 0.0009314 ,\n          0.00147349, 0.00080463, 0.00047006, 0.00090351, 0.00083369,\n          0.00047807, 0.00089991, 0.00105944, 0.00044925, 0.00071841,\n          0.00060605, 0.00048217, 0.00075544, 0.00045176, 0.00043216,\n          0.00101302, 0.00095492, 0.00073841, 0.00081593, 0.0005518 ,\n          0.00060894, 0.00068382, 0.00075341, 0.00066876, 0.00050733,\n          0.00127755, 0.0011001 , 0.00071916, 0.00033655, 0.00055946,\n          0.00080796, 0.00053543, 0.00066637, 0.00069417, 0.0008288 ,\n          0.00090053, 0.00139073, 0.00072715, 0.00090995, 0.00057426,\n          0.0005539 , 0.00071248, 0.00046093, 0.00075439, 0.00068323,\n          0.0006931 , 0.00070901, 0.00046891, 0.00073097, 0.00076917,\n          0.00041447, 0.0009758 , 0.00097831, 0.00056516, 0.00078207,\n          0.00058525, 0.0017144 , 0.00047879, 0.00067812, 0.00065094,\n          0.00091875, 0.00087697, 0.00094371, 0.00038594, 0.00050284,\n          0.00066448, 0.00091179, 0.00076399, 0.00082337, 0.00058437,\n          0.00103589, 0.00051693, 0.00090014, 0.00108697, 0.00087919,\n          0.00155223, 0.00069253, 0.0006932 , 0.00088983, 0.00060653,\n          0.00077379, 0.000584  , 0.00086707, 0.00041763, 0.00089363,\n          0.00074625, 0.00087952, 0.00074355, 0.00076628, 0.00086839,\n          0.00074453, 0.00064965, 0.0005879 , 0.00093718, 0.0006038 ,\n          0.00057969, 0.0008356 , 0.00063617, 0.00102093, 0.0007749 ,\n          0.00056183, 0.00090504, 0.00077016, 0.00058874, 0.00069843,\n          0.00044117, 0.00089556, 0.00047934, 0.00029422, 0.00044095,\n          0.00051083, 0.00057518, 0.00063333, 0.00074501, 0.00096123,\n          0.00033101, 0.00043956, 0.00100967, 0.00064956, 0.00029122,\n          0.00099183, 0.00096526, 0.00116252, 0.0004558 , 0.00069171,\n          0.00099188, 0.00050616, 0.00031793, 0.00041352, 0.00039184,\n          0.00086019, 0.00047357, 0.00046817, 0.00058426, 0.00071393,\n          0.00046978, 0.00099825, 0.00081993, 0.00074098, 0.00086549,\n          0.00052567, 0.00049493, 0.00212894, 0.0006151 , 0.00089385,\n          0.00071557, 0.00104078, 0.00083627, 0.00085901, 0.00069778,\n          0.00061597, 0.00074532, 0.00022675, 0.00035868, 0.0005673 ,\n          0.00062104, 0.00088907, 0.0010717 , 0.00052631, 0.00041693,\n          0.00036633, 0.00080522, 0.00100348, 0.00078217, 0.00070076,\n          0.00115103, 0.00053873, 0.00047048, 0.00090729, 0.00047986,\n          0.00037929, 0.00072492, 0.00046547, 0.00056882, 0.00039036,\n          0.00068316, 0.00065139, 0.0006659 , 0.0005338 , 0.00134499,\n          0.00058138, 0.00091298, 0.00059751, 0.00102638, 0.00058006,\n          0.00098664, 0.00068662, 0.00066822, 0.00053656, 0.00102104,\n          0.00045193, 0.00042511, 0.00183565, 0.00077651, 0.00072856,\n          0.00069279, 0.00087655, 0.00037092, 0.0011918 , 0.00100174,\n          0.00099934, 0.00066942, 0.00104389, 0.00077671, 0.00073209,\n          0.00045186, 0.0007895 , 0.00062827, 0.00041476, 0.00077962,\n          0.00072538, 0.00104151, 0.00077877, 0.00045701, 0.0007017 ,\n          0.00064432, 0.00118302, 0.00124254, 0.00061223, 0.00058137,\n          0.00071539, 0.00103539, 0.00052676, 0.00110316, 0.00045108,\n          0.00034934, 0.0006028 , 0.00057107, 0.0007138 , 0.00123953,\n          0.00025612, 0.00072402, 0.00075324, 0.00102228, 0.00066038,\n          0.00107616, 0.00063122, 0.00062829, 0.00059524, 0.00069215,\n          0.0006142 , 0.00106312, 0.000502  , 0.00090827, 0.00070296,\n          0.00100397, 0.00052119, 0.00083446, 0.0013241 , 0.00075752,\n          0.00091435, 0.0004422 , 0.0004295 , 0.00135242, 0.00092838,\n          0.00067736, 0.00089049, 0.00057234, 0.00071629, 0.00155178,\n          0.00082479, 0.00059305, 0.0009931 , 0.00083332, 0.00029053,\n          0.00070378, 0.00120074, 0.00060827, 0.00058907, 0.00062055,\n          0.00058798, 0.00045923, 0.00042117, 0.00103483, 0.00042915,\n          0.00064198, 0.00122785, 0.00043257, 0.00077574, 0.00088695,\n          0.00060597, 0.00114254, 0.00084159, 0.00073005, 0.00050061,\n          0.00081272, 0.00055252, 0.0006372 , 0.00043359, 0.00067181,\n          0.0009802 , 0.00052035, 0.00063488, 0.00082268, 0.00071634,\n          0.00054237, 0.00057105, 0.00035588, 0.00076601, 0.00068207,\n          0.00041479, 0.00071173, 0.00061492, 0.0008933 , 0.00073091,\n          0.00092165, 0.00040385, 0.00044717, 0.00075157, 0.00064878,\n          0.00057818, 0.00068207, 0.00056096, 0.00069956, 0.00061243,\n          0.00093885, 0.00065529, 0.00025603, 0.00102379, 0.00093918,\n          0.00042282, 0.00057948, 0.000986  , 0.00069295, 0.00068049,\n          0.00098745, 0.00070742, 0.00061453, 0.00081676, 0.00085548,\n          0.00040544, 0.00041569, 0.00051103, 0.00037812, 0.00051909,\n          0.00102781, 0.00057627, 0.00094499, 0.00073604, 0.00122579,\n          0.00082386, 0.0006192 , 0.00074081, 0.00107509, 0.00061123,\n          0.00063914, 0.00100503, 0.0004425 , 0.0003678 , 0.00032481,\n          0.00043177, 0.00047612, 0.00086416, 0.00081066, 0.00074126,\n          0.00078761, 0.00056526, 0.00090068, 0.00058895, 0.00046513,\n          0.00052927, 0.00104637, 0.00100743, 0.00057152, 0.00102802,\n          0.00084099, 0.00057332, 0.00112414, 0.00049947, 0.00128468,\n          0.0004994 , 0.00098448, 0.00093731, 0.00071826, 0.00050105,\n          0.00055958, 0.00068028, 0.00084032, 0.00074943, 0.00059356,\n          0.0006813 , 0.00052442, 0.00061027, 0.00110047, 0.00079074,\n          0.00085722, 0.00048231, 0.00087301, 0.0006924 , 0.00106057,\n          0.00072641, 0.00069174, 0.00151583, 0.00040761, 0.00062067,\n          0.00044663, 0.0006338 , 0.00089128, 0.00066106, 0.0001957 ,\n          0.00096781, 0.00038627, 0.000672  , 0.00046219, 0.0008727 ,\n          0.00061124, 0.0006947 , 0.00061699, 0.00053788, 0.00149738,\n          0.00072462, 0.00027082, 0.00109192, 0.00037385, 0.00056384,\n          0.00103319, 0.00068655, 0.00125115, 0.00080764, 0.00073255,\n          0.0009673 , 0.0005553 , 0.00063621, 0.00077215, 0.00065923,\n          0.00084823, 0.00082217, 0.00169902, 0.00024734, 0.00072554,\n          0.00081829, 0.00121008, 0.00101061, 0.00085312, 0.00072345,\n          0.00067573, 0.00086082, 0.00095946, 0.00084381, 0.0006506 ,\n          0.00057618, 0.0007213 , 0.00110563, 0.00053091, 0.00091107,\n          0.00062395, 0.00077709, 0.00039149, 0.00114981, 0.00098554,\n          0.00074871, 0.00074115, 0.00064963, 0.00061179, 0.00078812,\n          0.00066102, 0.00080824, 0.00119695, 0.00065104, 0.00086878,\n          0.00078441, 0.00112019, 0.00099811, 0.000419  , 0.00056877,\n          0.00093714, 0.00129745, 0.00057595, 0.00084316, 0.00097521,\n          0.00039956, 0.00093455, 0.00052618, 0.00098386, 0.00079531,\n          0.00047774, 0.00035512, 0.00094157, 0.00047458, 0.00042515,\n          0.00086621, 0.0009697 , 0.0005474 , 0.00046995, 0.00075711,\n          0.00031553, 0.00087533, 0.00182134, 0.00053352, 0.001109  ,\n          0.00085079, 0.00083735, 0.00122506, 0.00070484, 0.00031954,\n          0.00080837, 0.00054114, 0.00031843, 0.0005562 , 0.00063641,\n          0.00055054, 0.00036864, 0.00075281, 0.0007501 , 0.00087249,\n          0.0004907 , 0.00049179, 0.00066848, 0.00070636, 0.00125097,\n          0.0008197 , 0.00080538, 0.00035235, 0.0006912 , 0.00090488,\n          0.00050853, 0.00083358, 0.00083429, 0.0004779 , 0.00060053,\n          0.00057381, 0.00096344, 0.00070607, 0.00049146, 0.00060472,\n          0.00089303, 0.00084775, 0.00075883, 0.0010269 , 0.0007543 ,\n          0.00087131, 0.00051717, 0.0004466 , 0.00099831, 0.00120594,\n          0.00048366, 0.0005499 , 0.00065955, 0.00042389, 0.00060314,\n          0.00052015, 0.00072083, 0.00081903, 0.000925  , 0.00065597,\n          0.00076263, 0.00084531, 0.00061174, 0.00075885, 0.00077368,\n          0.0004125 , 0.00086431, 0.00134221, 0.00046957, 0.0007686 ,\n          0.00085532, 0.00054967, 0.00106997, 0.00067124, 0.00025108,\n          0.00075494, 0.00092817, 0.00070569, 0.00062444, 0.00192691,\n          0.00086367, 0.00107517, 0.00097382, 0.0005533 , 0.00068152,\n          0.00052836, 0.00027755, 0.0010055 , 0.00071597, 0.00053726,\n          0.00066916, 0.00083698, 0.00075773, 0.00100765, 0.00047478,\n          0.00073815, 0.00047181, 0.00085901, 0.00084795, 0.00037102,\n          0.00086761, 0.00086627, 0.00090117, 0.0008204 , 0.00079889,\n          0.00079678, 0.00069931, 0.00108566, 0.00084202, 0.00081896,\n          0.00047741, 0.00102909, 0.00044404, 0.00076458, 0.00060966,\n          0.0004403 , 0.00049761, 0.00064061, 0.00177434, 0.00074095,\n          0.00085334, 0.00065795, 0.00048426, 0.00095152, 0.00125236,\n          0.00072758, 0.00107778, 0.00043537, 0.00070248, 0.00097375,\n          0.00060664, 0.00048609, 0.0003431 , 0.00071113, 0.00042074,\n          0.00071001, 0.00084121, 0.00038207, 0.00078122, 0.00057839,\n          0.00092011, 0.00083924, 0.00069985, 0.00041246, 0.00062265,\n          0.00077195, 0.00048684, 0.00074983, 0.00055327, 0.00110804,\n          0.00086438, 0.0004779 , 0.00175268, 0.00085502, 0.00091197,\n          0.00175325, 0.00077326, 0.00057722, 0.00061117, 0.00053968,\n          0.00082889, 0.0005096 , 0.00072981, 0.00077757, 0.00079097,\n          0.00090083, 0.00059495, 0.00044739, 0.00079944, 0.00083246,\n          0.00093139, 0.00079434, 0.00099652, 0.00129128, 0.0003337 ,\n          0.00076212, 0.00074391, 0.00089479, 0.00059772, 0.00056618,\n          0.00097547, 0.00077911, 0.00056662, 0.00073993, 0.00057617,\n          0.00075801, 0.00024398, 0.00043106, 0.00074158, 0.00081935,\n          0.00059721, 0.00090381, 0.00065735, 0.00080897, 0.00080056,\n          0.00107253, 0.00100094, 0.00040297, 0.00093227, 0.00090049,\n          0.00039098, 0.00041093, 0.00032797, 0.00056239, 0.00050415,\n          0.00097745, 0.00089387, 0.00085512, 0.00088994, 0.00041032,\n          0.00046881, 0.00037076, 0.00070098, 0.00042505, 0.00100965,\n          0.00062505, 0.0005803 , 0.00091702, 0.00062231, 0.00049072,\n          0.00078588, 0.00041582, 0.00082918, 0.00072319, 0.00041988,\n          0.00082855, 0.00097053, 0.0005416 , 0.00065477, 0.00065041,\n          0.00072725, 0.00051439, 0.00072909, 0.00098282, 0.00065447,\n          0.00064415, 0.00126932, 0.00071658, 0.00049388, 0.00067031,\n          0.00064865, 0.00112926, 0.00069844, 0.00081192, 0.00063612,\n          0.00103743, 0.00066657, 0.00046033, 0.00057931, 0.0004255 ,\n          0.00087134, 0.00127629, 0.00102921, 0.00041778, 0.0015932 ,\n          0.00073358, 0.00094376, 0.00068815, 0.00070272, 0.00147601,\n          0.00052068, 0.00089185, 0.00060867, 0.00075282, 0.0007261 ,\n          0.00046007, 0.00093996, 0.00038459, 0.00118322, 0.00056868,\n          0.00075807, 0.00063981, 0.00077795, 0.00084304, 0.00059649,\n          0.00117241, 0.00090241, 0.0012191 , 0.00092783, 0.00113672,\n          0.00058287, 0.00065288, 0.00095503, 0.0012515 , 0.00073254,\n          0.00040083, 0.00018766, 0.00057415, 0.00086983, 0.0007678 ,\n          0.00049555, 0.00100888, 0.0008034 , 0.00087997, 0.00082307,\n          0.00052377, 0.00070913, 0.00038873, 0.0004586 , 0.00050765,\n          0.00103873, 0.00110716, 0.00082749, 0.00094922, 0.00081077,\n          0.00078497, 0.00089008, 0.00068018, 0.00102606, 0.0006443 ,\n          0.00084596, 0.00107525, 0.00081127, 0.00077901, 0.00076364,\n          0.00107615, 0.00054093, 0.00077349, 0.00072151, 0.00056417,\n          0.00059171, 0.0008868 , 0.00116052, 0.00105104, 0.00083289,\n          0.00074558, 0.00085281, 0.00065342, 0.00098392, 0.00062807,\n          0.00071926, 0.00098911, 0.00086234, 0.00076333, 0.00070331,\n          0.00042087, 0.00041921, 0.00038707, 0.00077365, 0.00098558,\n          0.00053351, 0.00069019, 0.00089429, 0.00036403, 0.00071056,\n          0.00073429, 0.00131133, 0.00077052, 0.00067764, 0.00079768,\n          0.00071134, 0.00070115, 0.00075316, 0.00103517, 0.00053722,\n          0.00081   , 0.00094899, 0.00096547, 0.00075608, 0.00096478,\n          0.00039999, 0.00086394, 0.00048278, 0.00076806, 0.00093372,\n          0.00045951, 0.00083331, 0.00077081, 0.00054137, 0.00070637,\n          0.00045734, 0.00101348, 0.00097929, 0.00099925, 0.00110014,\n          0.00063577, 0.00083726, 0.00048094, 0.00031441, 0.00057828,\n          0.00102834, 0.00088353, 0.00099583, 0.00087241, 0.00083699,\n          0.0008255 , 0.00097254, 0.00073553, 0.00092866, 0.00103575,\n          0.00036221, 0.00046187, 0.00051526, 0.000463  , 0.00075816,\n          0.00062129, 0.00040645, 0.00060685, 0.00060529, 0.00132139,\n          0.00078249, 0.00064518, 0.00060118, 0.00087631, 0.00108868,\n          0.00044465, 0.00112327, 0.00100546, 0.00073434, 0.00076963,\n          0.0007178 , 0.00153959, 0.00077172, 0.00059843, 0.00050646,\n          0.00128864, 0.00064478, 0.00034844, 0.00051795, 0.00085839,\n          0.0004393 , 0.00048365, 0.00078139, 0.00083402, 0.00112721],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_project/Conv2D',\n  'index': 69,\n  'shape': array([160,   1,   1, 960], dtype=int32),\n  'shape_signature': array([160,   1,   1, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.0040901 , 0.00633697, 0.00492061, 0.0034168 , 0.00363266,\n          0.00359928, 0.00372805, 0.00429695, 0.00399842, 0.00345206,\n          0.00465214, 0.00507964, 0.00465557, 0.00483631, 0.00302405,\n          0.00361211, 0.00418998, 0.00401205, 0.00713763, 0.00309296,\n          0.00384771, 0.00395041, 0.00383541, 0.00538793, 0.00372138,\n          0.00248352, 0.00461557, 0.00298284, 0.00374884, 0.00508953,\n          0.00531858, 0.00493944, 0.00519024, 0.00500997, 0.00303314,\n          0.004399  , 0.00768191, 0.00441001, 0.00584981, 0.00450623,\n          0.00476713, 0.00408533, 0.00445036, 0.00419052, 0.00576521,\n          0.0040768 , 0.0054422 , 0.00441929, 0.00405768, 0.00309825,\n          0.00498803, 0.00333816, 0.00419263, 0.0028457 , 0.00357146,\n          0.00318869, 0.00281885, 0.00295543, 0.00573905, 0.00443881,\n          0.00622199, 0.0032723 , 0.00305315, 0.00441179, 0.00330703,\n          0.00358288, 0.00422051, 0.00396075, 0.00270703, 0.00324832,\n          0.0029916 , 0.00400002, 0.00356642, 0.00572189, 0.00431251,\n          0.00474316, 0.00343906, 0.00459121, 0.00550964, 0.00356301,\n          0.00360854, 0.00600066, 0.00487349, 0.0040138 , 0.00355669,\n          0.00394506, 0.00425686, 0.00406209, 0.00448091, 0.00384452,\n          0.00378696, 0.0056127 , 0.00492622, 0.00320101, 0.00261646,\n          0.00434925, 0.00436847, 0.00459636, 0.00591494, 0.00374092,\n          0.00473798, 0.00505802, 0.00374034, 0.00516071, 0.00311723,\n          0.00489966, 0.00333208, 0.00493084, 0.00472285, 0.00494031,\n          0.00567813, 0.00465358, 0.00514332, 0.00349137, 0.00385575,\n          0.00418343, 0.00734358, 0.00286492, 0.00433852, 0.00592676,\n          0.00510604, 0.00262446, 0.00375388, 0.00373848, 0.00344689,\n          0.00460853, 0.00388473, 0.00552512, 0.00530278, 0.00499216,\n          0.00326415, 0.00448067, 0.006402  , 0.00816704, 0.00516331,\n          0.00372414, 0.00518181, 0.00455599, 0.00498796, 0.00427842,\n          0.00474239, 0.00662557, 0.00432314, 0.00639562, 0.00476604,\n          0.00323051, 0.0039684 , 0.00326997, 0.00360353, 0.00517297,\n          0.00309314, 0.00321439, 0.00832966, 0.00372729, 0.0043471 ,\n          0.00560097, 0.00316051, 0.00459585, 0.00419205, 0.00714994],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_expand/Conv2D',\n  'index': 70,\n  'shape': array([960,   1,   1, 160], dtype=int32),\n  'shape_signature': array([960,   1,   1, 160], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([4.37655370e-04, 4.05074534e-04, 5.87032700e-04, 5.39928733e-04,\n          4.38687828e-04, 3.87082400e-04, 7.90798105e-04, 5.96372003e-04,\n          3.36459547e-04, 2.79097148e-04, 2.16846878e-04, 6.00188156e-04,\n          4.39692376e-04, 4.24554310e-04, 7.65371602e-04, 7.75609980e-04,\n          5.34323917e-04, 5.00532391e-04, 5.59079810e-04, 5.73098892e-04,\n          4.49646381e-04, 5.02744224e-04, 8.15583800e-04, 3.80984828e-04,\n          6.63009705e-04, 6.37777848e-04, 7.14405789e-04, 5.47885837e-04,\n          9.20693856e-04, 6.26360881e-04, 7.96793960e-04, 3.77046526e-04,\n          4.98548907e-04, 7.56342197e-04, 3.88244342e-04, 4.69903258e-04,\n          3.46414483e-04, 6.78617274e-04, 5.07507822e-04, 3.25668487e-04,\n          4.67974693e-04, 5.16441360e-04, 9.63070954e-04, 4.91015031e-04,\n          4.71579930e-04, 3.62522551e-04, 5.67435985e-04, 4.55696863e-04,\n          5.08786819e-04, 5.34588587e-04, 4.57614369e-04, 2.54326034e-04,\n          1.22212863e-03, 1.27130374e-03, 5.12513914e-04, 4.93224419e-04,\n          3.13963799e-04, 4.77667141e-04, 5.40889043e-04, 7.87468336e-04,\n          5.14808227e-04, 5.87434450e-04, 3.70047201e-04, 3.96785763e-04,\n          7.22218538e-04, 6.54644973e-04, 5.12938190e-04, 2.90435099e-04,\n          7.93547195e-04, 4.21695382e-04, 3.66726366e-04, 6.32536947e-04,\n          3.14750505e-04, 4.82374278e-04, 2.58451037e-04, 5.11752267e-04,\n          9.94232716e-04, 4.06471605e-04, 4.81839379e-04, 4.64336015e-04,\n          8.41291971e-04, 8.89425864e-04, 5.57013438e-04, 5.86111797e-04,\n          3.82182479e-04, 3.89354769e-04, 1.17052055e-03, 4.77919646e-04,\n          6.73934293e-04, 1.15643535e-03, 4.19407181e-04, 5.83894900e-04,\n          5.98695886e-04, 6.00461848e-04, 4.25051723e-04, 7.72379397e-04,\n          6.93303300e-04, 5.02367038e-04, 4.51900618e-04, 3.19532963e-04,\n          2.65470822e-04, 3.06335452e-04, 4.39561118e-04, 7.11122353e-04,\n          4.99922025e-04, 4.71438922e-04, 5.41748654e-04, 5.56020415e-04,\n          4.53687477e-04, 5.22577204e-04, 6.43050589e-04, 5.52333135e-04,\n          3.15936166e-04, 8.88685172e-04, 3.90433153e-04, 5.89014497e-04,\n          4.44937585e-04, 8.35647399e-04, 4.18182026e-04, 3.33947566e-04,\n          6.09871931e-04, 7.22716504e-04, 5.03453310e-04, 4.04790655e-04,\n          5.49314544e-04, 6.78310927e-04, 6.08646311e-04, 6.04703091e-04,\n          5.01407834e-04, 7.79045746e-04, 6.42245752e-04, 8.74496298e-04,\n          4.13110713e-04, 6.18469785e-04, 5.01503411e-04, 5.91592863e-04,\n          6.55211974e-04, 5.15657826e-04, 3.66489607e-04, 6.68231864e-04,\n          5.20856003e-04, 5.61858527e-04, 7.89013575e-04, 4.69333987e-04,\n          4.92785824e-04, 6.23099739e-04, 4.99203394e-04, 6.65291795e-04,\n          5.22478949e-04, 6.69109577e-04, 6.26844296e-04, 5.54285536e-04,\n          4.29339067e-04, 7.97024579e-04, 4.73816996e-04, 8.44248396e-04,\n          5.08516910e-04, 4.69930499e-04, 4.59201576e-04, 5.57637948e-04,\n          5.97152684e-04, 1.49639382e-04, 5.76485123e-04, 4.66568483e-04,\n          5.70274540e-04, 8.87612579e-04, 5.14837913e-04, 7.65484525e-04,\n          7.46895152e-04, 3.55813856e-04, 5.85816510e-04, 8.12630227e-04,\n          5.39034372e-04, 4.27939463e-04, 8.85748246e-04, 3.27004906e-04,\n          3.55047785e-04, 5.26151969e-04, 5.61344321e-04, 5.52547979e-04,\n          4.37083276e-04, 6.15852245e-04, 4.09701897e-04, 1.37564537e-04,\n          6.12810778e-04, 9.49692097e-04, 3.89407534e-04, 7.28262938e-04,\n          4.29382868e-04, 3.65295506e-04, 5.39921282e-04, 6.03209483e-04,\n          4.60453128e-04, 3.35818127e-04, 5.67939074e-04, 5.84079011e-04,\n          4.95299522e-04, 6.07767142e-04, 3.50021233e-04, 4.62019234e-04,\n          4.16404102e-04, 6.40689686e-04, 6.14616030e-04, 5.74013102e-04,\n          3.74312047e-04, 2.39444169e-04, 5.75538841e-04, 3.22670210e-04,\n          5.14098501e-04, 6.99706317e-04, 4.44607373e-04, 5.67803392e-04,\n          3.24623834e-04, 3.91034875e-04, 5.69318712e-04, 3.86648782e-04,\n          3.57735960e-04, 5.01739501e-04, 3.66172724e-04, 6.54072210e-04,\n          6.43719628e-04, 9.26969049e-04, 3.40386032e-04, 8.68084142e-04,\n          6.12203323e-04, 6.55366923e-04, 4.78507136e-04, 5.63595910e-04,\n          7.62171869e-04, 5.20440633e-04, 4.56199370e-04, 4.36962320e-04,\n          5.31597878e-04, 3.71402362e-04, 3.74984695e-04, 3.76518117e-04,\n          6.84923609e-04, 5.28018165e-04, 3.69455694e-04, 4.34528571e-04,\n          6.58352801e-04, 6.07874652e-04, 4.47420229e-04, 3.93030874e-04,\n          2.12318395e-04, 5.81086613e-04, 5.67483308e-04, 4.73362335e-04,\n          4.64914425e-04, 4.98547044e-04, 5.73087193e-04, 8.48411117e-04,\n          2.91858742e-04, 3.36180616e-04, 6.74983254e-04, 6.44927379e-04,\n          4.01783444e-04, 6.06401125e-04, 9.20561724e-04, 6.24034205e-04,\n          5.09760750e-04, 4.90349892e-04, 5.64679620e-04, 4.82584554e-04,\n          5.35712577e-04, 2.40688052e-04, 9.21510800e-05, 5.71093056e-04,\n          4.85173310e-04, 5.29025274e-04, 5.19438530e-04, 3.67362285e-04,\n          5.89597679e-04, 6.63115934e-04, 3.46693560e-04, 5.16395667e-04,\n          5.20592439e-04, 5.56973449e-04, 3.05324298e-04, 4.01156925e-04,\n          4.99305199e-04, 4.49155865e-04, 7.01351732e-04, 5.02135314e-04,\n          5.21470443e-04, 6.23399392e-04, 4.90603561e-04, 5.93155622e-04,\n          2.73657381e-04, 5.59047388e-04, 4.89757746e-04, 5.60910616e-04,\n          4.99759044e-04, 5.88152325e-04, 4.27100807e-04, 5.08471043e-04,\n          6.00433093e-04, 1.32942674e-04, 3.48178030e-04, 6.63070008e-04,\n          5.95041725e-04, 6.50583301e-04, 7.65235047e-04, 4.29501903e-04,\n          4.91891406e-04, 4.72757587e-04, 8.37830477e-04, 5.58619562e-04,\n          6.48405286e-04, 2.40049761e-04, 6.29106013e-04, 5.75983373e-04,\n          5.19058434e-04, 3.59129888e-04, 3.63529718e-04, 4.48673149e-04,\n          4.95106739e-04, 5.68220101e-04, 8.26504256e-04, 5.25639101e-04,\n          5.12318802e-04, 3.65223066e-04, 5.29608515e-04, 1.30834655e-04,\n          5.49072516e-04, 6.64614199e-04, 4.00076387e-04, 5.22596820e-04,\n          4.83960262e-04, 6.85291307e-04, 6.89902226e-04, 5.77003288e-04,\n          5.55933220e-04, 5.92641416e-04, 5.90745243e-04, 3.72398761e-04,\n          8.46779789e-04, 5.79332351e-04, 4.58195806e-04, 7.35795125e-04,\n          9.37250676e-04, 4.89922066e-04, 6.05086039e-04, 5.99339197e-04,\n          6.33547257e-04, 6.40049402e-04, 4.82446252e-04, 5.18838409e-04,\n          3.81589809e-04, 4.55638685e-04, 7.88409729e-04, 4.39461932e-04,\n          8.20214453e-04, 6.31945091e-04, 6.49866764e-04, 6.97657815e-04,\n          7.61619653e-04, 4.93923260e-04, 5.06329176e-04, 4.57534217e-04,\n          4.71232343e-04, 4.33625159e-04, 5.32583508e-04, 3.38979386e-04,\n          5.19804133e-04, 3.35871009e-04, 6.68914639e-04, 1.68315557e-04,\n          2.97397753e-04, 3.40791245e-04, 4.91912826e-04, 5.36863401e-04,\n          5.81564615e-04, 6.57877419e-04, 5.59198612e-04, 4.32876666e-04,\n          8.17174849e-04, 6.15370751e-04, 4.58350638e-04, 5.45414980e-04,\n          4.24558937e-04, 5.72120072e-04, 5.34683466e-04, 2.43954113e-04,\n          5.73650235e-04, 6.03159424e-04, 5.41280315e-04, 3.13409226e-04,\n          8.41672532e-04, 3.53915384e-04, 4.85148019e-04, 7.18178402e-04,\n          5.91330288e-04, 5.30481746e-04, 7.28881627e-04, 5.90141048e-04,\n          6.58117118e-04, 5.14827610e-04, 5.20640635e-04, 4.61547228e-04,\n          6.04425208e-04, 6.06418005e-04, 6.27386034e-04, 7.53638160e-04,\n          5.69123018e-04, 3.74789379e-04, 7.57556700e-04, 3.42211337e-04,\n          7.81922601e-04, 5.13720617e-04, 3.07810900e-04, 4.51149856e-04,\n          2.84618145e-04, 6.55172335e-04, 6.05346344e-04, 5.10937010e-04,\n          8.62810994e-04, 7.08328676e-04, 6.70828274e-04, 7.05636630e-04,\n          9.15507553e-04, 6.35802047e-04, 6.41835970e-04, 6.53213821e-04,\n          4.45733371e-04, 4.69670980e-04, 4.76424117e-04, 5.17714245e-04,\n          8.44737457e-04, 6.75002288e-04, 5.78400388e-04, 7.75820634e-04,\n          7.76221394e-04, 7.58018228e-04, 2.60722591e-04, 4.09017637e-04,\n          6.42948609e-04, 4.40861390e-04, 7.39670533e-04, 4.40913049e-04,\n          8.74834892e-04, 4.50629450e-04, 5.25893061e-04, 4.53246641e-04,\n          3.38245154e-04, 5.53114514e-04, 5.37294196e-04, 6.99010794e-04,\n          5.24160918e-04, 4.98808862e-04, 4.97154077e-04, 3.35189106e-04,\n          4.83770098e-04, 6.96079107e-04, 5.04175667e-04, 3.23708140e-04,\n          6.15262252e-04, 6.89419860e-04, 5.16211265e-04, 6.15347817e-04,\n          6.76970463e-04, 5.24601433e-04, 3.16827121e-04, 4.79175564e-04,\n          6.97504554e-04, 1.97481233e-04, 6.10544288e-04, 4.89388942e-04,\n          5.74716949e-04, 4.34793648e-04, 3.62613413e-04, 4.30738990e-04,\n          5.08294150e-04, 5.34105056e-04, 2.91640172e-04, 7.23988691e-04,\n          4.39439958e-04, 7.06905616e-04, 3.79841309e-04, 6.65652798e-04,\n          4.56735812e-04, 7.54437293e-04, 4.03883343e-04, 4.59451345e-04,\n          6.15090365e-04, 5.49623393e-04, 6.81399193e-04, 3.43661522e-04,\n          4.66253696e-04, 4.87509562e-04, 3.31216725e-04, 4.46627208e-04,\n          4.13059170e-04, 4.56631096e-04, 5.13994717e-04, 5.65843482e-04,\n          4.53349028e-04, 7.25051155e-04, 6.79586432e-04, 5.19070949e-04,\n          6.92760514e-04, 7.21670804e-04, 7.18858675e-04, 5.08901023e-04,\n          5.98245650e-04, 4.92106716e-04, 7.51098210e-04, 3.65411339e-04,\n          6.24448410e-04, 5.57525840e-04, 4.09399858e-04, 7.31727749e-04,\n          4.65149817e-04, 1.15626364e-03, 4.22699639e-04, 6.37984602e-04,\n          7.84373784e-04, 1.82282733e-04, 3.92979244e-04, 4.71706036e-04,\n          6.13487151e-04, 1.05250964e-03, 5.28455712e-04, 6.82601356e-04,\n          5.00500086e-04, 3.97371361e-04, 7.01962388e-04, 4.80062969e-04,\n          7.39660463e-04, 4.80181683e-04, 4.89029218e-04, 5.64973394e-04,\n          3.77613702e-04, 5.99552935e-04, 1.04040129e-03, 5.75481332e-04,\n          4.84500750e-04, 3.37178382e-04, 5.56554121e-04, 5.59673179e-04,\n          2.11579347e-04, 5.68824820e-04, 4.66305239e-04, 3.78328870e-04,\n          9.12569929e-04, 4.10956651e-04, 4.70994797e-04, 6.19156694e-04,\n          5.08412428e-04, 5.30973368e-04, 4.91620682e-04, 5.43000002e-04,\n          5.29010431e-04, 7.01571174e-04, 6.78291195e-04, 5.04311523e-04,\n          5.61198103e-04, 7.31599401e-04, 5.63862792e-04, 5.48439391e-04,\n          5.42341557e-04, 2.25814787e-04, 4.24650992e-04, 2.98837927e-04,\n          3.92503076e-04, 5.23013237e-04, 5.82592387e-04, 5.70904172e-04,\n          6.52435701e-04, 6.57464494e-04, 3.71425762e-04, 4.82584495e-04,\n          1.95566536e-04, 2.60430330e-04, 6.64886902e-04, 3.88152781e-04,\n          6.02558895e-04, 8.07017437e-04, 6.16628211e-04, 6.41515711e-04,\n          4.01913596e-04, 3.88386165e-04, 6.64340274e-04, 4.14356095e-04,\n          7.36744609e-04, 3.70544207e-04, 5.25114767e-04, 4.60870273e-04,\n          3.59247846e-04, 5.71882643e-04, 1.14532351e-03, 4.41525743e-04,\n          6.19970204e-04, 4.06383246e-04, 7.28984247e-04, 5.16002881e-04,\n          5.43393777e-04, 3.10980686e-04, 5.63093810e-04, 5.73355996e-04,\n          6.42988540e-04, 3.93356924e-04, 4.98985755e-04, 7.02426361e-04,\n          2.71426135e-04, 2.73238751e-04, 2.96784041e-04, 6.43112289e-04,\n          5.27908909e-04, 3.95572308e-04, 6.74908224e-04, 3.29012953e-04,\n          4.53818153e-04, 7.28229061e-04, 5.15157182e-04, 5.94956917e-04,\n          6.86132407e-04, 5.57291147e-04, 5.99549385e-04, 2.71693076e-04,\n          4.94659587e-04, 3.85353051e-04, 5.68318646e-04, 5.06291050e-04,\n          5.54656843e-04, 4.50504682e-04, 4.98824520e-04, 5.39229484e-04,\n          4.46240010e-04, 4.98614623e-04, 8.00227688e-04, 5.98119746e-04,\n          3.28742753e-04, 1.75025940e-04, 2.98525527e-04, 1.71668828e-04,\n          4.80299466e-04, 4.82953474e-04, 3.55323718e-04, 6.57171826e-04,\n          3.55785480e-04, 4.12049005e-04, 1.62189579e-04, 8.31185665e-04,\n          4.87572368e-04, 5.82872017e-04, 5.60510496e-04, 4.91278712e-04,\n          4.22703830e-04, 5.54138969e-04, 1.28888263e-04, 6.61730126e-04,\n          3.59917089e-04, 1.81388968e-04, 3.99246986e-04, 4.01681027e-04,\n          5.82294189e-04, 3.28456779e-04, 3.95218201e-04, 5.38568594e-04,\n          5.04408905e-04, 4.33426525e-04, 6.00196305e-04, 6.55118667e-04,\n          5.03323914e-04, 5.33503655e-04, 5.59813576e-04, 6.60358171e-04,\n          4.90396516e-04, 4.36177914e-04, 4.96120017e-04, 1.64578471e-03,\n          7.43237499e-04, 7.33353663e-04, 4.41933720e-04, 4.07410378e-04,\n          7.37539609e-04, 3.64062871e-04, 4.53886692e-04, 4.32637957e-04,\n          8.65617301e-04, 4.81266412e-04, 5.67225448e-04, 6.20868814e-04,\n          4.81798546e-04, 6.45709049e-04, 5.45528485e-04, 4.10601962e-04,\n          9.64914972e-04, 5.97230741e-04, 6.41799299e-04, 5.44930750e-04,\n          3.76796146e-04, 7.36095884e-04, 5.10829501e-04, 7.36373186e-04,\n          8.33707396e-04, 4.14921727e-04, 8.06995435e-04, 5.52683894e-04,\n          3.85173655e-04, 6.81284058e-04, 6.73413218e-04, 6.82981685e-04,\n          3.53055832e-04, 3.13223049e-04, 5.42674330e-04, 2.18273839e-04,\n          8.53454403e-04, 7.62783224e-04, 6.25566812e-04, 2.99806910e-04,\n          2.81431188e-04, 5.71311801e-04, 5.41334332e-04, 6.19968341e-04,\n          7.19265954e-04, 6.73166825e-04, 3.80194717e-04, 5.06581913e-04,\n          4.88696620e-04, 4.43021039e-04, 4.70052735e-04, 4.40169184e-04,\n          3.81387072e-04, 4.09933535e-04, 5.74368692e-04, 8.12464510e-04,\n          7.00327393e-04, 5.52180805e-04, 4.44936857e-04, 6.69621571e-04,\n          5.11006743e-04, 6.20118517e-04, 5.50633064e-04, 4.99326328e-04,\n          4.76114132e-04, 7.24210637e-04, 6.48553658e-04, 2.10952203e-04,\n          5.73079509e-04, 4.14852460e-04, 5.27689641e-04, 4.91658866e-04,\n          7.92250852e-04, 8.78374907e-04, 5.27910946e-04, 6.33935095e-04,\n          7.85529322e-04, 4.14917595e-04, 4.61231393e-04, 6.02339976e-04,\n          3.17149999e-04, 3.80700221e-04, 5.34696388e-04, 5.71577519e-04,\n          7.91799161e-04, 8.46447656e-04, 7.31430657e-04, 6.96317817e-04,\n          4.79622395e-04, 6.24468783e-04, 6.90088200e-04, 4.03083774e-04,\n          7.83575000e-04, 5.33049810e-04, 6.04258210e-04, 3.22356063e-04,\n          4.39838099e-04, 6.59952872e-04, 5.62899397e-04, 6.14987861e-04,\n          1.03437365e-03, 3.49016977e-04, 4.97163215e-04, 1.76503498e-04,\n          4.29727690e-04, 4.32865520e-04, 5.32459700e-04, 4.70166153e-04,\n          6.86124491e-04, 6.94103888e-04, 1.25409779e-03, 6.39347127e-04,\n          4.68265789e-04, 6.72158727e-04, 2.61006469e-04, 4.94074833e-04,\n          6.60264108e-04, 4.15048999e-04, 1.26294105e-03, 7.34263274e-04,\n          4.02145553e-04, 4.08257416e-04, 4.50028310e-04, 4.57043352e-04,\n          5.76566264e-04, 4.46450576e-04, 4.00962861e-04, 6.35490054e-04,\n          5.61766792e-04, 5.47793519e-04, 2.49971927e-04, 5.55671577e-04,\n          4.12415277e-04, 5.64816291e-04, 4.50486055e-04, 5.01990377e-04,\n          1.81638985e-04, 5.02541370e-04, 1.27677165e-04, 4.30464017e-04,\n          6.43898791e-04, 5.88357914e-04, 4.61226067e-04, 4.09730623e-04,\n          4.91833373e-04, 5.65475551e-04, 4.60039446e-04, 4.98987385e-04,\n          4.09480068e-04, 4.49191721e-04, 7.21478486e-04, 3.79137200e-04,\n          4.98640642e-04, 6.88874570e-04, 3.35686724e-04, 9.00438463e-04,\n          4.90211765e-04, 5.76348335e-04, 4.04466613e-04, 3.42814077e-04,\n          2.25014563e-04, 4.72203799e-04, 7.23225239e-04, 9.07259877e-04,\n          5.68027142e-04, 5.19808498e-04, 6.62149687e-04, 1.00890233e-03,\n          4.12613823e-04, 4.30778106e-04, 6.02847664e-04, 6.76389609e-04,\n          3.90010187e-04, 7.68014172e-04, 4.39989148e-04, 5.25964540e-04,\n          6.27311121e-04, 3.96618241e-04, 4.85124794e-04, 4.42127784e-04,\n          6.65868225e-04, 1.16550236e-03, 7.67195888e-04, 5.55022038e-04,\n          6.57607219e-04, 6.56835095e-04, 5.30202291e-04, 2.72558595e-04,\n          4.84912860e-04, 3.12751945e-04, 6.58361008e-04, 2.50224693e-04,\n          2.77738989e-04, 1.03072007e-03, 4.98186972e-04, 4.22633078e-04,\n          5.90846757e-04, 5.96157217e-04, 6.36611425e-04, 5.98196988e-04,\n          5.26221993e-04, 4.68387501e-04, 5.18368266e-04, 5.82538196e-04,\n          3.39475839e-04, 5.26715652e-04, 7.95661937e-04, 5.10405283e-04,\n          6.92963658e-04, 7.14426395e-04, 4.64123266e-04, 4.86008270e-04,\n          3.71676666e-04, 8.91068776e-04, 4.90929175e-04, 5.61078952e-04,\n          4.58248192e-04, 5.33109822e-04, 3.86159110e-04, 5.23819705e-04,\n          5.75003854e-04, 1.61523698e-03, 2.77665938e-04, 5.79768850e-04,\n          6.15263416e-04, 4.53453336e-04, 6.63174782e-04, 5.14539657e-04,\n          5.83713350e-04, 4.97478293e-04, 5.08826517e-04, 3.48227797e-04,\n          2.94201018e-04, 3.72143259e-04, 5.84281166e-04, 7.97540881e-04,\n          5.04212978e-04, 4.56414360e-04, 7.94298830e-04, 4.50805383e-04,\n          1.07855757e-03, 4.52113833e-04, 8.02760944e-04, 3.57847719e-04,\n          8.93574033e-04, 4.13744216e-04, 4.43974568e-04, 4.94157546e-04,\n          8.93618679e-04, 6.80446159e-04, 5.80619439e-04, 5.15450665e-04,\n          5.77822793e-04, 3.08700895e-04, 2.21661394e-04, 6.76197000e-04,\n          8.66939314e-04, 5.32235310e-04, 3.32207856e-04, 4.88143618e-04,\n          3.79918551e-04, 4.80712508e-04, 6.96623058e-04, 6.46935659e-04,\n          4.78715898e-04, 7.35112408e-04, 6.04407920e-04, 4.21219680e-04,\n          1.44804595e-03, 2.71895173e-04, 5.46465337e-04, 4.99182497e-04,\n          3.10762523e-04, 5.84504160e-04, 3.56870703e-04, 4.36665316e-04,\n          7.43288372e-04, 6.12445176e-04, 5.05161297e-04, 4.16370895e-04,\n          4.14180220e-04, 8.18272820e-04, 1.16780146e-04, 2.79138592e-04,\n          6.83034945e-04, 2.99540552e-04, 5.59374923e-04, 5.94197947e-04],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_project/Conv2D',\n  'index': 71,\n  'shape': array([160,   1,   1, 960], dtype=int32),\n  'shape_signature': array([160,   1,   1, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.02201495, 0.00734691, 0.02069533, 0.00767855, 0.00749382,\n          0.00880803, 0.00897234, 0.01214322, 0.01200343, 0.02194574,\n          0.01178725, 0.00893265, 0.01780978, 0.01081247, 0.00700927,\n          0.01040311, 0.01710539, 0.01498987, 0.01322059, 0.01589002,\n          0.01018582, 0.01198392, 0.00780401, 0.02286358, 0.00889801,\n          0.00661217, 0.00985152, 0.00702768, 0.01453932, 0.01737047,\n          0.01151487, 0.01183774, 0.01112607, 0.01217446, 0.00902287,\n          0.0122279 , 0.01327431, 0.02304408, 0.01494993, 0.01148752,\n          0.03616246, 0.01164398, 0.011619  , 0.02313967, 0.01152185,\n          0.01065635, 0.01430976, 0.01160263, 0.01075054, 0.00634705,\n          0.01119626, 0.00940551, 0.00923041, 0.01374329, 0.00950313,\n          0.00824729, 0.01408475, 0.01286846, 0.03160913, 0.01124095,\n          0.01303438, 0.00892399, 0.00924703, 0.00925769, 0.00973763,\n          0.01022386, 0.0085103 , 0.00893318, 0.00615906, 0.00735719,\n          0.0081452 , 0.01134764, 0.00825669, 0.01921386, 0.02112602,\n          0.01619107, 0.00879214, 0.01896242, 0.01025598, 0.00976978,\n          0.01106932, 0.01932373, 0.02177014, 0.01151376, 0.00717597,\n          0.02385738, 0.01230278, 0.00878117, 0.01038139, 0.01095632,\n          0.00914578, 0.01159151, 0.01018104, 0.00924812, 0.01051986,\n          0.00934863, 0.01265272, 0.01983961, 0.01683468, 0.00971722,\n          0.01451501, 0.01066926, 0.00969222, 0.01834031, 0.00842885,\n          0.01260982, 0.00995437, 0.02990381, 0.01569388, 0.01895257,\n          0.01330179, 0.01834144, 0.0153136 , 0.00856573, 0.00710393,\n          0.01051804, 0.01436767, 0.00739281, 0.01152638, 0.01639545,\n          0.01036766, 0.00898612, 0.00793361, 0.01170048, 0.0116357 ,\n          0.01277036, 0.01010716, 0.01967885, 0.01545689, 0.01246461,\n          0.01439392, 0.01112366, 0.01727548, 0.03811779, 0.01403472,\n          0.01020915, 0.01313828, 0.01466138, 0.01041169, 0.01272401,\n          0.00866329, 0.01545102, 0.00958872, 0.01187731, 0.01105245,\n          0.01041057, 0.00683435, 0.0082757 , 0.00993017, 0.01163205,\n          0.01106469, 0.00793264, 0.03597195, 0.01339479, 0.01274368,\n          0.00999004, 0.00880209, 0.02145465, 0.01477643, 0.02460082],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_expand/Conv2D',\n  'index': 72,\n  'shape': array([960,   1,   1, 160], dtype=int32),\n  'shape_signature': array([960,   1,   1, 160], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00047696, 0.00029216, 0.00032111, 0.00056928, 0.00039034,\n          0.00034866, 0.00024803, 0.00067439, 0.00025845, 0.00056879,\n          0.00050853, 0.00043269, 0.00042731, 0.00091401, 0.0009075 ,\n          0.00029225, 0.00035302, 0.0004362 , 0.00031573, 0.00050765,\n          0.00040707, 0.00031119, 0.00054097, 0.00051479, 0.00035628,\n          0.00034709, 0.00109259, 0.00022811, 0.00064374, 0.00048636,\n          0.00036888, 0.00032213, 0.00030677, 0.00025132, 0.00020673,\n          0.00059402, 0.00032769, 0.00061353, 0.00044637, 0.00028099,\n          0.00036878, 0.00014812, 0.00032812, 0.00034468, 0.00041198,\n          0.00037334, 0.00033087, 0.00052529, 0.00057599, 0.00026129,\n          0.00024897, 0.00036747, 0.00039625, 0.00029933, 0.00044695,\n          0.00017268, 0.00038588, 0.00025435, 0.00061274, 0.00041339,\n          0.00041469, 0.00042316, 0.00030907, 0.00039338, 0.0006162 ,\n          0.00035221, 0.00095176, 0.00071671, 0.00050132, 0.00047342,\n          0.00017429, 0.00066317, 0.00031715, 0.0006493 , 0.00056549,\n          0.00136083, 0.00054417, 0.00049409, 0.00100249, 0.00040191,\n          0.00050805, 0.00051608, 0.00026282, 0.00054417, 0.00064842,\n          0.0006539 , 0.00039517, 0.00090639, 0.00019522, 0.00047505,\n          0.00031127, 0.00050412, 0.00030727, 0.00054043, 0.0006325 ,\n          0.00068512, 0.00043   , 0.00028975, 0.00066891, 0.00027207,\n          0.00018302, 0.00053898, 0.00036078, 0.00061379, 0.0003386 ,\n          0.00042891, 0.00024888, 0.00027117, 0.00042818, 0.00034104,\n          0.00047034, 0.00047579, 0.00025708, 0.00020299, 0.00050184,\n          0.00060433, 0.00046268, 0.00028426, 0.0005427 , 0.00042709,\n          0.00044114, 0.00032451, 0.00023677, 0.00048884, 0.00059485,\n          0.00018613, 0.00048677, 0.00062594, 0.00048234, 0.0004871 ,\n          0.00044396, 0.00030953, 0.00028729, 0.00042381, 0.00053782,\n          0.00051896, 0.0004925 , 0.00032062, 0.00038879, 0.00034851,\n          0.00043607, 0.00063469, 0.00032358, 0.00051391, 0.00047523,\n          0.00031683, 0.00051848, 0.0003241 , 0.00056296, 0.00053341,\n          0.00050105, 0.00065231, 0.00052236, 0.0007596 , 0.0005685 ,\n          0.00029314, 0.00038099, 0.00036626, 0.00024981, 0.00044654,\n          0.00032775, 0.00071813, 0.00045773, 0.00028235, 0.00042092,\n          0.00032846, 0.00026849, 0.00028998, 0.00050605, 0.00041319,\n          0.00017267, 0.00060218, 0.0003379 , 0.00036693, 0.00053896,\n          0.0003558 , 0.00043402, 0.00047156, 0.00053651, 0.00050267,\n          0.00059359, 0.00047195, 0.00041113, 0.00041892, 0.00059233,\n          0.00048385, 0.00027533, 0.0006427 , 0.00048453, 0.00049073,\n          0.00036574, 0.00082378, 0.00063867, 0.00072983, 0.00072963,\n          0.00044397, 0.00046585, 0.00024147, 0.00031862, 0.0003956 ,\n          0.0002991 , 0.00067827, 0.00037643, 0.00032389, 0.0017104 ,\n          0.00030887, 0.00045311, 0.00061963, 0.00070418, 0.00025977,\n          0.00053207, 0.00023492, 0.0005199 , 0.0003987 , 0.00047931,\n          0.00046713, 0.00036452, 0.00078972, 0.00012313, 0.00027913,\n          0.00034021, 0.00045733, 0.0002866 , 0.00028453, 0.00044637,\n          0.00057482, 0.00026058, 0.00031603, 0.00034814, 0.00033812,\n          0.00027483, 0.00029109, 0.00047464, 0.00034072, 0.0003956 ,\n          0.00047339, 0.00043806, 0.00024123, 0.0003758 , 0.00028473,\n          0.0008497 , 0.00049793, 0.00069871, 0.00077975, 0.0003445 ,\n          0.00197226, 0.00050313, 0.00056623, 0.00041489, 0.00033097,\n          0.00025917, 0.00062258, 0.00054355, 0.00048306, 0.00040701,\n          0.00036419, 0.00050161, 0.00087579, 0.00020294, 0.00082971,\n          0.00035551, 0.00048026, 0.00057091, 0.00071065, 0.00086057,\n          0.00029337, 0.00028967, 0.00029789, 0.00060752, 0.00046806,\n          0.00036166, 0.00030686, 0.00084083, 0.00021196, 0.00049968,\n          0.00042414, 0.00044035, 0.0005782 , 0.0004182 , 0.00047842,\n          0.00032281, 0.00028356, 0.0004915 , 0.00040155, 0.00024444,\n          0.00040215, 0.00036528, 0.00058604, 0.0005013 , 0.00048702,\n          0.00071271, 0.00056183, 0.00050125, 0.00041668, 0.00033725,\n          0.00032368, 0.00026966, 0.00035986, 0.00072116, 0.00057289,\n          0.00096126, 0.00045361, 0.00048469, 0.00065556, 0.0005295 ,\n          0.0003289 , 0.00083965, 0.0001457 , 0.00029204, 0.00052158,\n          0.00085935, 0.00037649, 0.00040582, 0.00047417, 0.00035496,\n          0.00076933, 0.00027818, 0.00059213, 0.00050689, 0.00043925,\n          0.00056554, 0.0003838 , 0.00062443, 0.00034864, 0.00052775,\n          0.00028116, 0.00024846, 0.00053111, 0.00069961, 0.00026568,\n          0.00044292, 0.00042289, 0.00109146, 0.00119843, 0.00031682,\n          0.00041509, 0.00087412, 0.000222  , 0.00022851, 0.00037657,\n          0.00042124, 0.00033145, 0.00041796, 0.00037473, 0.00037523,\n          0.00029243, 0.00086146, 0.00035488, 0.0003618 , 0.00023518,\n          0.00062762, 0.00050295, 0.00055489, 0.0003211 , 0.00018629,\n          0.00026289, 0.00048994, 0.00034771, 0.00024139, 0.000574  ,\n          0.00055686, 0.00044232, 0.00032729, 0.00071377, 0.00040873,\n          0.00018492, 0.00091946, 0.00075015, 0.00124311, 0.00057049,\n          0.00038634, 0.00033596, 0.00027951, 0.0005044 , 0.00019577,\n          0.00047369, 0.00052745, 0.00037017, 0.00062894, 0.00042721,\n          0.00047798, 0.00036618, 0.00075644, 0.0004496 , 0.00061942,\n          0.00060822, 0.00038817, 0.00064253, 0.00062888, 0.00054553,\n          0.00068623, 0.00031622, 0.00055309, 0.00066302, 0.00046859,\n          0.00041998, 0.0003445 , 0.00054518, 0.00062127, 0.00071454,\n          0.00052798, 0.00032958, 0.00047933, 0.00164195, 0.00029696,\n          0.00062176, 0.00054459, 0.00041862, 0.00033195, 0.00037986,\n          0.0004006 , 0.00090866, 0.0002104 , 0.00032578, 0.00045181,\n          0.00050075, 0.00034447, 0.00040693, 0.00029658, 0.00067908,\n          0.00054907, 0.00060521, 0.00047699, 0.00046289, 0.00049861,\n          0.00025817, 0.00070923, 0.00030737, 0.00071267, 0.00031523,\n          0.00026893, 0.00054599, 0.00046501, 0.00012855, 0.00032293,\n          0.00033526, 0.00054825, 0.00028698, 0.00055757, 0.00044458,\n          0.00050578, 0.00050599, 0.00042974, 0.00030874, 0.00032899,\n          0.00049951, 0.00036016, 0.00047336, 0.00030932, 0.00068878,\n          0.00019   , 0.00046317, 0.00087456, 0.00063029, 0.00084012,\n          0.0002545 , 0.00040251, 0.00025562, 0.00057737, 0.00017974,\n          0.00033187, 0.00036513, 0.0007047 , 0.00084655, 0.000298  ,\n          0.0002389 , 0.0003469 , 0.00040869, 0.00019809, 0.00049018,\n          0.00020698, 0.00029126, 0.00043373, 0.00061985, 0.00025355,\n          0.00054129, 0.00044572, 0.00025148, 0.00043074, 0.00042859,\n          0.00051513, 0.0005369 , 0.00066945, 0.00056237, 0.00047319,\n          0.00069078, 0.00062063, 0.00034677, 0.00050848, 0.00040801,\n          0.00047742, 0.00021439, 0.00067606, 0.00054956, 0.00057758,\n          0.00207144, 0.0003601 , 0.00060715, 0.00033382, 0.00052876,\n          0.00054544, 0.00037461, 0.00063097, 0.00062441, 0.00023983,\n          0.00026035, 0.00038227, 0.00064199, 0.00033608, 0.00035795,\n          0.00089113, 0.00043011, 0.00040616, 0.00038859, 0.00053725,\n          0.00059449, 0.0002772 , 0.00023611, 0.00040068, 0.00030486,\n          0.00038671, 0.00062626, 0.0006249 , 0.00035174, 0.00062451,\n          0.00026858, 0.00048786, 0.00051923, 0.00024615, 0.00079111,\n          0.00053919, 0.00038921, 0.00025276, 0.00023569, 0.00025593,\n          0.0005522 , 0.00083695, 0.00063111, 0.00039995, 0.00068532,\n          0.00036404, 0.00028576, 0.00039196, 0.00060755, 0.00033373,\n          0.00028134, 0.00059179, 0.00045692, 0.00016704, 0.00087776,\n          0.0005823 , 0.00036906, 0.00056335, 0.00029207, 0.0005873 ,\n          0.00022277, 0.0004171 , 0.00057215, 0.00048879, 0.00031518,\n          0.00024828, 0.00058301, 0.00030295, 0.00046687, 0.00024101,\n          0.00038468, 0.00028171, 0.0005953 , 0.00039967, 0.0005122 ,\n          0.00021116, 0.00046007, 0.00032682, 0.00039137, 0.00065331,\n          0.000483  , 0.00024419, 0.00040425, 0.00051939, 0.00040693,\n          0.0003509 , 0.00050257, 0.00036781, 0.00063014, 0.00054645,\n          0.00063694, 0.00033834, 0.00022371, 0.0004519 , 0.00030989,\n          0.00049425, 0.00075002, 0.00027419, 0.00025428, 0.00039817,\n          0.00059799, 0.00027049, 0.00039716, 0.00040027, 0.00062276,\n          0.00023815, 0.00028568, 0.00059491, 0.00028163, 0.00044327,\n          0.0004938 , 0.00044081, 0.000462  , 0.00035106, 0.00035405,\n          0.00044832, 0.00022495, 0.00029823, 0.00025424, 0.00068226,\n          0.00041414, 0.00045067, 0.00055127, 0.0002746 , 0.00012375,\n          0.00056637, 0.00041744, 0.00062648, 0.00055943, 0.00049039,\n          0.0004585 , 0.00044923, 0.00058805, 0.00036361, 0.00040536,\n          0.0004853 , 0.00031794, 0.00060559, 0.00048864, 0.00021695,\n          0.00096018, 0.00034273, 0.00029235, 0.00028569, 0.00032347,\n          0.00025714, 0.00078264, 0.00050923, 0.00038384, 0.00064817,\n          0.0002818 , 0.00047812, 0.00028302, 0.00024375, 0.00042434,\n          0.00054928, 0.00044187, 0.00053141, 0.00041037, 0.00044819,\n          0.00061699, 0.0002867 , 0.00032724, 0.00047989, 0.00035617,\n          0.00021414, 0.00052096, 0.00013915, 0.00042696, 0.00064471,\n          0.00076334, 0.00048652, 0.00049419, 0.00059336, 0.00021416,\n          0.00051829, 0.00068737, 0.00023545, 0.00059208, 0.00046147,\n          0.00031787, 0.00042267, 0.00025081, 0.00016505, 0.00045039,\n          0.00019568, 0.00039373, 0.00064236, 0.00042295, 0.0003831 ,\n          0.00045686, 0.00040892, 0.00062513, 0.00071477, 0.00028022,\n          0.00110147, 0.00043279, 0.00078385, 0.00052203, 0.00025269,\n          0.00068143, 0.00057396, 0.00017665, 0.00056064, 0.00042262,\n          0.00049994, 0.00039078, 0.00078267, 0.00091351, 0.00050526,\n          0.00025461, 0.00034344, 0.00050666, 0.00065878, 0.00048848,\n          0.00059188, 0.00036485, 0.00051063, 0.00054436, 0.0005419 ,\n          0.00050227, 0.00119623, 0.00056721, 0.00036605, 0.00034824,\n          0.00040837, 0.00019602, 0.00082125, 0.0004903 , 0.0002345 ,\n          0.00033242, 0.00024142, 0.0004173 , 0.00056916, 0.00046777,\n          0.00048456, 0.00033577, 0.00030849, 0.00069397, 0.0005684 ,\n          0.00068033, 0.00049552, 0.0002692 , 0.00036135, 0.00039735,\n          0.0004188 , 0.00050712, 0.00046041, 0.00045858, 0.0003606 ,\n          0.000614  , 0.00056741, 0.00028256, 0.00020159, 0.00034114,\n          0.00045677, 0.00071684, 0.00020166, 0.0004748 , 0.00025127,\n          0.00063085, 0.00031804, 0.00063067, 0.00037424, 0.00049202,\n          0.0004549 , 0.0004018 , 0.00048248, 0.00032176, 0.00039131,\n          0.00032262, 0.00039366, 0.00057065, 0.00037413, 0.0003903 ,\n          0.00042144, 0.00054301, 0.00036799, 0.0006223 , 0.00034606,\n          0.00046794, 0.00056136, 0.00057159, 0.0003942 , 0.00044558,\n          0.0002772 , 0.00024445, 0.00083415, 0.00075371, 0.00061453,\n          0.00037501, 0.00044898, 0.00062891, 0.00042844, 0.00062207,\n          0.0005706 , 0.00046711, 0.00032473, 0.00048419, 0.00052786,\n          0.00034338, 0.00051488, 0.00066676, 0.00054166, 0.0003444 ,\n          0.00059237, 0.00027038, 0.00037762, 0.00046616, 0.00053416,\n          0.00018851, 0.00046423, 0.000335  , 0.00057517, 0.00041536,\n          0.00041486, 0.0006485 , 0.00030933, 0.00065769, 0.00022536,\n          0.00033028, 0.00037241, 0.00025441, 0.00059202, 0.00021117,\n          0.00037195, 0.00074936, 0.00071696, 0.00090851, 0.00022874,\n          0.0002474 , 0.00017511, 0.00023798, 0.00068461, 0.00053366,\n          0.00083638, 0.00063577, 0.00106547, 0.00033606, 0.00032054,\n          0.0003811 , 0.00040215, 0.00045079, 0.00048835, 0.00048934,\n          0.00054446, 0.00028357, 0.00054394, 0.00021738, 0.00038137,\n          0.0008465 , 0.00045939, 0.00033891, 0.00074423, 0.00046878,\n          0.00099091, 0.00027064, 0.00054902, 0.00053507, 0.00037444,\n          0.00094111, 0.00049338, 0.00057244, 0.00029644, 0.00063685,\n          0.00032802, 0.00034134, 0.00069785, 0.00047796, 0.00044442,\n          0.00018431, 0.00051212, 0.00059525, 0.00084603, 0.00028553,\n          0.00031196, 0.00020331, 0.00034549, 0.00036232, 0.00051009,\n          0.00036342, 0.00049127, 0.00021751, 0.0007645 , 0.00026349,\n          0.00052808, 0.00013678, 0.0004853 , 0.00032514, 0.00046012,\n          0.0002708 , 0.00050774, 0.00049811, 0.00055165, 0.00040731,\n          0.00030351, 0.000418  , 0.00031335, 0.00054069, 0.0005385 ,\n          0.00021026, 0.00042053, 0.00032718, 0.00052769, 0.00022286,\n          0.0007837 , 0.00064461, 0.00023569, 0.0007314 , 0.00064029,\n          0.00030596, 0.00040139, 0.00042574, 0.00049873, 0.00035862,\n          0.0005268 , 0.00030952, 0.00063007, 0.0004309 , 0.00055224,\n          0.0003529 , 0.00129926, 0.00035021, 0.00039085, 0.00066282,\n          0.00026943, 0.00054992, 0.00040997, 0.00027576, 0.00069098,\n          0.00059836, 0.00025351, 0.00043308, 0.00030585, 0.00034682,\n          0.00035041, 0.00130312, 0.00069627, 0.00064164, 0.00052297,\n          0.00051672, 0.0004955 , 0.0004633 , 0.00068464, 0.00027747,\n          0.00058221, 0.00040365, 0.00038034, 0.00021813, 0.00058615,\n          0.0005353 , 0.00080139, 0.00048188, 0.00040403, 0.00043882,\n          0.00033555, 0.00073413, 0.00052855, 0.00038675, 0.00041278,\n          0.00048167, 0.00080963, 0.00032124, 0.0002531 , 0.0004762 ],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_project/Conv2D',\n  'index': 73,\n  'shape': array([320,   1,   1, 960], dtype=int32),\n  'shape_signature': array([320,   1,   1, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.0058283 , 0.00366728, 0.00324192, 0.00307881, 0.00358756,\n          0.00280317, 0.0036778 , 0.00337948, 0.00350474, 0.004878  ,\n          0.00348002, 0.00389392, 0.00290244, 0.00361577, 0.00381024,\n          0.00379038, 0.0031673 , 0.00260788, 0.0030953 , 0.00417692,\n          0.00373275, 0.00329561, 0.00411714, 0.00418448, 0.00297649,\n          0.00272587, 0.00338591, 0.00352523, 0.00334472, 0.00360496,\n          0.00298061, 0.00330295, 0.00330644, 0.00391408, 0.00405773,\n          0.00343667, 0.00375926, 0.00414574, 0.00284144, 0.00378192,\n          0.00440988, 0.00334625, 0.00400622, 0.00448307, 0.00352477,\n          0.00344139, 0.0035603 , 0.00416784, 0.0030502 , 0.00388127,\n          0.00296917, 0.00318087, 0.0029902 , 0.00340975, 0.00338421,\n          0.00427136, 0.00363407, 0.00404754, 0.00381068, 0.00377133,\n          0.00254462, 0.00311972, 0.00259155, 0.0037348 , 0.0033194 ,\n          0.00337983, 0.0035573 , 0.00303611, 0.00452166, 0.00362382,\n          0.00282379, 0.00297952, 0.00303482, 0.00414685, 0.00419287,\n          0.00332545, 0.00369542, 0.00378436, 0.00374524, 0.00359552,\n          0.00430377, 0.00320981, 0.00361022, 0.00376541, 0.00352181,\n          0.00485485, 0.00286756, 0.00282116, 0.00350731, 0.00397998,\n          0.00384229, 0.00323495, 0.00387813, 0.00366686, 0.00357897,\n          0.00330786, 0.0034684 , 0.00390382, 0.00338173, 0.00468057,\n          0.0046594 , 0.0032418 , 0.002827  , 0.00426573, 0.00490822,\n          0.00347407, 0.00364011, 0.0038504 , 0.0027578 , 0.00333993,\n          0.00444819, 0.00329597, 0.003046  , 0.00391921, 0.00426566,\n          0.00436481, 0.00468331, 0.00446849, 0.00352642, 0.0043714 ,\n          0.00319468, 0.00355798, 0.00311727, 0.00352872, 0.00260725,\n          0.00519643, 0.00347792, 0.00333168, 0.00561607, 0.00348322,\n          0.00300026, 0.00338955, 0.00313105, 0.00320823, 0.00238384,\n          0.00414893, 0.00325457, 0.00327577, 0.00381801, 0.00359022,\n          0.00436498, 0.00312219, 0.00364409, 0.00296604, 0.00303707,\n          0.00359046, 0.00323618, 0.00353186, 0.00354383, 0.0029868 ,\n          0.00337919, 0.0032717 , 0.00348264, 0.00285485, 0.00350425,\n          0.00343281, 0.00425257, 0.00312672, 0.00311264, 0.00328087,\n          0.00386601, 0.00323988, 0.00279424, 0.00328394, 0.00357599,\n          0.0036504 , 0.00388357, 0.00341732, 0.00420926, 0.00351909,\n          0.00324929, 0.00401985, 0.00362121, 0.00337499, 0.00337567,\n          0.00384223, 0.00349546, 0.00266185, 0.00352927, 0.00369851,\n          0.00331547, 0.00363102, 0.00364341, 0.00341041, 0.00281943,\n          0.00414895, 0.00420417, 0.00287397, 0.00328472, 0.00245895,\n          0.00312454, 0.00407488, 0.0032399 , 0.0030007 , 0.00422612,\n          0.0026231 , 0.00353424, 0.00343403, 0.00392446, 0.00440864,\n          0.00426005, 0.00394974, 0.00455629, 0.00409611, 0.00290576,\n          0.00391447, 0.00268366, 0.00317019, 0.00395236, 0.00386251,\n          0.00379548, 0.00346952, 0.00355246, 0.00331613, 0.00458008,\n          0.00350645, 0.00345314, 0.00376698, 0.00351781, 0.00419947,\n          0.00316506, 0.00411523, 0.00238404, 0.00386103, 0.00327246,\n          0.00352834, 0.00322461, 0.00381534, 0.00368465, 0.00398303,\n          0.00330845, 0.00354581, 0.00363903, 0.00385218, 0.00346609,\n          0.0039712 , 0.00490608, 0.00326235, 0.00339123, 0.00413469,\n          0.00455827, 0.00394376, 0.00441934, 0.00411081, 0.00383675,\n          0.00264293, 0.00403375, 0.00424641, 0.00374268, 0.00318069,\n          0.00404189, 0.00308513, 0.00393811, 0.00302946, 0.00267785,\n          0.00399727, 0.00259935, 0.00378263, 0.00290853, 0.00304008,\n          0.00316479, 0.00297627, 0.00374535, 0.00368559, 0.00381574,\n          0.0033453 , 0.00412967, 0.00371506, 0.00363915, 0.00392448,\n          0.00400845, 0.00329851, 0.00379965, 0.00348585, 0.00462081,\n          0.00383445, 0.00379277, 0.00332093, 0.00453395, 0.00318115,\n          0.00314395, 0.00326119, 0.00371292, 0.00323067, 0.00370321,\n          0.00368836, 0.00399735, 0.00317052, 0.00333868, 0.0035502 ,\n          0.00334555, 0.00379317, 0.0029237 , 0.00261788, 0.00382241,\n          0.00402416, 0.00390116, 0.00360938, 0.00419897, 0.00366993,\n          0.00437465, 0.0036134 , 0.00315746, 0.00260144, 0.00349996,\n          0.00320573, 0.00295404, 0.00246741, 0.0122762 , 0.0034817 ,\n          0.00397841, 0.00339374, 0.00348639, 0.0038897 , 0.00303934,\n          0.00315169, 0.0026416 , 0.00379701, 0.00277982, 0.00349082],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/Conv_1/Conv2D',\n  'index': 74,\n  'shape': array([1280,    1,    1,  320], dtype=int32),\n  'shape_signature': array([1280,    1,    1,  320], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00442078, 0.00312751, 0.00277058, ..., 0.00337631, 0.00351711,\n          0.00325549], dtype=float32),\n   'zero_points': array([0, 0, 0, ..., 0, 0, 0], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/expanded_conv_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_depthwise/depthwise;mobilenetv2_1.00_224/block_5_project/Conv2D',\n  'index': 75,\n  'shape': array([ 1,  3,  3, 32], dtype=int32),\n  'shape_signature': array([ 1,  3,  3, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project/Conv2D',\n  'index': 76,\n  'shape': array([16], dtype=int32),\n  'shape_signature': array([16], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_depthwise/depthwise;mobilenetv2_1.00_224/block_12_project/Conv2D',\n  'index': 77,\n  'shape': array([ 1,  3,  3, 96], dtype=int32),\n  'shape_signature': array([ 1,  3,  3, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_project/Conv2D;mobilenetv2_1.00_224/block_1_project/Conv2D',\n  'index': 78,\n  'shape': array([24], dtype=int32),\n  'shape_signature': array([24], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_depthwise/depthwise;mobilenetv2_1.00_224/block_3_depthwise/depthwise',\n  'index': 79,\n  'shape': array([  1,   3,   3, 144], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00703944, 0.02208933, 0.00877747, 0.01557459, 0.00680251,\n          0.01549216, 0.01344799, 0.03070085, 0.00722542, 0.00629034,\n          0.00662081, 0.01723231, 0.01275923, 0.00541622, 0.01952226,\n          0.01523379, 0.00791337, 0.00614407, 0.00906675, 0.02708817,\n          0.012445  , 0.01064352, 0.01110081, 0.00691291, 0.00825787,\n          0.01515553, 0.00349413, 0.00978491, 0.00637058, 0.00272305,\n          0.01207856, 0.01688474, 0.03631399, 0.00243321, 0.00920113,\n          0.01916846, 0.01815416, 0.00210151, 0.00376199, 0.00710637,\n          0.05507741, 0.00226187, 0.0091611 , 0.02488255, 0.00753443,\n          0.0106162 , 0.00406441, 0.00441256, 0.00987163, 0.00933722,\n          0.00596015, 0.00863907, 0.00893973, 0.00988305, 0.00634109,\n          0.01889369, 0.00799672, 0.00760282, 0.00513688, 0.00548368,\n          0.01495679, 0.00485733, 0.00581782, 0.00599863, 0.01442248,\n          0.01178356, 0.00917973, 0.00773965, 0.01199662, 0.00642204,\n          0.02514421, 0.00556859, 0.01027785, 0.00956557, 0.00284428,\n          0.02974026, 0.0179464 , 0.00800714, 0.03846782, 0.00562836,\n          0.00689293, 0.00458615, 0.01088385, 0.00599042, 0.08454736,\n          0.00848188, 0.00778315, 0.00801104, 0.00810894, 0.00582627,\n          0.00922354, 0.0063712 , 0.01259591, 0.02616363, 0.01125827,\n          0.005426  , 0.0105181 , 0.01610513, 0.02594719, 0.00777909,\n          0.00459296, 0.00977417, 0.00891635, 0.01095415, 0.0114083 ,\n          0.00542466, 0.0026598 , 0.01233535, 0.0063948 , 0.00601511,\n          0.00919991, 0.01174082, 0.00517   , 0.00451114, 0.00470322,\n          0.01690367, 0.0051641 , 0.01633363, 0.00846481, 0.00312654,\n          0.00726669, 0.01533064, 0.01337733, 0.00522882, 0.01957345,\n          0.00841743, 0.0118685 , 0.00696132, 0.02096634, 0.00862414,\n          0.2715985 , 0.01701213, 0.00557918, 0.03723642, 0.0058548 ,\n          0.00235345, 0.00864152, 0.00303049, 0.00683473, 0.00704357,\n          0.00231167, 0.00841001, 0.00232553, 0.009738  ], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_project/Conv2D',\n  'index': 80,\n  'shape': array([24], dtype=int32),\n  'shape_signature': array([24], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise/depthwise',\n  'index': 81,\n  'shape': array([  1,   3,   3, 144], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00469357, 0.00619575, 0.00374959, 0.00350478, 0.00281412,\n          0.00418805, 0.00309061, 0.00440527, 0.00251458, 0.00168034,\n          0.00167116, 0.00576359, 0.0030484 , 0.00710295, 0.0056803 ,\n          0.01052825, 0.00442883, 0.00362512, 0.00256753, 0.01463021,\n          0.00885822, 0.00421344, 0.00492655, 0.00589543, 0.00191731,\n          0.00759711, 0.00664777, 0.00257304, 0.00314658, 0.01316578,\n          0.00453851, 0.0040409 , 0.00885162, 0.00244023, 0.00354547,\n          0.00546796, 0.00369314, 0.00151882, 0.00464233, 0.00418028,\n          0.00628807, 0.01321945, 0.00424538, 0.00150312, 0.00275422,\n          0.0034558 , 0.00216611, 0.00327919, 0.00303044, 0.00671322,\n          0.00354171, 0.00182255, 0.00324488, 0.00396322, 0.00845323,\n          0.00374289, 0.00420431, 0.00499866, 0.00414411, 0.00320931,\n          0.00685068, 0.00370509, 0.00194615, 0.00358223, 0.00866421,\n          0.00290277, 0.0041882 , 0.00187076, 0.00164714, 0.00206402,\n          0.00519582, 0.00509017, 0.00319762, 0.00214339, 0.00437364,\n          0.00256665, 0.00371081, 0.00398275, 0.00327592, 0.0063838 ,\n          0.00356668, 0.0034291 , 0.00300574, 0.00603919, 0.00718287,\n          0.00267213, 0.00207777, 0.00336355, 0.00499115, 0.00631928,\n          0.00233603, 0.00481793, 0.00154416, 0.0075287 , 0.00604006,\n          0.0049564 , 0.00335218, 0.00527249, 0.00408718, 0.00348692,\n          0.00275379, 0.00385596, 0.00382565, 0.00579327, 0.00195319,\n          0.00406579, 0.00370567, 0.00319787, 0.00378178, 0.01131074,\n          0.00404749, 0.00398958, 0.0058002 , 0.00255575, 0.01973943,\n          0.00219485, 0.01096717, 0.00586279, 0.00865397, 0.00791778,\n          0.003171  , 0.00626433, 0.00258475, 0.0014881 , 0.0060698 ,\n          0.01055775, 0.00322948, 0.00181686, 0.01119712, 0.00516117,\n          0.00187   , 0.00455198, 0.01567527, 0.00290405, 0.00281608,\n          0.00144705, 0.00595396, 0.00656054, 0.00510278, 0.00387325,\n          0.00404192, 0.0061316 , 0.00404979, 0.00355808], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D;mobilenetv2_1.00_224/block_3_project/Conv2D',\n  'index': 82,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_4_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise/depthwise',\n  'index': 83,\n  'shape': array([  1,   3,   3, 192], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00715006, 0.00812535, 0.00459463, 0.00756578, 0.01420293,\n          0.00931612, 0.0099636 , 0.0282426 , 0.00657519, 0.0082178 ,\n          0.00828944, 0.00398512, 0.01027403, 0.00594774, 0.00742592,\n          0.01202787, 0.01321083, 0.00578749, 0.01420003, 0.01540744,\n          0.01581018, 0.01464013, 0.02082128, 0.02056701, 0.03418205,\n          0.00654128, 0.01706832, 0.00543887, 0.01284497, 0.00761254,\n          0.00934604, 0.00808412, 0.00478973, 0.00943088, 0.00717061,\n          0.0127391 , 0.00947356, 0.0087387 , 0.00790256, 0.00662346,\n          0.02810438, 0.00684851, 0.00738645, 0.02033546, 0.00934068,\n          0.00609978, 0.03656395, 0.0074869 , 0.01204856, 0.00588298,\n          0.00337832, 0.00919207, 0.01166223, 0.02521162, 0.01078446,\n          0.02299605, 0.01956462, 0.01177238, 0.01578118, 0.00636335,\n          0.00808723, 0.00464895, 0.00626945, 0.0130732 , 0.02206383,\n          0.01929629, 0.00970436, 0.00447084, 0.00962225, 0.02808685,\n          0.00882643, 0.0064862 , 0.00443771, 0.00733753, 0.00820483,\n          0.01354141, 0.01003173, 0.00503733, 0.0064979 , 0.02284201,\n          0.00870524, 0.00662342, 0.00798092, 0.01954003, 0.00292628,\n          0.00617338, 0.01916998, 0.00914182, 0.00814117, 0.01344659,\n          0.02988457, 0.01096635, 0.00830987, 0.02663791, 0.00547227,\n          0.00695339, 0.0069181 , 0.00871512, 0.01434665, 0.01294635,\n          0.01474936, 0.01380318, 0.01120608, 0.0062882 , 0.0031824 ,\n          0.00641598, 0.00360541, 0.00704163, 0.00882071, 0.01285668,\n          0.00634708, 0.00493138, 0.00664382, 0.00241595, 0.01993821,\n          0.00193268, 0.02016427, 0.00495785, 0.00550964, 0.00212395,\n          0.00868272, 0.00840639, 0.00929635, 0.01202978, 0.00627135,\n          0.00856928, 0.00852186, 0.0215446 , 0.00825361, 0.01043343,\n          0.03078658, 0.01633804, 0.00548452, 0.0090742 , 0.05977422,\n          0.02248172, 0.01465227, 0.00298535, 0.0295356 , 0.00662268,\n          0.00718272, 0.01458681, 0.0079784 , 0.00415738, 0.01441795,\n          0.01466846, 0.01017188, 0.00676951, 0.01911558, 0.00678468,\n          0.02216655, 0.01387733, 0.01383459, 0.02145158, 0.01057161,\n          0.00833577, 0.00691387, 0.01489839, 0.0072678 , 0.00883063,\n          0.01858123, 0.01372464, 0.00925202, 0.01536963, 0.00882763,\n          0.01116124, 0.01489049, 0.00657978, 0.01608459, 0.00412304,\n          0.01285653, 0.00444628, 0.01258152, 0.01207089, 0.01103388,\n          0.01728092, 0.02450257, 0.00855527, 0.00919949, 0.00820465,\n          0.01868815, 0.01049807, 0.01943984, 0.01463455, 0.0094278 ,\n          0.08168607, 0.00794754, 0.00814653, 0.0124915 , 0.00736643,\n          0.01214868, 0.00778089], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D;mobilenetv2_1.00_224/block_4_project/Conv2D',\n  'index': 84,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_depthwise/depthwise;mobilenetv2_1.00_224/block_6_depthwise/depthwise',\n  'index': 85,\n  'shape': array([  1,   3,   3, 192], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.007296  , 0.00667099, 0.01465669, 0.01324893, 0.03373145,\n          0.00692002, 0.02750794, 0.00991223, 0.01574573, 0.00778336,\n          0.00990046, 0.00847279, 0.01147847, 0.01243682, 0.01689361,\n          0.01122293, 0.00596302, 0.00819119, 0.01543793, 0.02704881,\n          0.01258167, 0.00416881, 0.0142988 , 0.0120491 , 0.00923241,\n          0.02465374, 0.01380283, 0.01478998, 0.00747176, 0.01550626,\n          0.03051376, 0.00920464, 0.00618284, 0.00630618, 0.02033216,\n          0.00450982, 0.01939184, 0.00836495, 0.00393054, 0.0161471 ,\n          0.01008132, 0.00918949, 0.01256887, 0.0056211 , 0.00857417,\n          0.00823707, 0.01577988, 0.0132466 , 0.00517078, 0.01340041,\n          0.01838229, 0.00938986, 0.00663366, 0.01022609, 0.00627739,\n          0.00812016, 0.02713687, 0.00802228, 0.01700526, 0.01570608,\n          0.01138605, 0.01904773, 0.00963309, 0.00665885, 0.00605896,\n          0.00360189, 0.01758086, 0.01107809, 0.01204786, 0.01821095,\n          0.02247492, 0.00392382, 0.01558065, 0.01121939, 0.00576946,\n          0.03738947, 0.01359687, 0.0028203 , 0.02198076, 0.00947582,\n          0.00778013, 0.00759102, 0.02533415, 0.00794009, 0.00854672,\n          0.01458856, 0.02050718, 0.00398096, 0.00512835, 0.01259664,\n          0.01519503, 0.00479174, 0.01623698, 0.01089715, 0.00906337,\n          0.01323007, 0.01182408, 0.00978648, 0.01767164, 0.0059063 ,\n          0.00516378, 0.0021331 , 0.00459539, 0.00845692, 0.01900717,\n          0.01283065, 0.00803435, 0.01746925, 0.00398785, 0.01890982,\n          0.02005042, 0.04231401, 0.00997844, 0.01796151, 0.01180416,\n          0.003921  , 0.01712603, 0.00773769, 0.00866241, 0.0093143 ,\n          0.04295254, 0.00260827, 0.02255719, 0.00458235, 0.00320988,\n          0.00971593, 0.02557365, 0.01177959, 0.01118351, 0.01927523,\n          0.00959276, 0.01594577, 0.01145211, 0.00344709, 0.01108454,\n          0.0118874 , 0.01680306, 0.01542022, 0.01006174, 0.01325681,\n          0.00433191, 0.01709209, 0.01290777, 0.00606477, 0.00693132,\n          0.01430585, 0.01326594, 0.0084053 , 0.03078572, 0.0073205 ,\n          0.0144513 , 0.00720061, 0.01629175, 0.01039357, 0.01592991,\n          0.0255987 , 0.00470062, 0.01389114, 0.01029884, 0.00978074,\n          0.01656436, 0.01414068, 0.01227738, 0.05699269, 0.00375944,\n          0.01581646, 0.01024813, 0.00756889, 0.01478795, 0.10850342,\n          0.00755591, 0.00791986, 0.01839324, 0.02334869, 0.00950944,\n          0.00490635, 0.00719689, 0.0332274 , 0.00984813, 0.00995366,\n          0.0092018 , 0.00725213, 0.00973296, 0.01091476, 0.01484339,\n          0.00879448, 0.0190607 , 0.01511109, 0.01390428, 0.00578789,\n          0.01778397, 0.01310071], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D',\n  'index': 86,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise',\n  'index': 87,\n  'shape': array([  1,   3,   3, 192], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00415438, 0.00882143, 0.00341659, 0.00432555, 0.00307053,\n          0.00713177, 0.00437397, 0.00429867, 0.00383254, 0.00281788,\n          0.00256794, 0.00883303, 0.00484051, 0.00215455, 0.00373972,\n          0.00220884, 0.0033562 , 0.00331585, 0.00170273, 0.00280684,\n          0.00192667, 0.00317876, 0.0041542 , 0.00540347, 0.00285713,\n          0.00314218, 0.00377016, 0.00175818, 0.00172522, 0.00224589,\n          0.00374127, 0.0045258 , 0.00502321, 0.00401473, 0.00435912,\n          0.00511889, 0.00726997, 0.00644976, 0.00202926, 0.00550931,\n          0.00393584, 0.00346309, 0.00323052, 0.00399299, 0.00448404,\n          0.0050727 , 0.00665075, 0.00513483, 0.0030263 , 0.00199524,\n          0.00361796, 0.00390255, 0.00639355, 0.00267935, 0.00336614,\n          0.00253171, 0.00498521, 0.00398786, 0.0031852 , 0.00481026,\n          0.00236116, 0.0028093 , 0.01012632, 0.00347232, 0.00215425,\n          0.00186506, 0.00526826, 0.00281163, 0.0035032 , 0.0033514 ,\n          0.00313146, 0.00977304, 0.00384524, 0.00299606, 0.00275027,\n          0.00287183, 0.00478594, 0.00276965, 0.00460102, 0.00182255,\n          0.00687829, 0.00415489, 0.00251541, 0.00411765, 0.00337743,\n          0.00571635, 0.0018493 , 0.003628  , 0.00270656, 0.00295649,\n          0.00278952, 0.00350457, 0.00595755, 0.0027383 , 0.00563985,\n          0.00136054, 0.00182659, 0.00376748, 0.00224583, 0.00205781,\n          0.0036022 , 0.00303005, 0.00521405, 0.0032749 , 0.00236756,\n          0.00293342, 0.00291853, 0.00256902, 0.00306314, 0.00326303,\n          0.00678011, 0.00338257, 0.00486774, 0.00334739, 0.00389117,\n          0.00185069, 0.00487322, 0.00422105, 0.00287271, 0.00180626,\n          0.00469288, 0.00233035, 0.00254118, 0.00179323, 0.00503108,\n          0.00397664, 0.00342532, 0.00243437, 0.00386878, 0.00380174,\n          0.00337886, 0.00339091, 0.00924774, 0.00232888, 0.00241478,\n          0.00233659, 0.00236288, 0.00402317, 0.00408832, 0.0053619 ,\n          0.00488672, 0.00283497, 0.00200478, 0.0032818 , 0.00237255,\n          0.00462164, 0.00566874, 0.00504909, 0.00314132, 0.00250583,\n          0.0046936 , 0.00336426, 0.00614735, 0.00166271, 0.00929179,\n          0.00212583, 0.00231591, 0.00725797, 0.00330826, 0.00225503,\n          0.00333301, 0.00310384, 0.00156279, 0.00333533, 0.00226643,\n          0.00356454, 0.00248211, 0.00335859, 0.00742827, 0.00440991,\n          0.00248592, 0.00331766, 0.00606519, 0.00445022, 0.00252639,\n          0.00866605, 0.00180799, 0.00559861, 0.00439781, 0.00351145,\n          0.00346629, 0.00233804, 0.00356718, 0.00215583, 0.00387113,\n          0.00358685, 0.00338875, 0.007364  , 0.00295138, 0.00277827,\n          0.0019906 , 0.0015174 ], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D;mobilenetv2_1.00_224/block_6_project/Conv2D',\n  'index': 88,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_7_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise/depthwise',\n  'index': 89,\n  'shape': array([  1,   3,   3, 384], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01063308, 0.01065962, 0.00548661, 0.00474287, 0.02887514,\n          0.00719261, 0.01068173, 0.00719886, 0.00368227, 0.00789986,\n          0.01985128, 0.00671374, 0.01378988, 0.00745561, 0.04814113,\n          0.01631362, 0.01097063, 0.0028008 , 0.00599762, 0.01188752,\n          0.00517263, 0.00933209, 0.01069536, 0.02642483, 0.01532877,\n          0.00589356, 0.00589284, 0.00476261, 0.00758955, 0.01203112,\n          0.01119222, 0.0048239 , 0.00586789, 0.01228245, 0.01150947,\n          0.00641646, 0.00412101, 0.01205008, 0.01701717, 0.00896862,\n          0.00372964, 0.00575779, 0.00557197, 0.00606944, 0.00754806,\n          0.00660279, 0.02769779, 0.00968108, 0.00618101, 0.01150442,\n          0.0073608 , 0.01015499, 0.01611336, 0.02520366, 0.00909392,\n          0.01235905, 0.00511567, 0.00392668, 0.00606633, 0.00708487,\n          0.00893771, 0.01214346, 0.00610462, 0.01990546, 0.00858462,\n          0.02287661, 0.00871497, 0.024516  , 0.00485749, 0.00735552,\n          0.0124079 , 0.0110687 , 0.03100578, 0.01090671, 0.00821839,\n          0.00699474, 0.01977996, 0.00644432, 0.00632681, 0.01693021,\n          0.02370734, 0.01869575, 0.00955716, 0.00550925, 0.00848941,\n          0.01929834, 0.00442078, 0.02620363, 0.00673072, 0.00638196,\n          0.01202309, 0.01562459, 0.03397445, 0.01248326, 0.01524217,\n          0.01939013, 0.00615047, 0.00755208, 0.01524948, 0.01189349,\n          0.01696667, 0.0111924 , 0.00830414, 0.00592891, 0.00637688,\n          0.00671292, 0.01224502, 0.00979639, 0.02486983, 0.01970987,\n          0.01531494, 0.01485981, 0.00549256, 0.00936849, 0.00491431,\n          0.01801687, 0.00578591, 0.00609764, 0.01211024, 0.06464077,\n          0.00478986, 0.0045378 , 0.01160872, 0.02539786, 0.00255093,\n          0.01914537, 0.01060386, 0.02198762, 0.00658877, 0.00895867,\n          0.01040098, 0.01366776, 0.00382902, 0.0063288 , 0.00514092,\n          0.00507555, 0.00619225, 0.02101344, 0.00698734, 0.00795904,\n          0.00715791, 0.00370176, 0.00956693, 0.00926832, 0.00516404,\n          0.01219687, 0.0122597 , 0.00495468, 0.0138246 , 0.00396386,\n          0.00634798, 0.00877383, 0.00291884, 0.02356962, 0.01702631,\n          0.02611727, 0.00879576, 0.02803655, 0.01589198, 0.01125262,\n          0.01081048, 0.01171589, 0.01007461, 0.0060063 , 0.00719558,\n          0.02641805, 0.00950323, 0.00561256, 0.00690319, 0.00853464,\n          0.00328704, 0.02186868, 0.00592019, 0.01015813, 0.00865092,\n          0.015145  , 0.00706045, 0.00644526, 0.00947   , 0.0085932 ,\n          0.01700524, 0.00578953, 0.01148801, 0.01822935, 0.00910269,\n          0.00457803, 0.00453575, 0.00568481, 0.0248486 , 0.01736578,\n          0.01843593, 0.01188513, 0.00249268, 0.0519641 , 0.00724064,\n          0.01618482, 0.01519326, 0.01827737, 0.00653772, 0.01116132,\n          0.00625991, 0.0102973 , 0.00600175, 0.01689063, 0.01178672,\n          0.00769472, 0.00752339, 0.01210227, 0.02053423, 0.01164874,\n          0.01136674, 0.00738852, 0.006857  , 0.01659556, 0.00796546,\n          0.00745523, 0.03723019, 0.00513629, 0.0065842 , 0.0072893 ,\n          0.02465809, 0.00461013, 0.01209389, 0.00893251, 0.00593067,\n          0.01084358, 0.00981476, 0.01235812, 0.02828683, 0.00866378,\n          0.00781518, 0.00877781, 0.01059273, 0.00202313, 0.00322628,\n          0.01236039, 0.00618794, 0.01677895, 0.01551891, 0.00772007,\n          0.02652874, 0.00453216, 0.00828343, 0.00323345, 0.00977758,\n          0.00919894, 0.00944629, 0.01627554, 0.01290069, 0.00977295,\n          0.01556138, 0.00371341, 0.0101366 , 0.02023144, 0.01308496,\n          0.0135818 , 0.0026873 , 0.00758368, 0.00504223, 0.00723594,\n          0.01850627, 0.01214455, 0.00664809, 0.00428545, 0.00568104,\n          0.01203805, 0.0144257 , 0.00783768, 0.00786246, 0.00961832,\n          0.04641276, 0.01516505, 0.00407677, 0.00619491, 0.00696381,\n          0.00735867, 0.00808696, 0.0074643 , 0.01102007, 0.01307523,\n          0.00387978, 0.00961466, 0.00807342, 0.01843133, 0.00726775,\n          0.01181062, 0.01115921, 0.01873717, 0.01242725, 0.02582044,\n          0.00694029, 0.00523645, 0.00779596, 0.00798205, 0.01173044,\n          0.01214976, 0.00443761, 0.01101369, 0.00585035, 0.01192737,\n          0.00891013, 0.00700792, 0.01901044, 0.01001734, 0.00933674,\n          0.00428231, 0.00916659, 0.00939856, 0.0081927 , 0.02419884,\n          0.00403184, 0.00897617, 0.00620744, 0.00893943, 0.04162415,\n          0.01269368, 0.00532182, 0.00727363, 0.0061898 , 0.00788099,\n          0.00736576, 0.01042122, 0.02074307, 0.0100115 , 0.00718065,\n          0.00492736, 0.00819567, 0.00542523, 0.00546916, 0.00840651,\n          0.02169932, 0.03465447, 0.00645841, 0.00485322, 0.01101636,\n          0.00548749, 0.01051912, 0.02467825, 0.02378217, 0.00835826,\n          0.02328946, 0.02266478, 0.00650546, 0.00549153, 0.00548199,\n          0.02076817, 0.01356043, 0.0027975 , 0.0193244 , 0.00534487,\n          0.00864485, 0.01214404, 0.00840529, 0.01134971, 0.01042484,\n          0.00555608, 0.00883643, 0.01490671, 0.01183291, 0.00528543,\n          0.01569116, 0.02170927, 0.00630522, 0.00822228, 0.01569146,\n          0.0065014 , 0.01174485, 0.01060979, 0.01303618, 0.00702068,\n          0.00534064, 0.00954197, 0.00612177, 0.00554688, 0.00458791,\n          0.0117141 , 0.00986441, 0.00365872, 0.00556918, 0.01438099,\n          0.01055537, 0.00285414, 0.00640948, 0.01516852], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D;mobilenetv2_1.00_224/block_7_project/Conv2D',\n  'index': 90,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_8_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise/depthwise',\n  'index': 91,\n  'shape': array([  1,   3,   3, 384], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01038694, 0.007467  , 0.00584435, 0.009054  , 0.02199024,\n          0.00793353, 0.00892045, 0.008504  , 0.00914574, 0.00664717,\n          0.00597505, 0.00891999, 0.00845745, 0.00945398, 0.0174029 ,\n          0.00983481, 0.00774737, 0.00618728, 0.00435679, 0.00564758,\n          0.00783711, 0.00886703, 0.01911021, 0.00600643, 0.00751882,\n          0.01770453, 0.00596594, 0.01102405, 0.02353603, 0.00682126,\n          0.00595406, 0.01347059, 0.01409663, 0.00907923, 0.01210259,\n          0.01328736, 0.00711047, 0.00708825, 0.00474787, 0.01226399,\n          0.00313014, 0.0045561 , 0.01416584, 0.01089048, 0.00976398,\n          0.01961528, 0.0081209 , 0.00617606, 0.00985767, 0.00888105,\n          0.00500495, 0.00975908, 0.02722935, 0.00801811, 0.01365941,\n          0.00547398, 0.02211687, 0.0065047 , 0.01444565, 0.01136277,\n          0.0174046 , 0.00359267, 0.01826153, 0.01443469, 0.0079158 ,\n          0.01301312, 0.01058073, 0.01582715, 0.00609681, 0.02010754,\n          0.03854871, 0.01147912, 0.01003103, 0.01072291, 0.00855646,\n          0.00666378, 0.00772922, 0.01066934, 0.00824044, 0.00676882,\n          0.00626542, 0.00905678, 0.00549933, 0.00761215, 0.01289381,\n          0.00853339, 0.00531452, 0.0073197 , 0.0079416 , 0.01028722,\n          0.01868902, 0.01558028, 0.01837354, 0.01330323, 0.00841639,\n          0.00665017, 0.01309849, 0.00894167, 0.01250745, 0.0112442 ,\n          0.00700162, 0.02970654, 0.01677407, 0.00653784, 0.00658331,\n          0.00538396, 0.01879961, 0.00576449, 0.00709888, 0.00534049,\n          0.00595307, 0.00969167, 0.00475241, 0.01481273, 0.00659355,\n          0.04451795, 0.01123823, 0.01713397, 0.00548843, 0.00879551,\n          0.00828948, 0.0156316 , 0.01088034, 0.01724764, 0.03619952,\n          0.02222177, 0.00903768, 0.0072946 , 0.01104378, 0.00681717,\n          0.00658414, 0.00657869, 0.02302317, 0.00942778, 0.01132093,\n          0.00612519, 0.01123497, 0.00293601, 0.00799421, 0.01938222,\n          0.00892292, 0.00324483, 0.00712066, 0.00703421, 0.01369713,\n          0.00645326, 0.0220633 , 0.01139343, 0.02344812, 0.00517549,\n          0.00858674, 0.02835575, 0.03403847, 0.01570348, 0.00899153,\n          0.00921131, 0.00752565, 0.00510735, 0.00880339, 0.00667619,\n          0.00254338, 0.02843796, 0.00704439, 0.007331  , 0.00984441,\n          0.00566872, 0.00534234, 0.00685739, 0.01251756, 0.0048944 ,\n          0.00424814, 0.01956569, 0.01094165, 0.00926764, 0.00965041,\n          0.00803956, 0.00503211, 0.01429135, 0.0119719 , 0.00855138,\n          0.00715646, 0.01084858, 0.00486436, 0.00710252, 0.02517758,\n          0.01814717, 0.00928895, 0.01770906, 0.00763265, 0.00924013,\n          0.00275823, 0.01626041, 0.01496577, 0.00599512, 0.00469819,\n          0.00656988, 0.00791037, 0.01061818, 0.0044726 , 0.01350759,\n          0.00696447, 0.01554495, 0.00571451, 0.00567384, 0.0476666 ,\n          0.02199123, 0.01046135, 0.02458149, 0.00969435, 0.02212637,\n          0.0183508 , 0.01245324, 0.01644105, 0.00732486, 0.01395584,\n          0.00431471, 0.00688567, 0.00774676, 0.01176949, 0.00523917,\n          0.00541046, 0.00696412, 0.00923417, 0.00702337, 0.01079121,\n          0.01107529, 0.00816676, 0.00841239, 0.02635744, 0.00628355,\n          0.00628572, 0.01285251, 0.00856611, 0.01276265, 0.01809118,\n          0.00788288, 0.00837631, 0.0047525 , 0.01595477, 0.01236707,\n          0.0138473 , 0.00125002, 0.01342998, 0.02451641, 0.01126446,\n          0.0054086 , 0.00314028, 0.00995764, 0.01415394, 0.0123058 ,\n          0.00747603, 0.02360149, 0.01274189, 0.00456107, 0.00695762,\n          0.00632955, 0.00644497, 0.00628579, 0.01668902, 0.01227955,\n          0.0077388 , 0.00240892, 0.00637214, 0.00732114, 0.00499562,\n          0.00698633, 0.00276329, 0.0213557 , 0.00887703, 0.00612985,\n          0.00670504, 0.00689308, 0.00726063, 0.01126305, 0.02005271,\n          0.02250228, 0.0135663 , 0.0049859 , 0.00512428, 0.0146362 ,\n          0.01816649, 0.02693849, 0.00779771, 0.02013084, 0.0080123 ,\n          0.00732186, 0.00426177, 0.00455769, 0.01075284, 0.01574283,\n          0.01256983, 0.0049744 , 0.01987608, 0.00479843, 0.00283366,\n          0.00756615, 0.00687334, 0.00730132, 0.01484132, 0.01053211,\n          0.0142222 , 0.01620497, 0.01157779, 0.01528901, 0.02057346,\n          0.0069199 , 0.02226742, 0.02672871, 0.00782919, 0.00852799,\n          0.01280058, 0.00460216, 0.00574213, 0.01600485, 0.00679252,\n          0.00984871, 0.02189323, 0.0080564 , 0.0222645 , 0.00720131,\n          0.00601553, 0.00629037, 0.00560677, 0.0126222 , 0.01085164,\n          0.05433284, 0.013914  , 0.01444968, 0.0185214 , 0.00636553,\n          0.00716109, 0.00420918, 0.00448694, 0.01015929, 0.00802252,\n          0.01157361, 0.00469778, 0.01318366, 0.00629804, 0.02490359,\n          0.00466001, 0.03974456, 0.03408721, 0.01063777, 0.01448104,\n          0.00622052, 0.00912443, 0.00952157, 0.00423684, 0.01522733,\n          0.03065546, 0.02167181, 0.00962104, 0.0107604 , 0.00824157,\n          0.00491   , 0.00748249, 0.01040945, 0.00672784, 0.01300433,\n          0.01010258, 0.00855599, 0.00905283, 0.03308443, 0.00652388,\n          0.01572493, 0.02659381, 0.00627689, 0.00681091, 0.00783043,\n          0.00628335, 0.00852647, 0.02552075, 0.01341882, 0.00449632,\n          0.03986598, 0.00262559, 0.00739795, 0.00929919, 0.01978743,\n          0.01678469, 0.01007126, 0.00950598, 0.00530411], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D;mobilenetv2_1.00_224/block_8_project/Conv2D',\n  'index': 92,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_depthwise/depthwise;mobilenetv2_1.00_224/block_10_depthwise/depthwise',\n  'index': 93,\n  'shape': array([  1,   3,   3, 384], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.01028732, 0.00570299, 0.00748107, 0.01822944, 0.01148123,\n          0.00419228, 0.00821509, 0.01695483, 0.01490752, 0.02455448,\n          0.00425705, 0.01732389, 0.0120363 , 0.00985082, 0.01552168,\n          0.00508418, 0.01827919, 0.0059469 , 0.01067117, 0.00430441,\n          0.01081534, 0.00785509, 0.00916881, 0.02214256, 0.0080692 ,\n          0.00385712, 0.01079646, 0.02099112, 0.00475221, 0.01091039,\n          0.00334113, 0.01732451, 0.02497968, 0.00979488, 0.00965475,\n          0.00891856, 0.01154918, 0.01531873, 0.00966766, 0.007968  ,\n          0.02285173, 0.00940916, 0.0132671 , 0.00699328, 0.00491151,\n          0.0079313 , 0.00468173, 0.00711127, 0.01291646, 0.00689837,\n          0.01175659, 0.00450323, 0.00602345, 0.00505583, 0.01227412,\n          0.00756065, 0.01025696, 0.00719105, 0.01513697, 0.01128911,\n          0.00843115, 0.00584799, 0.00637534, 0.00406683, 0.02372263,\n          0.0116175 , 0.01108462, 0.0132625 , 0.01831578, 0.01026747,\n          0.02043504, 0.01621717, 0.02073623, 0.00601787, 0.01229315,\n          0.01459991, 0.03553049, 0.00824904, 0.00830929, 0.01091799,\n          0.01157136, 0.00732345, 0.01098921, 0.00551174, 0.01107602,\n          0.00675007, 0.00629289, 0.01563243, 0.00709937, 0.00805082,\n          0.00624027, 0.03808008, 0.00633399, 0.00741244, 0.01298984,\n          0.00549262, 0.01043988, 0.00768643, 0.01983451, 0.02368804,\n          0.01080893, 0.01315023, 0.00198046, 0.00805746, 0.00723095,\n          0.00575173, 0.00370529, 0.00692575, 0.00760478, 0.00709226,\n          0.00730933, 0.00447225, 0.03209958, 0.01436563, 0.01146496,\n          0.0080094 , 0.00713196, 0.0091392 , 0.00470981, 0.00618046,\n          0.00865153, 0.00357581, 0.01051985, 0.01738052, 0.00790136,\n          0.04983324, 0.00747274, 0.0095844 , 0.00803804, 0.00499464,\n          0.00477952, 0.01006388, 0.01208554, 0.00811978, 0.00765507,\n          0.00493689, 0.01702185, 0.00518538, 0.00726972, 0.0088518 ,\n          0.01032779, 0.00895394, 0.0055242 , 0.02948813, 0.01664525,\n          0.0113947 , 0.00944076, 0.00994955, 0.01015722, 0.00634648,\n          0.01308461, 0.00486376, 0.00680861, 0.0043948 , 0.009411  ,\n          0.01246399, 0.00542523, 0.0155424 , 0.00804401, 0.00586519,\n          0.01694349, 0.0123553 , 0.01015196, 0.02957707, 0.01198537,\n          0.00463812, 0.00806112, 0.0032501 , 0.00645769, 0.00981253,\n          0.01047151, 0.01983928, 0.00764658, 0.0159535 , 0.01003409,\n          0.00473662, 0.01419325, 0.00913383, 0.00797084, 0.00450102,\n          0.00584906, 0.00998061, 0.00627761, 0.00614121, 0.0148333 ,\n          0.01264224, 0.01035926, 0.00493276, 0.00847427, 0.00647483,\n          0.00533357, 0.0117783 , 0.00542726, 0.01217754, 0.00993387,\n          0.00613319, 0.01036005, 0.00383913, 0.00850119, 0.00756398,\n          0.00572929, 0.01042689, 0.00436286, 0.0098202 , 0.00744454,\n          0.01132049, 0.00918918, 0.0054117 , 0.00492183, 0.00915089,\n          0.0182835 , 0.0223541 , 0.01586192, 0.00648382, 0.00693898,\n          0.00689431, 0.01037636, 0.00470144, 0.01238547, 0.0243346 ,\n          0.00436533, 0.02987499, 0.00670475, 0.01647107, 0.00971435,\n          0.00716507, 0.01071863, 0.00819097, 0.00588144, 0.01176406,\n          0.01050858, 0.00995164, 0.01607906, 0.00758248, 0.01812517,\n          0.01096838, 0.01018213, 0.00854157, 0.00430062, 0.01156947,\n          0.02875537, 0.00943799, 0.00969872, 0.01379192, 0.00725133,\n          0.02287708, 0.0195662 , 0.01636386, 0.00808371, 0.00413235,\n          0.02897476, 0.01160453, 0.00652208, 0.02463924, 0.0064938 ,\n          0.01487475, 0.0095381 , 0.01579437, 0.00746674, 0.01906151,\n          0.00947598, 0.00748754, 0.00804788, 0.0090224 , 0.00833174,\n          0.01184192, 0.00845029, 0.00728483, 0.01662648, 0.01877739,\n          0.00631787, 0.0081086 , 0.0225743 , 0.02761573, 0.01359184,\n          0.00704866, 0.01469541, 0.00767792, 0.00535322, 0.01657529,\n          0.00959424, 0.00970606, 0.01008765, 0.00352885, 0.00663615,\n          0.00746513, 0.00382544, 0.00966146, 0.00774048, 0.00599881,\n          0.00906261, 0.00968796, 0.01067015, 0.01255705, 0.0151441 ,\n          0.00560409, 0.01032201, 0.00613964, 0.00824625, 0.00615738,\n          0.01245202, 0.00775655, 0.0118198 , 0.00764558, 0.00639738,\n          0.00922049, 0.00932   , 0.01180166, 0.00550374, 0.00489744,\n          0.01203536, 0.0073121 , 0.00950769, 0.01179736, 0.00712792,\n          0.00995768, 0.02408551, 0.02567674, 0.00682075, 0.01722499,\n          0.00378973, 0.00521143, 0.00810217, 0.01349463, 0.01351313,\n          0.01181559, 0.00838845, 0.00900135, 0.01235131, 0.00509988,\n          0.0201855 , 0.00638105, 0.00506127, 0.02026995, 0.0098977 ,\n          0.02718759, 0.00899462, 0.0133828 , 0.00566231, 0.01032263,\n          0.00679775, 0.01909531, 0.00658646, 0.0076408 , 0.00516668,\n          0.00572209, 0.01657151, 0.00510613, 0.01070649, 0.01512333,\n          0.00525277, 0.01199063, 0.01181475, 0.01304259, 0.00908425,\n          0.0091487 , 0.00765807, 0.0033045 , 0.00639316, 0.01252647,\n          0.00907025, 0.0062326 , 0.01795395, 0.00847483, 0.00937008,\n          0.0102478 , 0.01024235, 0.01004485, 0.00759241, 0.00707442,\n          0.00221369, 0.00980958, 0.00690919, 0.0122717 , 0.00980115,\n          0.02384641, 0.00544219, 0.01183171, 0.00452082, 0.01228232,\n          0.00939062, 0.00865441, 0.00984904, 0.02735041], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D',\n  'index': 94,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise',\n  'index': 95,\n  'shape': array([  1,   3,   3, 384], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00250826, 0.01211112, 0.00561946, 0.0276864 , 0.00400455,\n          0.00397332, 0.00932126, 0.00279975, 0.00551501, 0.00742826,\n          0.00598152, 0.00825833, 0.00903741, 0.00583228, 0.01993532,\n          0.00737187, 0.00582288, 0.00346691, 0.01096901, 0.00598296,\n          0.00154328, 0.00738016, 0.01056411, 0.0065508 , 0.00204668,\n          0.00802372, 0.00472054, 0.00361579, 0.00175136, 0.00763921,\n          0.00880922, 0.00354111, 0.003654  , 0.00221677, 0.00563849,\n          0.01143959, 0.00818092, 0.0055098 , 0.01614164, 0.0180663 ,\n          0.01686033, 0.00713365, 0.00743526, 0.01836461, 0.01025165,\n          0.00352379, 0.00560935, 0.00594498, 0.00477544, 0.00798476,\n          0.0059023 , 0.00843774, 0.00743938, 0.00752476, 0.00716843,\n          0.00169112, 0.02763415, 0.00567196, 0.01716841, 0.01395379,\n          0.00228081, 0.00505698, 0.0036802 , 0.00616946, 0.01567497,\n          0.00797736, 0.03446904, 0.00510433, 0.0059371 , 0.00422468,\n          0.00727528, 0.00776213, 0.00931781, 0.00259678, 0.00358397,\n          0.00647235, 0.00671924, 0.00558439, 0.00574635, 0.00900071,\n          0.01424748, 0.00599363, 0.00373453, 0.00492573, 0.00748228,\n          0.00518011, 0.00691847, 0.00520241, 0.00569117, 0.00838857,\n          0.00956339, 0.00776338, 0.0038971 , 0.02793304, 0.00215909,\n          0.01230328, 0.00344389, 0.00590866, 0.00194216, 0.01057076,\n          0.00977264, 0.00555026, 0.0028992 , 0.00204735, 0.00764389,\n          0.00182156, 0.01094884, 0.00745452, 0.01441006, 0.0047992 ,\n          0.01024819, 0.01352963, 0.00449627, 0.0132987 , 0.00326509,\n          0.01573557, 0.01115134, 0.00174212, 0.00447476, 0.02526129,\n          0.00200453, 0.00735224, 0.01610405, 0.00604206, 0.00433535,\n          0.00294102, 0.00636427, 0.00564638, 0.01558773, 0.00491475,\n          0.00712726, 0.01395335, 0.00863675, 0.01077502, 0.00657922,\n          0.0133721 , 0.00233241, 0.01088547, 0.01762382, 0.01232101,\n          0.00619377, 0.02626119, 0.00636197, 0.00453738, 0.01348475,\n          0.01013663, 0.00354196, 0.0073373 , 0.01851281, 0.00410161,\n          0.01079419, 0.00723952, 0.00561752, 0.01337079, 0.00880319,\n          0.00689547, 0.01722735, 0.00621269, 0.00963775, 0.0158329 ,\n          0.01583011, 0.00500086, 0.00618534, 0.00302172, 0.00124749,\n          0.01350279, 0.00754959, 0.00708101, 0.01112797, 0.00362633,\n          0.00578594, 0.00229156, 0.00599881, 0.00322542, 0.02060188,\n          0.01050615, 0.01004821, 0.01415206, 0.00409446, 0.00833775,\n          0.00622494, 0.00192381, 0.00544255, 0.01239198, 0.00263708,\n          0.00533037, 0.00856813, 0.01165854, 0.00817159, 0.0071089 ,\n          0.00948071, 0.01231403, 0.00970947, 0.01844765, 0.00701054,\n          0.00281676, 0.00449317, 0.00486214, 0.00750762, 0.00664812,\n          0.01733832, 0.00760729, 0.00791471, 0.00395145, 0.01088058,\n          0.00859191, 0.00398085, 0.00956754, 0.00594817, 0.00408632,\n          0.01028202, 0.02399956, 0.00246275, 0.00446535, 0.00652905,\n          0.00543921, 0.00683494, 0.00314087, 0.01132285, 0.00862729,\n          0.00760048, 0.01485006, 0.00954243, 0.01821475, 0.00914667,\n          0.00445906, 0.0023359 , 0.00909237, 0.00580981, 0.0023287 ,\n          0.02037991, 0.0050893 , 0.00718338, 0.0103844 , 0.00485086,\n          0.00604657, 0.00486013, 0.0142559 , 0.00486011, 0.01773096,\n          0.00463214, 0.00856214, 0.00315559, 0.02034533, 0.0047643 ,\n          0.03336587, 0.00747566, 0.00822342, 0.00247101, 0.01045295,\n          0.02779219, 0.00667936, 0.00912377, 0.00185209, 0.01053171,\n          0.00514915, 0.00183245, 0.01259728, 0.00635127, 0.00786544,\n          0.01363482, 0.00669983, 0.00624073, 0.00194881, 0.01166498,\n          0.00843976, 0.01135097, 0.01232462, 0.00570462, 0.02479082,\n          0.00513545, 0.00792962, 0.00639597, 0.00764082, 0.00342112,\n          0.00782815, 0.01062959, 0.00934154, 0.00678827, 0.00568008,\n          0.00337709, 0.00247038, 0.00502818, 0.00298766, 0.00252494,\n          0.00455877, 0.00680948, 0.0250613 , 0.01062361, 0.00466831,\n          0.0106721 , 0.0040394 , 0.0070522 , 0.01055457, 0.01680067,\n          0.01080057, 0.00886133, 0.00798444, 0.01537927, 0.00723355,\n          0.00650072, 0.00786028, 0.00469688, 0.00591174, 0.0054578 ,\n          0.00645953, 0.00611549, 0.00390022, 0.0116522 , 0.00148757,\n          0.00460626, 0.01124904, 0.0050203 , 0.00911023, 0.00666705,\n          0.00559518, 0.00168126, 0.01010733, 0.00590857, 0.01964599,\n          0.00532691, 0.00313646, 0.00945511, 0.01063902, 0.00932938,\n          0.01850566, 0.00866717, 0.00714415, 0.00793066, 0.00730825,\n          0.00710834, 0.01019804, 0.00634484, 0.00897328, 0.01066028,\n          0.00674479, 0.0086903 , 0.00560808, 0.00470166, 0.00962784,\n          0.00262148, 0.00307394, 0.00787129, 0.00733312, 0.00683188,\n          0.00496151, 0.0043574 , 0.00799526, 0.00823687, 0.00844404,\n          0.01640874, 0.00713532, 0.00823953, 0.00160594, 0.0115952 ,\n          0.00541739, 0.02205568, 0.00598898, 0.01930745, 0.00749992,\n          0.00846819, 0.02039767, 0.01201006, 0.01451254, 0.00466866,\n          0.00187248, 0.00668583, 0.0022731 , 0.00812037, 0.01483039,\n          0.00544338, 0.00422416, 0.01914092, 0.00620302, 0.00569065,\n          0.02328829, 0.00621162, 0.00851622, 0.00721651, 0.00203542,\n          0.00650188, 0.00816747, 0.00704935, 0.0105869 ], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_project/Conv2D;mobilenetv2_1.00_224/block_10_project/Conv2D',\n  'index': 96,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_11_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise/depthwise',\n  'index': 97,\n  'shape': array([  1,   3,   3, 576], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00952345, 0.00806128, 0.00881806, 0.01351839, 0.00418096,\n          0.01876805, 0.00495873, 0.00392563, 0.00666885, 0.00598617,\n          0.00688515, 0.01537972, 0.00814984, 0.01317041, 0.00400714,\n          0.00686405, 0.01356233, 0.0033233 , 0.00688602, 0.00411108,\n          0.00929731, 0.00936486, 0.00674048, 0.00721885, 0.00604873,\n          0.01293554, 0.00606542, 0.01329202, 0.00773662, 0.00636726,\n          0.00747347, 0.01684604, 0.00907164, 0.00545934, 0.01176183,\n          0.00321251, 0.00721784, 0.00789029, 0.00646176, 0.00361382,\n          0.00475498, 0.00625852, 0.00601267, 0.00916604, 0.00912002,\n          0.00892079, 0.00768248, 0.01361574, 0.00355586, 0.00467637,\n          0.00771715, 0.01029971, 0.00784854, 0.00945375, 0.00434729,\n          0.00418308, 0.0043254 , 0.03105525, 0.00909626, 0.00719329,\n          0.00855228, 0.00920911, 0.00864272, 0.0075676 , 0.026667  ,\n          0.00885465, 0.00956954, 0.008138  , 0.02740172, 0.00526147,\n          0.01067889, 0.00539292, 0.00760305, 0.00511921, 0.00650373,\n          0.01081933, 0.01929549, 0.00742824, 0.01512197, 0.01088879,\n          0.01034782, 0.00632078, 0.00662079, 0.01684734, 0.00719798,\n          0.00509574, 0.00683749, 0.0069659 , 0.01195452, 0.00780729,\n          0.00609848, 0.00446136, 0.01139603, 0.00816794, 0.00533475,\n          0.00863526, 0.00854385, 0.01590163, 0.00621233, 0.00504078,\n          0.00701155, 0.00550011, 0.01242669, 0.00809661, 0.00567588,\n          0.00635573, 0.01347728, 0.00345366, 0.00464264, 0.00969317,\n          0.00621483, 0.00997902, 0.00487762, 0.00726447, 0.00742381,\n          0.00973099, 0.01012127, 0.0101814 , 0.01062642, 0.0086571 ,\n          0.00438509, 0.01198725, 0.00607973, 0.00413436, 0.01152287,\n          0.00524748, 0.00703644, 0.01133103, 0.00737184, 0.00795953,\n          0.00768434, 0.0072629 , 0.00941399, 0.01239178, 0.02196467,\n          0.01434613, 0.01544362, 0.01227981, 0.00738899, 0.00585757,\n          0.00783391, 0.01010627, 0.00618696, 0.01485112, 0.01013721,\n          0.0054791 , 0.0104491 , 0.00370189, 0.00604709, 0.00341001,\n          0.01023136, 0.0115391 , 0.00564715, 0.00931205, 0.01372789,\n          0.01429261, 0.00426917, 0.0053838 , 0.0072527 , 0.00773289,\n          0.01276784, 0.00684715, 0.00983947, 0.00474249, 0.00856526,\n          0.01487755, 0.00927037, 0.00729513, 0.01613951, 0.00895357,\n          0.01017259, 0.00534791, 0.00626916, 0.00260255, 0.00972099,\n          0.0120114 , 0.01922774, 0.01072232, 0.01448673, 0.00838333,\n          0.00415468, 0.01476891, 0.00420685, 0.00749156, 0.02190368,\n          0.00544462, 0.01073804, 0.00718298, 0.01180337, 0.00905061,\n          0.00692067, 0.02483707, 0.00645691, 0.00998409, 0.00797577,\n          0.0091475 , 0.0108081 , 0.00728854, 0.00573011, 0.00908479,\n          0.00452609, 0.01113237, 0.00858661, 0.00883828, 0.00988629,\n          0.00593686, 0.00655551, 0.01324117, 0.00568961, 0.00568241,\n          0.01015341, 0.00533507, 0.00317958, 0.00837948, 0.00654116,\n          0.00969054, 0.0092573 , 0.0226819 , 0.01526862, 0.00976598,\n          0.00924084, 0.01562498, 0.004346  , 0.01705609, 0.01133943,\n          0.02050158, 0.01614114, 0.00265763, 0.00784971, 0.00934034,\n          0.00550471, 0.01012967, 0.00439617, 0.00921631, 0.00769538,\n          0.00546707, 0.00465239, 0.00969696, 0.00523326, 0.00783758,\n          0.00850186, 0.0051317 , 0.01117613, 0.00908556, 0.00948058,\n          0.00426012, 0.00822639, 0.00976555, 0.00620484, 0.01623168,\n          0.01749324, 0.00434335, 0.00588966, 0.01057763, 0.00860345,\n          0.00617201, 0.01055133, 0.00747709, 0.00563039, 0.1052124 ,\n          0.00751349, 0.01386002, 0.01099118, 0.00869775, 0.00919824,\n          0.00858162, 0.02153196, 0.0074596 , 0.01053841, 0.00323081,\n          0.008221  , 0.0058129 , 0.01448916, 0.01954249, 0.01123992,\n          0.00725456, 0.01339043, 0.00473434, 0.00577718, 0.00453354,\n          0.00978852, 0.00614554, 0.0082743 , 0.02183888, 0.00859797,\n          0.03326122, 0.00553837, 0.00733055, 0.00378174, 0.00866687,\n          0.00756435, 0.01253287, 0.01485605, 0.0098069 , 0.01330336,\n          0.01251675, 0.01137066, 0.00667708, 0.00768333, 0.01195701,\n          0.00712844, 0.00570017, 0.01031434, 0.00516244, 0.00935651,\n          0.00404571, 0.00535807, 0.01019157, 0.01238215, 0.00826275,\n          0.01000789, 0.0073916 , 0.00650113, 0.00796948, 0.00533671,\n          0.00707863, 0.00347047, 0.00645785, 0.00731462, 0.01059059,\n          0.01175096, 0.00654258, 0.01616855, 0.0045626 , 0.00875287,\n          0.00526784, 0.00980899, 0.00676276, 0.01317936, 0.004513  ,\n          0.00465979, 0.01363071, 0.00949994, 0.01155199, 0.00482348,\n          0.01127267, 0.01552673, 0.00429434, 0.01680057, 0.03120394,\n          0.00601319, 0.00585565, 0.01249614, 0.01233193, 0.00696126,\n          0.01129684, 0.00785694, 0.01886777, 0.00881378, 0.00506515,\n          0.00415569, 0.00890744, 0.00733746, 0.00699163, 0.01029271,\n          0.01392105, 0.00913342, 0.01060324, 0.00906443, 0.00483742,\n          0.00882672, 0.01456138, 0.00583183, 0.00700366, 0.00604607,\n          0.00749973, 0.02064095, 0.00479479, 0.01461619, 0.00574287,\n          0.02132837, 0.01297893, 0.01580497, 0.01013606, 0.00820354,\n          0.00486692, 0.01007492, 0.0112544 , 0.00636953, 0.01404573,\n          0.00657607, 0.01256681, 0.00854973, 0.01539508, 0.01629313,\n          0.00445525, 0.01421578, 0.01152403, 0.00371522, 0.01352809,\n          0.01473458, 0.0079999 , 0.00969416, 0.01224651, 0.02051157,\n          0.00326312, 0.00397545, 0.01068444, 0.01030964, 0.00649138,\n          0.01258369, 0.00374705, 0.00796476, 0.00846259, 0.00471098,\n          0.0094274 , 0.01868206, 0.00971362, 0.00649849, 0.00899547,\n          0.00754084, 0.01532624, 0.0025135 , 0.00543632, 0.00805961,\n          0.01577718, 0.00788167, 0.00310178, 0.00743409, 0.0065281 ,\n          0.01299135, 0.00874346, 0.0080108 , 0.00474817, 0.01863884,\n          0.00448859, 0.01109582, 0.0074103 , 0.01307565, 0.01438296,\n          0.00834419, 0.00902994, 0.00950398, 0.01329159, 0.00857734,\n          0.0125361 , 0.00779162, 0.01217137, 0.01039007, 0.01765516,\n          0.00792736, 0.00566965, 0.00772975, 0.01710911, 0.00844184,\n          0.00970982, 0.006974  , 0.00936847, 0.00779232, 0.02001324,\n          0.00528503, 0.00636234, 0.00809093, 0.01160481, 0.00727309,\n          0.01578075, 0.00653099, 0.00625146, 0.00841814, 0.0082801 ,\n          0.00329361, 0.01031873, 0.00519231, 0.00570226, 0.00588303,\n          0.0052317 , 0.0125281 , 0.00687371, 0.00630992, 0.01179634,\n          0.00452976, 0.00545767, 0.00436893, 0.01276427, 0.00315635,\n          0.0061271 , 0.00326835, 0.0067669 , 0.00898748, 0.0139974 ,\n          0.01189376, 0.00471818, 0.00536761, 0.00810948, 0.00522276,\n          0.00470203, 0.00673965, 0.00617207, 0.00923867, 0.00844694,\n          0.00414452, 0.01810112, 0.01061021, 0.00882493, 0.00827386,\n          0.01579203, 0.00416619, 0.00457169, 0.00915389, 0.00665071,\n          0.00594503, 0.00986033, 0.01009993, 0.00188988, 0.0129415 ,\n          0.00597445, 0.0051135 , 0.00434213, 0.0084418 , 0.01193538,\n          0.00452115, 0.00664502, 0.00458861, 0.00599153, 0.01006824,\n          0.01071662, 0.01147831, 0.01080498, 0.01333047, 0.01142504,\n          0.02121373, 0.00748422, 0.00976788, 0.00349891, 0.01590749,\n          0.0069825 , 0.01178447, 0.01273316, 0.0072369 , 0.00724373,\n          0.00742513, 0.0076531 , 0.00552747, 0.00655709, 0.02356022,\n          0.00371418, 0.00539921, 0.01347787, 0.01198242, 0.01663195,\n          0.01441698, 0.0040159 , 0.00670445, 0.01400239, 0.01438483,\n          0.01252527, 0.01622671, 0.00856303, 0.00619389, 0.00233969,\n          0.00248215, 0.00358261, 0.00825115, 0.03213073, 0.01203158,\n          0.00960343, 0.00964341, 0.00499596, 0.00518793, 0.0044276 ,\n          0.00670223, 0.00526092, 0.00420762, 0.00374941, 0.01655109,\n          0.00424652, 0.00719804, 0.01180407, 0.01104573, 0.00685196,\n          0.01399822, 0.0082394 , 0.00614487, 0.01424264, 0.01139611,\n          0.01397181], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_project/Conv2D;mobilenetv2_1.00_224/block_11_project/Conv2D',\n  'index': 98,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_depthwise/depthwise;mobilenetv2_1.00_224/block_13_depthwise/depthwise',\n  'index': 99,\n  'shape': array([  1,   3,   3, 576], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00822491, 0.00781824, 0.00629696, 0.01133748, 0.00435609,\n          0.00724466, 0.00452909, 0.00762769, 0.00406181, 0.02293154,\n          0.01180173, 0.00940906, 0.00748773, 0.00649777, 0.00883258,\n          0.00443942, 0.00617758, 0.00364798, 0.01087909, 0.00707039,\n          0.01497123, 0.00603366, 0.00813779, 0.0085089 , 0.00800454,\n          0.00601034, 0.01575602, 0.00707845, 0.01000622, 0.04606627,\n          0.0104782 , 0.01160152, 0.00866282, 0.00533509, 0.00737736,\n          0.01094051, 0.00172997, 0.00573821, 0.00598114, 0.00565956,\n          0.00792612, 0.00357985, 0.01304703, 0.00676421, 0.00716054,\n          0.00574111, 0.01131479, 0.01237452, 0.00575415, 0.00997093,\n          0.00515092, 0.01039397, 0.00841657, 0.00263425, 0.00292199,\n          0.00599342, 0.00765662, 0.00596874, 0.01162216, 0.012138  ,\n          0.01037741, 0.0046494 , 0.00426326, 0.00344492, 0.00422957,\n          0.00348628, 0.00494153, 0.00386334, 0.00384911, 0.01384848,\n          0.00231269, 0.01315402, 0.00332332, 0.00237564, 0.01287636,\n          0.00683581, 0.01189169, 0.00602194, 0.00625607, 0.00248845,\n          0.01052528, 0.00344374, 0.00598402, 0.01480795, 0.00546613,\n          0.00824256, 0.02226261, 0.05611886, 0.00750487, 0.02929744,\n          0.01826798, 0.005035  , 0.01048088, 0.01324048, 0.00693782,\n          0.00808854, 0.00435706, 0.03335744, 0.00701965, 0.00371082,\n          0.01437794, 0.0053736 , 0.0070705 , 0.00504277, 0.0055906 ,\n          0.00908193, 0.0060566 , 0.01397735, 0.00907513, 0.00184528,\n          0.00374014, 0.01054592, 0.00670699, 0.00239509, 0.01165894,\n          0.02141387, 0.04232391, 0.00796248, 0.00891892, 0.03127805,\n          0.00310356, 0.0116348 , 0.006724  , 0.00851167, 0.00763684,\n          0.00363788, 0.00415916, 0.00667796, 0.00596458, 0.00499129,\n          0.00752653, 0.00424248, 0.00889353, 0.00820839, 0.01228202,\n          0.00687022, 0.01328698, 0.00870068, 0.00709757, 0.00888783,\n          0.00508965, 0.02912777, 0.00923581, 0.00616666, 0.01320907,\n          0.0065006 , 0.0065995 , 0.01364159, 0.00524759, 0.01464552,\n          0.00510992, 0.00449071, 0.00805822, 0.00189657, 0.0190027 ,\n          0.00959987, 0.00816434, 0.00852107, 0.00531599, 0.00215976,\n          0.0061994 , 0.01236051, 0.01546828, 0.01581664, 0.00567694,\n          0.0062592 , 0.03953374, 0.00536846, 0.00868893, 0.00652853,\n          0.00795901, 0.00719963, 0.00676591, 0.00946336, 0.0134243 ,\n          0.00968402, 0.00614857, 0.0138156 , 0.00538665, 0.00554984,\n          0.00843669, 0.00402774, 0.0093304 , 0.00420057, 0.00965023,\n          0.01399309, 0.01976565, 0.00801529, 0.00251176, 0.0044744 ,\n          0.00781753, 0.0061803 , 0.00347033, 0.03224847, 0.00668032,\n          0.00809194, 0.00490619, 0.00439337, 0.01202187, 0.00783757,\n          0.0116641 , 0.00636263, 0.00639539, 0.00748298, 0.00781144,\n          0.01430805, 0.00945121, 0.00758925, 0.00872221, 0.00455539,\n          0.01404093, 0.01075487, 0.03426033, 0.00534797, 0.00405641,\n          0.00539515, 0.01688427, 0.00851544, 0.0050978 , 0.00197547,\n          0.0044007 , 0.0099569 , 0.00344575, 0.00495213, 0.00908078,\n          0.01543406, 0.01220348, 0.00651569, 0.00521182, 0.00452869,\n          0.00478662, 0.01074572, 0.01002867, 0.00859509, 0.00406891,\n          0.00424987, 0.01172058, 0.01037412, 0.0077992 , 0.00546175,\n          0.00929532, 0.00330332, 0.00151325, 0.0143367 , 0.0123972 ,\n          0.01203426, 0.00737966, 0.00674004, 0.0050901 , 0.00804235,\n          0.00547401, 0.00783303, 0.00464893, 0.00362353, 0.00394834,\n          0.00492704, 0.01323779, 0.0105349 , 0.00278494, 0.00306299,\n          0.00653936, 0.01320366, 0.01369143, 0.00678753, 0.00215655,\n          0.00462797, 0.00247873, 0.00385406, 0.00466566, 0.0118718 ,\n          0.00764473, 0.01267823, 0.00618636, 0.00445651, 0.01007951,\n          0.00593119, 0.00669924, 0.00239796, 0.00666555, 0.00402344,\n          0.00966611, 0.00604809, 0.00870855, 0.0052834 , 0.00567105,\n          0.00416303, 0.00817737, 0.00747902, 0.01499434, 0.00634367,\n          0.0055116 , 0.01045016, 0.00822783, 0.01192386, 0.03089589,\n          0.00732509, 0.01387273, 0.00528629, 0.00966945, 0.00661254,\n          0.0080948 , 0.00283111, 0.00625138, 0.00906429, 0.00238756,\n          0.00547856, 0.01234866, 0.0232394 , 0.01485401, 0.01665807,\n          0.01183639, 0.00372768, 0.00631801, 0.00846848, 0.00617866,\n          0.00229743, 0.00641028, 0.00507826, 0.01249256, 0.00274133,\n          0.00822043, 0.00888063, 0.01069804, 0.00592133, 0.00530834,\n          0.00561578, 0.01073098, 0.00491362, 0.00709492, 0.01307427,\n          0.00675777, 0.00305659, 0.00605561, 0.00620678, 0.0102781 ,\n          0.00911621, 0.00689293, 0.0073309 , 0.01440599, 0.00274241,\n          0.00720305, 0.00741708, 0.00399913, 0.00326849, 0.0092754 ,\n          0.00772235, 0.00569143, 0.01065611, 0.07664248, 0.00305221,\n          0.01121582, 0.00340608, 0.00321816, 0.00454691, 0.0264655 ,\n          0.00662678, 0.00735578, 0.01959444, 0.00862763, 0.00726833,\n          0.0102402 , 0.00509483, 0.00448108, 0.00457012, 0.01242245,\n          0.01191446, 0.00808091, 0.00797489, 0.00388767, 0.01679118,\n          0.01352537, 0.02502424, 0.0028181 , 0.00760236, 0.00788746,\n          0.01092667, 0.00960029, 0.01464809, 0.04819266, 0.00692186,\n          0.01228677, 0.00858077, 0.01359923, 0.00846168, 0.00378483,\n          0.00804162, 0.00637551, 0.00946921, 0.00737236, 0.01530374,\n          0.01421332, 0.01727621, 0.00971619, 0.00969739, 0.00517686,\n          0.00492398, 0.00583404, 0.01148592, 0.00442111, 0.00574932,\n          0.00719691, 0.01615297, 0.0098747 , 0.00764095, 0.00836481,\n          0.00433899, 0.00511499, 0.00554778, 0.01279086, 0.01103079,\n          0.00473663, 0.00607187, 0.00433987, 0.00943934, 0.00605109,\n          0.01085675, 0.00578009, 0.00945396, 0.00394296, 0.00718555,\n          0.00960355, 0.00804432, 0.00531286, 0.01203804, 0.01152611,\n          0.00396075, 0.00977076, 0.00669609, 0.00429182, 0.00454363,\n          0.00610823, 0.00262444, 0.01870449, 0.02250654, 0.0064869 ,\n          0.00927457, 0.01214905, 0.00520377, 0.02383584, 0.00452295,\n          0.00768179, 0.00434798, 0.00541345, 0.007948  , 0.00914808,\n          0.01975477, 0.00840925, 0.01246984, 0.01401273, 0.00890832,\n          0.00384497, 0.00477629, 0.00548678, 0.00333603, 0.0086488 ,\n          0.01010679, 0.00293521, 0.0160518 , 0.00285663, 0.01178616,\n          0.02100669, 0.00862135, 0.00173577, 0.00730562, 0.01258857,\n          0.02164313, 0.00591701, 0.0087541 , 0.00736304, 0.00879485,\n          0.00653548, 0.01241886, 0.00778752, 0.00878962, 0.00677886,\n          0.00290326, 0.00858433, 0.00694419, 0.00561337, 0.01013391,\n          0.00474491, 0.00971479, 0.01039374, 0.01183631, 0.01255178,\n          0.00446935, 0.01663432, 0.00789662, 0.00540778, 0.01328451,\n          0.01040697, 0.00551818, 0.03629142, 0.01139686, 0.00446057,\n          0.00703846, 0.02118174, 0.00909924, 0.00810568, 0.01026077,\n          0.01151789, 0.00615103, 0.00666361, 0.03178737, 0.0046187 ,\n          0.01059646, 0.00190887, 0.00432532, 0.00875629, 0.0068701 ,\n          0.00552266, 0.00609578, 0.01239404, 0.00612512, 0.01362649,\n          0.01462341, 0.00344851, 0.01308496, 0.01075481, 0.00564267,\n          0.00758187, 0.00545491, 0.00219724, 0.01844884, 0.00437885,\n          0.00639562, 0.00864917, 0.00621697, 0.0038093 , 0.00521366,\n          0.0084479 , 0.00410686, 0.01017318, 0.0025472 , 0.00795784,\n          0.0104639 , 0.00449819, 0.00644911, 0.00883755, 0.00460544,\n          0.00765135, 0.0046983 , 0.00822797, 0.00498056, 0.00490245,\n          0.00952576, 0.00573613, 0.01033387, 0.01122415, 0.0052791 ,\n          0.01022775, 0.01739173, 0.01232434, 0.04407082, 0.00932758,\n          0.00902378, 0.00830298, 0.00447226, 0.00737212, 0.00586182,\n          0.00608671, 0.0025495 , 0.0127694 , 0.00552009, 0.00578397,\n          0.00626229, 0.00523043, 0.00844209, 0.00262068, 0.0087037 ,\n          0.00645448, 0.01078501, 0.01953527, 0.00833792, 0.00620976,\n          0.00276692], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_project/Conv2D',\n  'index': 100,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise',\n  'index': 101,\n  'shape': array([  1,   3,   3, 576], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00441046, 0.00282981, 0.00482067, 0.00214313, 0.00390375,\n          0.00182165, 0.00183063, 0.00532543, 0.00197502, 0.00380623,\n          0.00292646, 0.0046968 , 0.00368785, 0.00372725, 0.00383338,\n          0.00371237, 0.00306282, 0.00125572, 0.00503876, 0.00589452,\n          0.00389446, 0.0013867 , 0.00359288, 0.00288034, 0.00639914,\n          0.00262969, 0.0026192 , 0.00155689, 0.00630928, 0.00198007,\n          0.00352825, 0.00284447, 0.00308054, 0.00474354, 0.00810431,\n          0.00343475, 0.00222674, 0.0131676 , 0.0041875 , 0.00360286,\n          0.0035802 , 0.00308686, 0.00335119, 0.00233011, 0.00306274,\n          0.00237248, 0.00330598, 0.00381628, 0.00308572, 0.00177727,\n          0.00273265, 0.0042598 , 0.00316955, 0.0032875 , 0.00178209,\n          0.00478006, 0.00309713, 0.00316475, 0.00210349, 0.00327213,\n          0.00238551, 0.00170292, 0.00378182, 0.0014456 , 0.00458198,\n          0.00578225, 0.00497441, 0.00507682, 0.00397403, 0.00412386,\n          0.002534  , 0.00489113, 0.00518839, 0.00344992, 0.00456525,\n          0.00428361, 0.00323709, 0.00615533, 0.00646664, 0.00423263,\n          0.00590535, 0.00393536, 0.00320846, 0.00379393, 0.00359375,\n          0.0018133 , 0.00372544, 0.00397528, 0.00473987, 0.0028412 ,\n          0.00285736, 0.00165878, 0.00318721, 0.00349913, 0.00385915,\n          0.00236843, 0.00406096, 0.00491375, 0.00180691, 0.00418586,\n          0.00264514, 0.0032819 , 0.00419742, 0.00274975, 0.0056895 ,\n          0.00272879, 0.00329903, 0.00453852, 0.00372694, 0.00438122,\n          0.00224455, 0.00164758, 0.00536651, 0.00099404, 0.00262958,\n          0.00156455, 0.00257957, 0.0016343 , 0.00540505, 0.00500429,\n          0.00198727, 0.00252495, 0.00327003, 0.00286402, 0.00643903,\n          0.00360057, 0.00558562, 0.00243522, 0.0013591 , 0.00333334,\n          0.00378949, 0.00442664, 0.00292518, 0.00275711, 0.00436347,\n          0.00514198, 0.00471606, 0.00172187, 0.00141297, 0.00235138,\n          0.00466959, 0.00599123, 0.00296413, 0.00317718, 0.00601188,\n          0.00322046, 0.00366378, 0.00550546, 0.00366803, 0.00418341,\n          0.00307778, 0.00227095, 0.00497543, 0.00258498, 0.00100386,\n          0.00303118, 0.00360941, 0.00251467, 0.00547276, 0.00385729,\n          0.00417762, 0.00406485, 0.00429337, 0.00441599, 0.003115  ,\n          0.00427472, 0.00564135, 0.00169912, 0.00315433, 0.00620266,\n          0.00634163, 0.00343688, 0.00174467, 0.00793375, 0.00356983,\n          0.00871704, 0.00339707, 0.00541389, 0.00552077, 0.00361049,\n          0.00412866, 0.00301354, 0.00340658, 0.0039364 , 0.0046686 ,\n          0.00415271, 0.00620524, 0.01110915, 0.00443477, 0.00126714,\n          0.00397407, 0.00321946, 0.00570604, 0.00153042, 0.00333379,\n          0.00605102, 0.00417719, 0.00318065, 0.00435985, 0.00143158,\n          0.00344498, 0.00326536, 0.0033073 , 0.00263343, 0.00323688,\n          0.00362731, 0.00343047, 0.00684359, 0.0046901 , 0.00543734,\n          0.00297919, 0.00297922, 0.00186525, 0.00413583, 0.00677101,\n          0.0015909 , 0.00213058, 0.00235034, 0.0028182 , 0.00167493,\n          0.00330244, 0.00287416, 0.00390432, 0.00353171, 0.00378424,\n          0.00188096, 0.00979893, 0.00485914, 0.00527405, 0.00602263,\n          0.00203047, 0.00409115, 0.0032976 , 0.00414567, 0.00338347,\n          0.00191563, 0.00236587, 0.00603189, 0.00572055, 0.00438677,\n          0.00607463, 0.0023077 , 0.00336322, 0.00315473, 0.00584372,\n          0.0040547 , 0.00228243, 0.00834422, 0.00388671, 0.00288634,\n          0.00467962, 0.00405896, 0.00451582, 0.00577035, 0.00302615,\n          0.00487791, 0.00228659, 0.00411706, 0.00128297, 0.00287548,\n          0.00441213, 0.00411574, 0.00285203, 0.00154629, 0.0027115 ,\n          0.00446243, 0.00420265, 0.00213196, 0.0028902 , 0.00206151,\n          0.00200467, 0.00318139, 0.00307262, 0.00336351, 0.0038288 ,\n          0.00443982, 0.00361602, 0.00554644, 0.00415443, 0.0037755 ,\n          0.00436155, 0.00166229, 0.00247997, 0.00220987, 0.00257028,\n          0.00593604, 0.00484487, 0.00340143, 0.00304271, 0.00472486,\n          0.00386102, 0.00220529, 0.00328511, 0.00328983, 0.00638746,\n          0.00320511, 0.00499837, 0.00569356, 0.00267802, 0.00312423,\n          0.00399549, 0.00567489, 0.00175872, 0.00603041, 0.0045639 ,\n          0.00687633, 0.0031697 , 0.00287154, 0.00316548, 0.00325068,\n          0.00486073, 0.00504159, 0.00244517, 0.00276002, 0.00364813,\n          0.00244842, 0.00350624, 0.00310128, 0.00301325, 0.00334144,\n          0.00172936, 0.00342727, 0.00417076, 0.00374944, 0.00436846,\n          0.00440638, 0.0023389 , 0.00276813, 0.00407898, 0.00491271,\n          0.00251079, 0.0018385 , 0.00352317, 0.0022977 , 0.00395758,\n          0.00523328, 0.00528378, 0.00424975, 0.00401463, 0.00356212,\n          0.00400454, 0.00297152, 0.00203774, 0.00316175, 0.00141935,\n          0.0037565 , 0.00161284, 0.0056101 , 0.00508659, 0.00147916,\n          0.00246355, 0.00632062, 0.00768468, 0.0025981 , 0.0049141 ,\n          0.00270087, 0.00267574, 0.00488741, 0.00474406, 0.00474687,\n          0.00167217, 0.00179216, 0.00300919, 0.00334434, 0.00169727,\n          0.0049906 , 0.00137595, 0.00434582, 0.00323177, 0.00279732,\n          0.00155916, 0.00426875, 0.00341698, 0.0028053 , 0.00258544,\n          0.00311355, 0.003205  , 0.00296981, 0.00129506, 0.00346035,\n          0.00461964, 0.00478114, 0.00483904, 0.00456562, 0.00220928,\n          0.00195069, 0.00373639, 0.00622199, 0.00183308, 0.00344937,\n          0.00508466, 0.00381834, 0.00244648, 0.00322498, 0.00435457,\n          0.00505584, 0.0031402 , 0.00174188, 0.00472696, 0.00311535,\n          0.00382687, 0.00278403, 0.00468813, 0.0069154 , 0.00419024,\n          0.00196633, 0.00674711, 0.00204381, 0.00809572, 0.00529227,\n          0.00472721, 0.00610048, 0.00145677, 0.00571044, 0.00324022,\n          0.00519237, 0.00332463, 0.00349486, 0.00345323, 0.00379404,\n          0.0019738 , 0.00203955, 0.0034948 , 0.00424993, 0.00237395,\n          0.00362745, 0.00323773, 0.00200819, 0.00340476, 0.00281608,\n          0.0104462 , 0.00626758, 0.00291415, 0.00397087, 0.00395569,\n          0.00317902, 0.00330031, 0.00233238, 0.00230811, 0.00384424,\n          0.00345267, 0.00149377, 0.00226372, 0.00310595, 0.00451049,\n          0.00358753, 0.00444039, 0.00311451, 0.00230529, 0.00172777,\n          0.00238287, 0.00375069, 0.0034472 , 0.00512118, 0.00478716,\n          0.00423066, 0.0039542 , 0.00562533, 0.00528627, 0.00248795,\n          0.00191222, 0.00429583, 0.00409645, 0.00288043, 0.00311818,\n          0.00330727, 0.00330163, 0.00579592, 0.00356329, 0.00449245,\n          0.00396707, 0.00436366, 0.00302977, 0.00440443, 0.00293787,\n          0.00513838, 0.00539187, 0.00407779, 0.00413826, 0.00389029,\n          0.00401932, 0.003233  , 0.0030213 , 0.00162077, 0.00357305,\n          0.00569098, 0.00089887, 0.00356726, 0.00426407, 0.00534242,\n          0.00375519, 0.00280204, 0.00210817, 0.00125214, 0.00449268,\n          0.00463339, 0.00417251, 0.00444228, 0.00418475, 0.00360496,\n          0.00378372, 0.00222991, 0.0022607 , 0.00687281, 0.00383817,\n          0.0039415 , 0.00363093, 0.00324348, 0.00297967, 0.00257683,\n          0.00629453, 0.00253176, 0.00462762, 0.00685787, 0.00352981,\n          0.00276347, 0.00081745, 0.0060727 , 0.00356672, 0.00153711,\n          0.00187367, 0.00574972, 0.00422077, 0.00393569, 0.00529347,\n          0.00299018, 0.00206028, 0.00548692, 0.0028395 , 0.00353891,\n          0.0051497 , 0.00341156, 0.00586768, 0.001426  , 0.00412693,\n          0.00353328, 0.00488483, 0.00323837, 0.00566376, 0.00326679,\n          0.00433187, 0.00434385, 0.00481376, 0.00465038, 0.00369704,\n          0.00310571, 0.00227618, 0.00337943, 0.00165487, 0.00548025,\n          0.00468991, 0.00359984, 0.00252055, 0.00243347, 0.00440024,\n          0.00366882, 0.00243248, 0.00311154, 0.00349295, 0.00328989,\n          0.00455522, 0.00393117, 0.00552902, 0.00540595, 0.00645225,\n          0.00368398, 0.00399526, 0.0050321 , 0.00642154, 0.00400601,\n          0.00516353, 0.00224023, 0.00406553, 0.01913082, 0.00438681,\n          0.00450903], dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_project/Conv2D;mobilenetv2_1.00_224/block_13_project/Conv2D',\n  'index': 102,\n  'shape': array([160], dtype=int32),\n  'shape_signature': array([160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_14_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise/depthwise',\n  'index': 103,\n  'shape': array([  1,   3,   3, 960], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00902076, 0.00954033, 0.00852188, 0.00606995, 0.00651688,\n          0.00834804, 0.0048666 , 0.01338382, 0.00921006, 0.00879257,\n          0.0103116 , 0.00718307, 0.00941546, 0.00501373, 0.00766206,\n          0.00498185, 0.01856976, 0.01063151, 0.00201692, 0.00979924,\n          0.00879825, 0.01087748, 0.00638163, 0.00871371, 0.01053053,\n          0.00865607, 0.0110557 , 0.00401753, 0.00559822, 0.0042323 ,\n          0.00721287, 0.00861745, 0.00634448, 0.00817807, 0.00508014,\n          0.01290102, 0.00721309, 0.00424656, 0.00670158, 0.00543409,\n          0.00928629, 0.01090091, 0.00403517, 0.0061675 , 0.00387953,\n          0.00766809, 0.00905559, 0.01187174, 0.01072684, 0.00772477,\n          0.00682024, 0.01182661, 0.00513119, 0.00514791, 0.0018217 ,\n          0.01227772, 0.00258888, 0.01619004, 0.00831679, 0.00834691,\n          0.01080359, 0.0106006 , 0.00593514, 0.0060162 , 0.00888383,\n          0.00688107, 0.00483992, 0.00644528, 0.0189511 , 0.0089062 ,\n          0.00663172, 0.01033721, 0.0081915 , 0.00259735, 0.00605795,\n          0.00804814, 0.01702827, 0.00240883, 0.01770122, 0.00667467,\n          0.00562334, 0.00992758, 0.00350166, 0.01145217, 0.0071427 ,\n          0.00485412, 0.00518313, 0.00709022, 0.00690587, 0.00644834,\n          0.00990275, 0.01771081, 0.00429579, 0.00529625, 0.00663475,\n          0.00407395, 0.0066199 , 0.00841833, 0.00303113, 0.00813188,\n          0.02020412, 0.00321547, 0.008297  , 0.01446756, 0.00851972,\n          0.01155434, 0.00303913, 0.00583132, 0.00953376, 0.02170985,\n          0.00462103, 0.00769951, 0.00668563, 0.00629325, 0.00328123,\n          0.00564089, 0.00392094, 0.01203368, 0.0044752 , 0.00838025,\n          0.0067413 , 0.0079148 , 0.00710965, 0.01033657, 0.01054205,\n          0.01259036, 0.00818482, 0.00999732, 0.00707831, 0.00538155,\n          0.00435695, 0.00607622, 0.00444472, 0.00666709, 0.00828765,\n          0.00852916, 0.00633884, 0.00445124, 0.02557405, 0.00701463,\n          0.00440503, 0.00689017, 0.00744618, 0.00553485, 0.01883018,\n          0.00564886, 0.00516226, 0.008118  , 0.00252585, 0.00965717,\n          0.00736123, 0.00760681, 0.0037292 , 0.00859398, 0.00510783,\n          0.00461319, 0.01055235, 0.00788047, 0.00874017, 0.0072384 ,\n          0.00949371, 0.00688065, 0.02281915, 0.00454434, 0.00347404,\n          0.01086222, 0.00935074, 0.00277773, 0.00919714, 0.01509442,\n          0.01241458, 0.00622758, 0.00563761, 0.00774101, 0.01398858,\n          0.00738255, 0.00900723, 0.01093002, 0.01667013, 0.0068325 ,\n          0.00442794, 0.00802317, 0.0084922 , 0.00654982, 0.0097797 ,\n          0.00654939, 0.01023878, 0.00946493, 0.00967656, 0.00389667,\n          0.00846615, 0.00418906, 0.00872136, 0.00758679, 0.0090978 ,\n          0.00809142, 0.00823994, 0.00406277, 0.00701839, 0.00890127,\n          0.00578563, 0.01087322, 0.01675398, 0.02515505, 0.00763732,\n          0.00753945, 0.01227855, 0.00879403, 0.00872863, 0.0052546 ,\n          0.01746837, 0.0019766 , 0.00790923, 0.004094  , 0.00835218,\n          0.00469524, 0.00716695, 0.00698926, 0.00614859, 0.00553561,\n          0.01682765, 0.00664206, 0.01008098, 0.00913061, 0.01082391,\n          0.00706254, 0.01894519, 0.00890424, 0.0484657 , 0.00268272,\n          0.00870391, 0.00597101, 0.0116085 , 0.00417591, 0.00536364,\n          0.00273987, 0.0077009 , 0.01389182, 0.01047531, 0.00834363,\n          0.01000995, 0.00585981, 0.00733945, 0.00881608, 0.00882185,\n          0.00393434, 0.00410146, 0.00620828, 0.00635595, 0.00720068,\n          0.00308617, 0.01873803, 0.00435654, 0.01121636, 0.00493119,\n          0.0104959 , 0.00252997, 0.01830895, 0.00508447, 0.00731725,\n          0.00948332, 0.01049754, 0.00737609, 0.00625252, 0.00417016,\n          0.01081548, 0.00472716, 0.00400113, 0.00789139, 0.00806916,\n          0.00652638, 0.00200225, 0.00744213, 0.00720631, 0.0165194 ,\n          0.00723366, 0.00576847, 0.00674822, 0.00854168, 0.0034567 ,\n          0.01252803, 0.011185  , 0.00804289, 0.00647244, 0.00780192,\n          0.00793051, 0.01392662, 0.0049562 , 0.0050844 , 0.00398249,\n          0.0096614 , 0.01858902, 0.006356  , 0.00589672, 0.00675701,\n          0.00585527, 0.00748028, 0.00893626, 0.00853893, 0.00416394,\n          0.008331  , 0.00856571, 0.0096354 , 0.00510234, 0.0245814 ,\n          0.00859817, 0.00873344, 0.0050552 , 0.00850296, 0.00145119,\n          0.00561112, 0.00833143, 0.00568453, 0.01028119, 0.01526768,\n          0.00998373, 0.01808529, 0.00687049, 0.01380545, 0.01089358,\n          0.00397166, 0.00810781, 0.00842164, 0.00934661, 0.00537206,\n          0.01326778, 0.00531389, 0.01013144, 0.00590099, 0.00591574,\n          0.01066906, 0.00826217, 0.0067911 , 0.00889958, 0.01010863,\n          0.0055821 , 0.00593359, 0.00915116, 0.01505844, 0.00563629,\n          0.00474217, 0.00631609, 0.00630214, 0.01229739, 0.0093096 ,\n          0.00881812, 0.00498555, 0.00644381, 0.00335196, 0.00931521,\n          0.00926329, 0.00570162, 0.00562698, 0.00619263, 0.00757223,\n          0.00779328, 0.01058839, 0.01045445, 0.00305588, 0.01011095,\n          0.00433004, 0.00876918, 0.00529671, 0.00433066, 0.00452065,\n          0.00718084, 0.00384697, 0.03587817, 0.00536928, 0.00504137,\n          0.00579845, 0.00945387, 0.0103397 , 0.00261254, 0.03660436,\n          0.00849643, 0.00668304, 0.00742264, 0.01422708, 0.0050235 ,\n          0.01762651, 0.0139755 , 0.00457179, 0.01046041, 0.01085396,\n          0.00791336, 0.01088922, 0.0104532 , 0.00916131, 0.02348123,\n          0.00529126, 0.00384343, 0.02307641, 0.00472261, 0.00451419,\n          0.01092279, 0.00274997, 0.00815786, 0.03318131, 0.01573043,\n          0.01081689, 0.0121714 , 0.0060639 , 0.00775634, 0.00298619,\n          0.00690742, 0.01007534, 0.00416253, 0.01023668, 0.02417018,\n          0.00620801, 0.00817895, 0.00390978, 0.00937296, 0.00245969,\n          0.00538517, 0.00812984, 0.01084049, 0.00698003, 0.0089636 ,\n          0.01138727, 0.00533072, 0.00668862, 0.01543541, 0.01013621,\n          0.00503716, 0.007084  , 0.00490474, 0.00853045, 0.00334973,\n          0.00680729, 0.00808255, 0.01113184, 0.01017654, 0.00654709,\n          0.00260864, 0.00802263, 0.00311647, 0.01061455, 0.00202683,\n          0.0034753 , 0.00588588, 0.00806814, 0.00707951, 0.00929657,\n          0.00838299, 0.00560081, 0.00555064, 0.00753514, 0.02173411,\n          0.0058881 , 0.00800431, 0.01093312, 0.0135719 , 0.0079563 ,\n          0.01068844, 0.0058155 , 0.02658306, 0.0090954 , 0.00709036,\n          0.00664469, 0.01075267, 0.00797313, 0.01462152, 0.00592827,\n          0.00228977, 0.01055982, 0.00881982, 0.00802899, 0.00758621,\n          0.00845628, 0.00822917, 0.00309936, 0.00865329, 0.01001944,\n          0.00722855, 0.01279202, 0.00779873, 0.02969604, 0.00687656,\n          0.00945199, 0.00530221, 0.00454366, 0.00395842, 0.01178009,\n          0.0057207 , 0.00579921, 0.00520133, 0.00791594, 0.00830023,\n          0.01425565, 0.00926444, 0.00236854, 0.00478682, 0.00222486,\n          0.00846497, 0.00706516, 0.01797367, 0.00347306, 0.00837928,\n          0.00901161, 0.005211  , 0.00861797, 0.00826364, 0.00441942,\n          0.01136825, 0.00920972, 0.00300499, 0.00549635, 0.00976316,\n          0.00744752, 0.00290232, 0.00672611, 0.00348505, 0.008942  ,\n          0.00223205, 0.03042673, 0.00455917, 0.01033807, 0.00306506,\n          0.00591654, 0.00873765, 0.00330221, 0.00766074, 0.01032185,\n          0.00762744, 0.01423153, 0.00458474, 0.00746622, 0.00616318,\n          0.00314512, 0.00678019, 0.01692778, 0.0138743 , 0.00369767,\n          0.00890697, 0.00640898, 0.00870798, 0.00543749, 0.00342025,\n          0.00623697, 0.00665611, 0.00217122, 0.00781259, 0.01003435,\n          0.00743614, 0.01372203, 0.01766177, 0.01370353, 0.0097965 ,\n          0.00794541, 0.0060411 , 0.00709345, 0.00499079, 0.0052064 ,\n          0.0111926 , 0.00748556, 0.0098084 , 0.01485966, 0.00502713,\n          0.00163911, 0.00456826, 0.01043922, 0.00588002, 0.00476711,\n          0.00477956, 0.00598916, 0.00493221, 0.00787659, 0.00393561,\n          0.00796749, 0.00499979, 0.00742298, 0.01039895, 0.00396988,\n          0.00448068, 0.00949016, 0.00693833, 0.00447112, 0.01189074,\n          0.00761102, 0.00522595, 0.01016988, 0.00616962, 0.0115198 ,\n          0.01207604, 0.0092144 , 0.00366395, 0.01292478, 0.01104396,\n          0.00612957, 0.00471943, 0.00723353, 0.00493556, 0.00341613,\n          0.01061391, 0.00689458, 0.00440941, 0.00453178, 0.00924056,\n          0.0131656 , 0.00530123, 0.03210792, 0.00657153, 0.00791602,\n          0.00648607, 0.00580282, 0.00410285, 0.00572783, 0.02175471,\n          0.0087025 , 0.00573258, 0.00523994, 0.0077826 , 0.00627333,\n          0.00605328, 0.00837444, 0.00210934, 0.00612032, 0.00710809,\n          0.0103463 , 0.02758585, 0.00874806, 0.00527776, 0.00836197,\n          0.00633922, 0.00763464, 0.00446056, 0.00809587, 0.00429501,\n          0.00697238, 0.02493537, 0.00538517, 0.00372642, 0.01350612,\n          0.00292291, 0.00281684, 0.00638336, 0.01227382, 0.00479364,\n          0.00446194, 0.00399955, 0.00514289, 0.0055194 , 0.00762073,\n          0.00674487, 0.00555221, 0.01821793, 0.0066833 , 0.00889657,\n          0.00704292, 0.00459784, 0.00578689, 0.00158496, 0.01207751,\n          0.00561227, 0.00776149, 0.00719832, 0.0055239 , 0.01030189,\n          0.00591737, 0.00587703, 0.00503694, 0.00474161, 0.00544142,\n          0.00486173, 0.00683925, 0.00983771, 0.00843366, 0.01264729,\n          0.00994425, 0.00820595, 0.01055207, 0.0067909 , 0.00584286,\n          0.00467347, 0.00436287, 0.00664363, 0.00795731, 0.00490669,\n          0.00336667, 0.00626677, 0.00708523, 0.00789874, 0.00212698,\n          0.00183499, 0.00932785, 0.00367499, 0.00818668, 0.00438381,\n          0.002713  , 0.01046369, 0.0109406 , 0.00644539, 0.00533217,\n          0.0055595 , 0.00762102, 0.00606992, 0.0080883 , 0.00649252,\n          0.00322956, 0.01120917, 0.00927854, 0.00624787, 0.00691811,\n          0.00506747, 0.00566203, 0.00417828, 0.00809342, 0.01450075,\n          0.00649642, 0.01325267, 0.00335225, 0.00688944, 0.00950604,\n          0.00299712, 0.00694323, 0.00582556, 0.01814308, 0.01036419,\n          0.00463892, 0.01787973, 0.0162985 , 0.00656812, 0.00617899,\n          0.01010178, 0.01196035, 0.00571981, 0.0093975 , 0.00350687,\n          0.00731161, 0.00224527, 0.01347326, 0.0013393 , 0.0034429 ,\n          0.01020864, 0.02360498, 0.00960679, 0.00900444, 0.00601656,\n          0.00606996, 0.00892565, 0.00391342, 0.00862136, 0.0075902 ,\n          0.0055563 , 0.01136938, 0.00480009, 0.00665998, 0.00524061,\n          0.00478178, 0.0121283 , 0.00982183, 0.00489901, 0.00692375,\n          0.00852247, 0.00907315, 0.00655841, 0.00529638, 0.00745123,\n          0.00636392, 0.0191917 , 0.01225848, 0.01075808, 0.00698914,\n          0.01122596, 0.0044992 , 0.0174748 , 0.00635453, 0.01510248,\n          0.01197242, 0.00307371, 0.01045173, 0.01454296, 0.00812954,\n          0.00678133, 0.00590733, 0.00450878, 0.00297125, 0.01186678,\n          0.00425198, 0.00789662, 0.00577228, 0.00784538, 0.0084566 ,\n          0.00267072, 0.00554785, 0.00206743, 0.00622703, 0.00378272,\n          0.00630139, 0.00551668, 0.00519936, 0.0045445 , 0.00641208,\n          0.0082834 , 0.0062973 , 0.00632466, 0.00744784, 0.00657239,\n          0.00943072, 0.00545039, 0.00722612, 0.00497937, 0.00677726,\n          0.00970318, 0.00411793, 0.03332301, 0.00484752, 0.0117805 ,\n          0.0038243 , 0.00699692, 0.00361027, 0.00447104, 0.00679755,\n          0.00587929, 0.00721757, 0.00319714, 0.0050182 , 0.00624477,\n          0.01611158, 0.02883592, 0.00733414, 0.00651225, 0.01019129,\n          0.02024537, 0.0047738 , 0.00764696, 0.00368668, 0.00753036,\n          0.01699132, 0.01084915, 0.00699806, 0.00831481, 0.00747564,\n          0.00468352, 0.0069159 , 0.00748506, 0.02077863, 0.00818625,\n          0.00645974, 0.00327672, 0.01372707, 0.01077806, 0.02142498,\n          0.00631582, 0.00282107, 0.00870795, 0.0030171 , 0.00525026,\n          0.01031639, 0.00495104, 0.00815286, 0.00818611, 0.00445299,\n          0.00583615, 0.00683859, 0.00702196, 0.00315749, 0.0032051 ,\n          0.0071697 , 0.00562929, 0.00666367, 0.0095167 , 0.00365662,\n          0.01340696, 0.01787115, 0.00836559, 0.00240678, 0.00855843,\n          0.00869402, 0.0066721 , 0.00621489, 0.00918309, 0.00316938,\n          0.01158289, 0.00659589, 0.00382804, 0.00994654, 0.00483558,\n          0.00714825, 0.00376613, 0.00365725, 0.00848591, 0.00979572,\n          0.00842392, 0.00960437, 0.00833012, 0.00584929, 0.00915666,\n          0.00497411, 0.00496033, 0.00252166, 0.00412237, 0.00472221,\n          0.01103836, 0.00739697, 0.00977663, 0.00343098, 0.02146608,\n          0.01758557, 0.00616294, 0.00632731, 0.01152523, 0.00302903,\n          0.00486574, 0.00393244, 0.00601687, 0.00782614, 0.00905738,\n          0.00628583, 0.00875095, 0.00645165, 0.00745343, 0.00798174,\n          0.01271659, 0.00591787, 0.00734263, 0.00969432, 0.0119409 ,\n          0.01058462, 0.00592435, 0.00749462, 0.00673471, 0.00382429,\n          0.02345842, 0.00724743, 0.00875385, 0.00957439, 0.03324192,\n          0.00743228, 0.02329031, 0.00404525, 0.0084362 , 0.00666291,\n          0.00788371, 0.00591462, 0.00515022, 0.01732809, 0.00602834,\n          0.00618281, 0.00453066, 0.00577782, 0.00525406, 0.00966155,\n          0.00585331, 0.00271274, 0.01098552, 0.00456324, 0.00511107,\n          0.00487493, 0.00720209, 0.01211656, 0.00780853, 0.00752512,\n          0.0065972 , 0.00922083, 0.00809803, 0.00518203, 0.00448817],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_project/Conv2D;mobilenetv2_1.00_224/block_14_project/Conv2D',\n  'index': 104,\n  'shape': array([160], dtype=int32),\n  'shape_signature': array([160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_depthwise/depthwise;mobilenetv2_1.00_224/block_16_depthwise/depthwise',\n  'index': 105,\n  'shape': array([  1,   3,   3, 960], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00686964, 0.00520222, 0.00467574, 0.004461  , 0.00295245,\n          0.0024334 , 0.00431185, 0.0072022 , 0.00264864, 0.03054606,\n          0.02389725, 0.01322974, 0.00657433, 0.00726969, 0.00108137,\n          0.00470422, 0.00337617, 0.00628558, 0.00310178, 0.00676044,\n          0.00157833, 0.00544604, 0.00764794, 0.00831755, 0.00257816,\n          0.0069041 , 0.0019167 , 0.01321119, 0.00238723, 0.00611032,\n          0.00398011, 0.00596745, 0.00244143, 0.00779675, 0.00287616,\n          0.00715895, 0.00796346, 0.00896818, 0.00761527, 0.00949258,\n          0.01535042, 0.00262155, 0.00140729, 0.00782013, 0.00926743,\n          0.00676532, 0.00606386, 0.00275308, 0.00445167, 0.00480312,\n          0.00411082, 0.00718852, 0.01028465, 0.00498705, 0.00311912,\n          0.0113771 , 0.00924967, 0.00863382, 0.00285306, 0.00260142,\n          0.00509493, 0.00337711, 0.00412522, 0.00638914, 0.00604139,\n          0.0046234 , 0.00443343, 0.00811338, 0.00303049, 0.03527417,\n          0.00888735, 0.00476542, 0.00462054, 0.00430253, 0.00688461,\n          0.00324865, 0.00314279, 0.00761584, 0.00672972, 0.00568548,\n          0.00240371, 0.00162184, 0.01051369, 0.00269752, 0.0056227 ,\n          0.01003925, 0.00504231, 0.01311098, 0.00569119, 0.00583092,\n          0.00579733, 0.00321191, 0.00627533, 0.01115132, 0.00538525,\n          0.00624922, 0.00157842, 0.00628088, 0.01436124, 0.00535177,\n          0.00456576, 0.00419491, 0.01094584, 0.00932927, 0.00156896,\n          0.00940476, 0.00453944, 0.00427367, 0.00769804, 0.00319035,\n          0.0022747 , 0.00555358, 0.0060727 , 0.00440939, 0.0036273 ,\n          0.00582924, 0.01041501, 0.00444812, 0.00585907, 0.00763212,\n          0.00672258, 0.00210934, 0.00259735, 0.00480751, 0.00251368,\n          0.00622772, 0.00641658, 0.00419608, 0.00686972, 0.00651338,\n          0.0070401 , 0.00539705, 0.01012906, 0.0035224 , 0.00711206,\n          0.00392481, 0.00448396, 0.00404261, 0.00257772, 0.0076961 ,\n          0.00652562, 0.00169536, 0.00810304, 0.01564203, 0.00937203,\n          0.00734837, 0.0026058 , 0.0087581 , 0.00413926, 0.01157514,\n          0.00735749, 0.00298305, 0.00748968, 0.00790598, 0.00440481,\n          0.00337187, 0.00501546, 0.00371437, 0.00660943, 0.00930913,\n          0.00733367, 0.02939125, 0.00319709, 0.00203221, 0.00976766,\n          0.00508597, 0.01199239, 0.00198673, 0.00271839, 0.01012291,\n          0.01019763, 0.00586744, 0.00469557, 0.00809961, 0.00329513,\n          0.01153582, 0.00827263, 0.00383613, 0.00533312, 0.00664988,\n          0.00548722, 0.004006  , 0.00776487, 0.02299074, 0.00646895,\n          0.00517589, 0.00728499, 0.00188359, 0.00916212, 0.00299957,\n          0.00493242, 0.00294966, 0.00325886, 0.00432237, 0.00594129,\n          0.00296783, 0.0075362 , 0.00215529, 0.00340834, 0.00561931,\n          0.01011309, 0.00290402, 0.00500137, 0.00800097, 0.0133289 ,\n          0.00899638, 0.00463712, 0.01260347, 0.00400646, 0.00250149,\n          0.00281605, 0.00441478, 0.00522502, 0.00898062, 0.01106422,\n          0.01027302, 0.02372624, 0.0046833 , 0.00871142, 0.0043365 ,\n          0.00598499, 0.00674055, 0.00452175, 0.00369761, 0.00083352,\n          0.00271535, 0.0035469 , 0.00348002, 0.00658318, 0.00494629,\n          0.01147151, 0.003466  , 0.01097481, 0.00393116, 0.00529088,\n          0.01148884, 0.00579949, 0.00437069, 0.00394502, 0.0067306 ,\n          0.00282043, 0.00735376, 0.00860355, 0.00233899, 0.01691115,\n          0.00776449, 0.00457235, 0.00422895, 0.01348954, 0.00719471,\n          0.01007198, 0.00375817, 0.00507576, 0.00582491, 0.00450058,\n          0.00539832, 0.00473937, 0.00450894, 0.00190463, 0.00295932,\n          0.00526242, 0.0073211 , 0.00453396, 0.00595029, 0.0083984 ,\n          0.0222271 , 0.05488002, 0.00556839, 0.00781753, 0.00590104,\n          0.00562093, 0.00398174, 0.0035012 , 0.00337213, 0.01638796,\n          0.00720304, 0.00459106, 0.00595737, 0.00354651, 0.00342383,\n          0.01080768, 0.00932997, 0.0039679 , 0.0045381 , 0.00202436,\n          0.00488433, 0.01041667, 0.0071616 , 0.00669628, 0.00441854,\n          0.00841336, 0.00498449, 0.00776904, 0.01120197, 0.01036401,\n          0.0023966 , 0.00583022, 0.02243487, 0.01218095, 0.00425788,\n          0.00311222, 0.00355447, 0.00314895, 0.00503961, 0.00841089,\n          0.00435239, 0.00102619, 0.00503504, 0.00454485, 0.01725265,\n          0.00387544, 0.00595046, 0.00901433, 0.00432994, 0.00337105,\n          0.00848275, 0.00722337, 0.0033535 , 0.00581004, 0.00378964,\n          0.0038524 , 0.00517842, 0.00599025, 0.02574758, 0.00629164,\n          0.00498991, 0.00293763, 0.01039585, 0.00310229, 0.005898  ,\n          0.00570931, 0.00405907, 0.00591788, 0.00479601, 0.00547328,\n          0.01086217, 0.00375705, 0.00135199, 0.00379675, 0.00264455,\n          0.0022513 , 0.00451991, 0.00924274, 0.00222717, 0.00766177,\n          0.00188774, 0.00920058, 0.00450962, 0.01310333, 0.00575614,\n          0.00280299, 0.00669418, 0.00523797, 0.00488394, 0.00654052,\n          0.00315234, 0.00596367, 0.00788896, 0.00663727, 0.00591966,\n          0.01023158, 0.00397085, 0.00481091, 0.00694226, 0.00775036,\n          0.00563813, 0.00616603, 0.03201733, 0.02394578, 0.00536698,\n          0.0090345 , 0.00651968, 0.00899439, 0.01921687, 0.01482425,\n          0.00543629, 0.00938182, 0.00350546, 0.00620447, 0.00431175,\n          0.00470221, 0.00270789, 0.00365835, 0.01594585, 0.00477953,\n          0.00251823, 0.0054416 , 0.00363842, 0.00662124, 0.00626326,\n          0.00696561, 0.00101588, 0.00734163, 0.01080769, 0.00547928,\n          0.00811883, 0.00633821, 0.00738484, 0.00732828, 0.00356284,\n          0.00375551, 0.00359242, 0.00324483, 0.00529912, 0.00365037,\n          0.00519229, 0.00715378, 0.00253908, 0.00671402, 0.00655401,\n          0.00570342, 0.0077051 , 0.01216464, 0.00158574, 0.00563385,\n          0.01009849, 0.00285369, 0.0129011 , 0.00397432, 0.00369643,\n          0.00597498, 0.00409294, 0.00489475, 0.00453485, 0.00591876,\n          0.00765401, 0.00732546, 0.00576016, 0.00232964, 0.00127267,\n          0.00513515, 0.0030225 , 0.00321329, 0.00804923, 0.01445379,\n          0.00493559, 0.00647264, 0.00756152, 0.00304449, 0.00526117,\n          0.00277812, 0.00826056, 0.00450416, 0.0127174 , 0.00933002,\n          0.00619096, 0.00829172, 0.00477607, 0.01124964, 0.00751893,\n          0.00928501, 0.0035624 , 0.01853038, 0.00729814, 0.0065994 ,\n          0.00836559, 0.00536139, 0.00505053, 0.00525076, 0.00201306,\n          0.00570576, 0.01039862, 0.01231123, 0.00564163, 0.00602889,\n          0.00787466, 0.0016141 , 0.01140105, 0.00766698, 0.00535752,\n          0.0066057 , 0.0129832 , 0.00529154, 0.00274978, 0.00785914,\n          0.00629157, 0.00558955, 0.00312519, 0.00498249, 0.0041696 ,\n          0.00245132, 0.00483301, 0.00621299, 0.00510725, 0.00303074,\n          0.00843045, 0.0053523 , 0.00432203, 0.01139261, 0.01197579,\n          0.00646643, 0.01143686, 0.0232413 , 0.00421157, 0.00380388,\n          0.00531424, 0.00299972, 0.00549734, 0.00744794, 0.01060955,\n          0.00805113, 0.00321783, 0.00344943, 0.00410059, 0.01252303,\n          0.00989036, 0.00264373, 0.01302613, 0.00808378, 0.00303264,\n          0.00340204, 0.00706882, 0.0073482 , 0.00236505, 0.00801316,\n          0.00368335, 0.00531361, 0.00633825, 0.00562153, 0.00736119,\n          0.00695326, 0.00320213, 0.00421443, 0.00475346, 0.00530818,\n          0.01723263, 0.00335514, 0.00758133, 0.00200977, 0.00625782,\n          0.00801058, 0.00503202, 0.00483351, 0.00729258, 0.00566607,\n          0.0081979 , 0.01277884, 0.00651449, 0.00595652, 0.00690722,\n          0.00802238, 0.0085304 , 0.0094947 , 0.00865635, 0.00791894,\n          0.00831398, 0.00472513, 0.00307735, 0.00339527, 0.01134196,\n          0.00295312, 0.00968756, 0.00679173, 0.00339135, 0.00407988,\n          0.00937241, 0.00977868, 0.00681384, 0.00614277, 0.00404838,\n          0.00457443, 0.00875452, 0.00848212, 0.01017893, 0.01070821,\n          0.00910739, 0.00661876, 0.01047905, 0.00298443, 0.0085898 ,\n          0.00375941, 0.00251819, 0.04833673, 0.00821681, 0.0122493 ,\n          0.0037237 , 0.00794334, 0.00269133, 0.00676073, 0.00424851,\n          0.00490973, 0.0061771 , 0.00633804, 0.00490424, 0.00775742,\n          0.00512434, 0.00558037, 0.00659104, 0.00399969, 0.00732989,\n          0.00278172, 0.00218632, 0.00310146, 0.01313469, 0.00375308,\n          0.00347616, 0.00423807, 0.00756104, 0.00381419, 0.00641585,\n          0.00579528, 0.00675122, 0.00129512, 0.00255553, 0.0051557 ,\n          0.00471342, 0.00438494, 0.00235336, 0.00468287, 0.0079016 ,\n          0.00546315, 0.00979718, 0.00372142, 0.00417346, 0.00743658,\n          0.00423367, 0.00626362, 0.01080362, 0.00723966, 0.00632884,\n          0.00865681, 0.00551183, 0.00749012, 0.00781385, 0.00649781,\n          0.00940494, 0.00354778, 0.00239746, 0.00272972, 0.00848161,\n          0.0049992 , 0.00576182, 0.01176637, 0.02633323, 0.00881349,\n          0.02792951, 0.00396107, 0.00659185, 0.00519412, 0.00367401,\n          0.00345966, 0.00554705, 0.03366683, 0.00408786, 0.00936536,\n          0.00792317, 0.00751492, 0.00757131, 0.00507392, 0.00752528,\n          0.03716313, 0.00348267, 0.00432027, 0.02427552, 0.00682147,\n          0.01150006, 0.00390341, 0.00620364, 0.00804845, 0.014799  ,\n          0.00502299, 0.00506219, 0.0042509 , 0.00476927, 0.00700898,\n          0.00239973, 0.00589463, 0.01084443, 0.01123325, 0.01278131,\n          0.00658388, 0.00793323, 0.0032601 , 0.00268272, 0.02039973,\n          0.00622623, 0.00259083, 0.00411513, 0.01240307, 0.01042879,\n          0.00930979, 0.0049823 , 0.00617666, 0.00619519, 0.00357471,\n          0.00364211, 0.02584476, 0.01098433, 0.00287048, 0.00819793,\n          0.00316558, 0.00106552, 0.00492343, 0.00287492, 0.00867994,\n          0.0027071 , 0.00269022, 0.00519135, 0.00162592, 0.00758127,\n          0.00312839, 0.00211621, 0.00395157, 0.00663592, 0.01449939,\n          0.02518612, 0.00306988, 0.02594973, 0.00336503, 0.0090069 ,\n          0.00441468, 0.01539177, 0.01286852, 0.00629553, 0.00935997,\n          0.0026363 , 0.00638798, 0.00582406, 0.02542441, 0.00669533,\n          0.00527221, 0.0086743 , 0.00850089, 0.00597527, 0.00727738,\n          0.00278332, 0.0103192 , 0.00437341, 0.00390054, 0.0037339 ,\n          0.0029693 , 0.00773695, 0.00355101, 0.00892717, 0.00436356,\n          0.00788194, 0.01315505, 0.00487535, 0.00984291, 0.01246973,\n          0.00969973, 0.00698216, 0.00325415, 0.0055058 , 0.00439852,\n          0.00108835, 0.00652102, 0.00222915, 0.00451537, 0.00387401,\n          0.00816406, 0.00336265, 0.00952949, 0.00865057, 0.0054874 ,\n          0.01059704, 0.00338647, 0.00339942, 0.00246357, 0.00225005,\n          0.00353708, 0.00467076, 0.00314743, 0.006798  , 0.00696087,\n          0.01229603, 0.0095971 , 0.00809387, 0.00333623, 0.00136456,\n          0.00860758, 0.01475359, 0.0047458 , 0.0051414 , 0.00560756,\n          0.03236942, 0.00871495, 0.0077082 , 0.00695038, 0.01070228,\n          0.00812677, 0.01277722, 0.00931033, 0.00419016, 0.00486439,\n          0.00483808, 0.01245453, 0.00865081, 0.00479866, 0.01017515,\n          0.00209383, 0.00475458, 0.01507623, 0.00397065, 0.00438864,\n          0.00585824, 0.00258825, 0.0091569 , 0.01070511, 0.00911356,\n          0.00462819, 0.00681143, 0.0130512 , 0.00406684, 0.0132869 ,\n          0.00201079, 0.00798434, 0.004555  , 0.00834396, 0.00962621,\n          0.03440376, 0.00519127, 0.00789146, 0.00668386, 0.01236994,\n          0.01029759, 0.00799274, 0.00509763, 0.00319942, 0.00278079,\n          0.00755753, 0.00309921, 0.0061578 , 0.02298408, 0.00561895,\n          0.0035002 , 0.02291919, 0.00460834, 0.00382933, 0.00533657,\n          0.00734568, 0.00523794, 0.03241895, 0.0064618 , 0.00901028,\n          0.00431482, 0.00628536, 0.00788962, 0.00457732, 0.00098359,\n          0.00797399, 0.00615088, 0.00161102, 0.00529863, 0.01653411,\n          0.00535703, 0.02130562, 0.00381069, 0.00355959, 0.00563925,\n          0.00476568, 0.00537709, 0.00186156, 0.00371298, 0.00292194,\n          0.00560226, 0.00796095, 0.00481115, 0.00745013, 0.00743145,\n          0.00489824, 0.01413373, 0.00887545, 0.01033271, 0.02708245,\n          0.00143143, 0.00772229, 0.0086867 , 0.00446816, 0.00472095,\n          0.00849087, 0.00094081, 0.00902196, 0.00370889, 0.01265573,\n          0.00303278, 0.01864067, 0.0080968 , 0.00601707, 0.00732075,\n          0.00529666, 0.00478902, 0.00215043, 0.00352202, 0.01437112,\n          0.0045385 , 0.00901298, 0.01033243, 0.00887452, 0.00556125,\n          0.00633359, 0.00468253, 0.00274741, 0.00380064, 0.02352038,\n          0.00476945, 0.00304351, 0.00790422, 0.00291248, 0.00904946,\n          0.00720653, 0.00657899, 0.00272575, 0.01343385, 0.00391439,\n          0.00218275, 0.00466652, 0.00508861, 0.00574206, 0.01422244,\n          0.00697048, 0.00327581, 0.00473837, 0.00652362, 0.00118714,\n          0.00788091, 0.00462433, 0.00892544, 0.00568175, 0.00529655,\n          0.00157511, 0.00434223, 0.00582582, 0.00458657, 0.00418625,\n          0.0090073 , 0.00964554, 0.00707643, 0.00238215, 0.00229065,\n          0.01027481, 0.00204501, 0.00338594, 0.00379681, 0.0031736 ,\n          0.00609835, 0.03301751, 0.00256409, 0.00321149, 0.00948697,\n          0.00275401, 0.00436856, 0.00313495, 0.00834464, 0.01836694,\n          0.00869374, 0.00297782, 0.0092526 , 0.00436096, 0.00629274,\n          0.00393788, 0.02331381, 0.0071514 , 0.00093807, 0.03342767,\n          0.00664179, 0.00581908, 0.02666011, 0.01134894, 0.00216301],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_project/Conv2D',\n  'index': 106,\n  'shape': array([160], dtype=int32),\n  'shape_signature': array([160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise',\n  'index': 107,\n  'shape': array([  1,   3,   3, 960], dtype=int32),\n  'shape_signature': array([  1,   3,   3, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([0.00794946, 0.0220081 , 0.00731044, 0.00381843, 0.00709322,\n          0.00216583, 0.01877736, 0.00503619, 0.01569164, 0.00405114,\n          0.00308433, 0.00632088, 0.0081884 , 0.00365479, 0.00738117,\n          0.01371084, 0.0121075 , 0.00397998, 0.00328923, 0.00510791,\n          0.00272202, 0.01352178, 0.00378204, 0.01211019, 0.00722295,\n          0.01299343, 0.00314169, 0.01770835, 0.00613376, 0.00499753,\n          0.01080447, 0.01106207, 0.00922827, 0.01559873, 0.01561492,\n          0.00380286, 0.0106909 , 0.00950373, 0.00537139, 0.01566214,\n          0.01690546, 0.03165817, 0.00379984, 0.01427832, 0.01041739,\n          0.00859969, 0.01983758, 0.00446334, 0.0029184 , 0.02260404,\n          0.02171779, 0.00832483, 0.00415149, 0.01222008, 0.00779696,\n          0.02278901, 0.00524211, 0.01558114, 0.00389339, 0.00717178,\n          0.00788392, 0.00498262, 0.0050517 , 0.00478951, 0.00649457,\n          0.01150593, 0.00311139, 0.00473316, 0.00533997, 0.00722126,\n          0.01967916, 0.00360807, 0.01870665, 0.00287591, 0.00351552,\n          0.00258047, 0.00910453, 0.00408471, 0.00396271, 0.01511446,\n          0.00772704, 0.00327831, 0.02035276, 0.00705354, 0.00586816,\n          0.00375985, 0.01528193, 0.00337618, 0.01229123, 0.00514228,\n          0.01253727, 0.00502479, 0.01229901, 0.00348441, 0.00419475,\n          0.00298664, 0.00479477, 0.00968858, 0.00707236, 0.01015235,\n          0.0096792 , 0.00512248, 0.00430391, 0.00296062, 0.00494344,\n          0.00578752, 0.02019139, 0.02353042, 0.00774832, 0.00628857,\n          0.01122334, 0.00358837, 0.01333173, 0.016047  , 0.00948017,\n          0.00537552, 0.00475673, 0.01156144, 0.00222238, 0.00832725,\n          0.00903509, 0.01184434, 0.01713644, 0.00441733, 0.00494315,\n          0.02896232, 0.00646208, 0.00498775, 0.00869549, 0.00463828,\n          0.00350832, 0.0071205 , 0.00511332, 0.00399455, 0.00550871,\n          0.00854983, 0.00243713, 0.01315057, 0.01558789, 0.01060148,\n          0.00497852, 0.00361388, 0.01551891, 0.0028415 , 0.00978998,\n          0.01190978, 0.00416404, 0.01359018, 0.00324003, 0.00763572,\n          0.00504467, 0.00362763, 0.00264592, 0.00640305, 0.00569864,\n          0.0175961 , 0.01101565, 0.01893719, 0.018324  , 0.00760255,\n          0.01394822, 0.00294347, 0.00576321, 0.0162337 , 0.00661003,\n          0.00852526, 0.01268547, 0.01575442, 0.00588283, 0.00671337,\n          0.03137337, 0.00835939, 0.01387859, 0.0062819 , 0.00467118,\n          0.015141  , 0.0033666 , 0.00440575, 0.00487246, 0.00671722,\n          0.00692311, 0.00473097, 0.00347823, 0.00941175, 0.00498062,\n          0.00593366, 0.01084222, 0.00391628, 0.00240386, 0.00582967,\n          0.01393215, 0.00554471, 0.00378352, 0.00482406, 0.00390631,\n          0.00703156, 0.00689219, 0.01435163, 0.01426346, 0.01182274,\n          0.02071338, 0.00363827, 0.01212459, 0.00884935, 0.00370352,\n          0.0123531 , 0.00722868, 0.00402733, 0.00977971, 0.00999547,\n          0.00478753, 0.02682745, 0.00456869, 0.01358611, 0.00577473,\n          0.00876589, 0.00746575, 0.00381695, 0.01556801, 0.00898877,\n          0.01351032, 0.00592424, 0.01183909, 0.01448377, 0.00489193,\n          0.00637878, 0.01392474, 0.009769  , 0.0038415 , 0.01564481,\n          0.01493211, 0.01604209, 0.00275346, 0.01046076, 0.01333656,\n          0.00346012, 0.00459978, 0.00544393, 0.01231075, 0.01514346,\n          0.00373844, 0.00497689, 0.00386008, 0.00295933, 0.01175712,\n          0.0017598 , 0.00767046, 0.00418696, 0.00530497, 0.01560805,\n          0.01716481, 0.00639329, 0.00388556, 0.00545286, 0.00397281,\n          0.00642168, 0.00335738, 0.00387795, 0.0209223 , 0.00420757,\n          0.00623651, 0.00924883, 0.00319595, 0.00291447, 0.01033352,\n          0.01411252, 0.00938019, 0.00388295, 0.00548139, 0.00485262,\n          0.00571837, 0.01370065, 0.00378078, 0.02371443, 0.00676271,\n          0.00519608, 0.0052481 , 0.00467671, 0.00492182, 0.01476506,\n          0.01128763, 0.01541447, 0.00576973, 0.0131759 , 0.01406366,\n          0.00869396, 0.01273122, 0.00904894, 0.00722628, 0.0073007 ,\n          0.0039361 , 0.00648094, 0.00499089, 0.00691684, 0.00757044,\n          0.01275309, 0.00907181, 0.00966474, 0.00316187, 0.0050774 ,\n          0.00291948, 0.00681409, 0.01088251, 0.00466217, 0.00721963,\n          0.01627626, 0.00399359, 0.00699902, 0.01403764, 0.00986255,\n          0.00316757, 0.00525912, 0.00448131, 0.00679825, 0.00811765,\n          0.00355185, 0.01854386, 0.00602794, 0.00504914, 0.00337099,\n          0.00342812, 0.01408401, 0.0040672 , 0.01196809, 0.00719868,\n          0.01623194, 0.01516373, 0.00362595, 0.00338729, 0.0152477 ,\n          0.00543939, 0.00975925, 0.00579047, 0.00275895, 0.00345153,\n          0.01904203, 0.00479934, 0.0166678 , 0.01929576, 0.00822408,\n          0.00480471, 0.01379491, 0.00596393, 0.00345695, 0.01048435,\n          0.01286667, 0.00504906, 0.01134576, 0.00524764, 0.01361298,\n          0.00405948, 0.00463392, 0.00696286, 0.01145388, 0.02305519,\n          0.01848377, 0.00434184, 0.00531958, 0.01365615, 0.00362918,\n          0.01152957, 0.0128557 , 0.01389796, 0.00307439, 0.00581113,\n          0.02661676, 0.00538406, 0.00486935, 0.00352506, 0.00413264,\n          0.00972078, 0.01330683, 0.01286829, 0.00570295, 0.01471631,\n          0.00419853, 0.00606818, 0.00975545, 0.00614413, 0.00968432,\n          0.00442143, 0.01106985, 0.00421813, 0.01044687, 0.00565266,\n          0.00552067, 0.00642569, 0.00302237, 0.00328546, 0.00569091,\n          0.00620781, 0.01312159, 0.0041489 , 0.00659884, 0.00975798,\n          0.01428299, 0.01004422, 0.00525465, 0.00551131, 0.00254538,\n          0.00264651, 0.00947473, 0.00528778, 0.00432696, 0.01432492,\n          0.00563718, 0.00502451, 0.00652075, 0.01339164, 0.01574064,\n          0.0066518 , 0.00232225, 0.02577587, 0.01418421, 0.008707  ,\n          0.00467176, 0.01074509, 0.01196527, 0.00815121, 0.0074435 ,\n          0.00667617, 0.00293332, 0.00481943, 0.00377346, 0.00400108,\n          0.01349472, 0.00734203, 0.01274986, 0.0029763 , 0.01156634,\n          0.01445251, 0.00750516, 0.00602071, 0.2490414 , 0.01667674,\n          0.00671867, 0.00384449, 0.016493  , 0.00559207, 0.00377553,\n          0.00253358, 0.00710714, 0.00634043, 0.0180075 , 0.01479332,\n          0.00450153, 0.00691359, 0.00597404, 0.0187295 , 0.00458087,\n          0.02376219, 0.00640165, 0.00370224, 0.00367832, 0.004435  ,\n          0.01508928, 0.01751777, 0.02041769, 0.00624088, 0.02391616,\n          0.00904007, 0.01122591, 0.00523775, 0.00284128, 0.01239718,\n          0.02560812, 0.0126449 , 0.01124575, 0.01564066, 0.00827186,\n          0.0130046 , 0.00543068, 0.00818132, 0.00625934, 0.01550705,\n          0.00437562, 0.00687481, 0.0118148 , 0.00512939, 0.01697108,\n          0.00416746, 0.00386626, 0.00417943, 0.00447028, 0.00690639,\n          0.00296593, 0.00477984, 0.01583491, 0.00509602, 0.0063743 ,\n          0.00500884, 0.01879591, 0.00419898, 0.00740632, 0.00588112,\n          0.00445375, 0.01043706, 0.00376898, 0.01792208, 0.00542478,\n          0.00378243, 0.00898998, 0.00515609, 0.00733798, 0.01671472,\n          0.01860531, 0.01243277, 0.00583275, 0.00707743, 0.00713138,\n          0.00422126, 0.00950097, 0.0111933 , 0.01020472, 0.00461876,\n          0.00579078, 0.02460194, 0.01027703, 0.0166227 , 0.01056338,\n          0.01243928, 0.00574714, 0.00607824, 0.02008689, 0.00606947,\n          0.0143062 , 0.00381081, 0.00546271, 0.01745687, 0.00415967,\n          0.00380803, 0.0164476 , 0.01996091, 0.01394307, 0.015535  ,\n          0.00279478, 0.00498983, 0.00376215, 0.00966734, 0.00426174,\n          0.0127242 , 0.01190317, 0.00620748, 0.00689491, 0.02061657,\n          0.01695055, 0.0029627 , 0.00296366, 0.02388295, 0.00459391,\n          0.00294343, 0.00645585, 0.00668575, 0.013063  , 0.00484144,\n          0.02729847, 0.01522931, 0.01213422, 0.00413946, 0.01442997,\n          0.02441897, 0.00594953, 0.01012349, 0.00547443, 0.02018724,\n          0.01358584, 0.00784436, 0.00307515, 0.01127641, 0.00792603,\n          0.0246017 , 0.00739597, 0.01248213, 0.00832304, 0.00347079,\n          0.00247626, 0.02564306, 0.00488816, 0.00494861, 0.00800545,\n          0.0063296 , 0.00410251, 0.00824512, 0.00346841, 0.00503908,\n          0.00440967, 0.0104942 , 0.0135734 , 0.00785535, 0.01445324,\n          0.01624033, 0.01543286, 0.01715986, 0.01824074, 0.00434042,\n          0.00440951, 0.01189514, 0.01021531, 0.00675828, 0.00550318,\n          0.01887996, 0.00495659, 0.00430932, 0.02214519, 0.00487391,\n          0.00531993, 0.0040076 , 0.00906666, 0.00761504, 0.00871485,\n          0.00271005, 0.01390314, 0.01247523, 0.0168415 , 0.0061117 ,\n          0.01293543, 0.01141015, 0.00588226, 0.00798049, 0.03590808,\n          0.0035941 , 0.00478551, 0.0053746 , 0.00465747, 0.00359002,\n          0.01174418, 0.00571312, 0.00370659, 0.00400246, 0.0066015 ,\n          0.00852949, 0.01270799, 0.0064063 , 0.00991922, 0.02058766,\n          0.00431391, 0.01115349, 0.00528435, 0.01358107, 0.1118613 ,\n          0.01694199, 0.0019745 , 0.0040525 , 0.01022164, 0.00400784,\n          0.0163053 , 0.00381007, 0.01287869, 0.01144587, 0.0092837 ,\n          0.00326214, 0.01306679, 0.00552701, 0.00792575, 0.00762048,\n          0.00390837, 0.01656354, 0.01450345, 0.00271186, 0.01658028,\n          0.02294329, 0.00256107, 0.02304098, 0.01347432, 0.00966611,\n          0.00517368, 0.00399637, 0.00601117, 0.00560789, 0.01460293,\n          0.00526093, 0.00594864, 0.01708032, 0.01897531, 0.01058103,\n          0.00597645, 0.00923978, 0.0182157 , 0.02470114, 0.0065296 ,\n          0.02304742, 0.00435817, 0.0050671 , 0.01351321, 0.0146192 ,\n          0.00592147, 0.00700749, 0.00342263, 0.00352666, 0.01506662,\n          0.00413958, 0.00995511, 0.00405998, 0.00492411, 0.01877563,\n          0.00276236, 0.00346257, 0.02518779, 0.00686509, 0.00600864,\n          0.00698995, 0.00384366, 0.00398816, 0.00353537, 0.00531552,\n          0.0121582 , 0.01369095, 0.00418698, 0.00575507, 0.00427977,\n          0.00359845, 0.00968045, 0.00364389, 0.00732968, 0.00424845,\n          0.00588011, 0.00486347, 0.00397714, 0.01828788, 0.01054743,\n          0.00995734, 0.02186557, 0.00699588, 0.01151541, 0.01309152,\n          0.01033598, 0.01874613, 0.01753601, 0.01580408, 0.00639794,\n          0.00889793, 0.01190739, 0.00942032, 0.00405935, 0.00642721,\n          0.00369941, 0.00667042, 0.01369426, 0.01142416, 0.00606594,\n          0.00451561, 0.00412706, 0.00671331, 0.00958822, 0.00348679,\n          0.00189453, 0.00619545, 0.01817217, 0.0220883 , 0.0092217 ,\n          0.00815461, 0.00280781, 0.02090275, 0.01322008, 0.01206448,\n          0.00360797, 0.01234027, 0.0058708 , 0.01518882, 0.00437634,\n          0.01919916, 0.00418975, 0.00455476, 0.01070188, 0.00745066,\n          0.01397536, 0.00897006, 0.00329307, 0.00521019, 0.01775351,\n          0.00923914, 0.00599201, 0.00723046, 0.00388261, 0.01569373,\n          0.00312406, 0.00322557, 0.00449917, 0.00794851, 0.00724083,\n          0.01292484, 0.01485231, 0.00530967, 0.00408314, 0.00463843,\n          0.00461452, 0.00648825, 0.00605347, 0.00909933, 0.0030595 ,\n          0.00477614, 0.0058286 , 0.00935062, 0.00539223, 0.00487315,\n          0.01137698, 0.00953681, 0.00470947, 0.00299145, 0.00715369,\n          0.00410842, 0.01797564, 0.01141007, 0.0081689 , 0.00618171,\n          0.01280705, 0.00602193, 0.01492493, 0.00789094, 0.00658566,\n          0.00853634, 0.00391331, 0.01319876, 0.0048561 , 0.0144051 ,\n          0.00370569, 0.00616693, 0.01199958, 0.0034657 , 0.01897673,\n          0.01112152, 0.00382998, 0.00595214, 0.00227622, 0.02139076,\n          0.01275209, 0.01447431, 0.02133865, 0.00698048, 0.00302404,\n          0.00337002, 0.00488533, 0.00443628, 0.01817638, 0.01502155,\n          0.0162853 , 0.00644081, 0.00412299, 0.00666807, 0.0067078 ,\n          0.01238379, 0.01193926, 0.00394305, 0.01622355, 0.00605915,\n          0.00245907, 0.00473676, 0.0181438 , 0.00486547, 0.00829271,\n          0.00610918, 0.00872288, 0.00428577, 0.00539424, 0.00441542,\n          0.00325012, 0.00503421, 0.00537907, 0.01340422, 0.00331203,\n          0.01441535, 0.01069211, 0.00438864, 0.00412757, 0.0046976 ,\n          0.03217259, 0.01202183, 0.00558014, 0.00333803, 0.01436207,\n          0.01550222, 0.01789876, 0.00953024, 0.01124407, 0.00750247,\n          0.00403996, 0.00465154, 0.02036167, 0.0058328 , 0.01090903,\n          0.01056467, 0.01019725, 0.00351931, 0.01272459, 0.01012088,\n          0.01849529, 0.00746901, 0.00693679, 0.00813645, 0.00671374,\n          0.01719194, 0.00640922, 0.0042005 , 0.00460074, 0.00615044,\n          0.0118286 , 0.00372568, 0.01186918, 0.00653483, 0.01623663,\n          0.00337486, 0.00501855, 0.01354231, 0.00378299, 0.00384803,\n          0.0138116 , 0.0059014 , 0.0045553 , 0.00298346, 0.01322041,\n          0.00591475, 0.01021457, 0.00495113, 0.00702973, 0.00445675,\n          0.01216366, 0.00448632, 0.01187606, 0.0105504 , 0.00359075,\n          0.00993834, 0.0033114 , 0.00831252, 0.01419537, 0.00243894,\n          0.00645638, 0.01643761, 0.00382801, 0.02257565, 0.00502576,\n          0.0075387 , 0.00260369, 0.0057748 , 0.0048005 , 0.00365853,\n          0.00515349, 0.00298892, 0.00362103, 0.00209869, 0.02254871,\n          0.00376929, 0.00628283, 0.01214451, 0.02018415, 0.00421625,\n          0.00556654, 0.00324785, 0.01228158, 0.00994455, 0.00723524,\n          0.01497418, 0.00517689, 0.00405797, 0.01357763, 0.0025317 ,\n          0.00476411, 0.00434637, 0.01433707, 0.01518977, 0.00504534],\n         dtype=float32),\n   'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n   'quantized_dimension': 3},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_project/Conv2D',\n  'index': 108,\n  'shape': array([320], dtype=int32),\n  'shape_signature': array([320], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/Conv1_relu/Relu6;mobilenetv2_1.00_224/bn_Conv1/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D;mobilenetv2_1.00_224/Conv1/Conv2D',\n  'index': 109,\n  'shape': array([  1, 112, 112,  32], dtype=int32),\n  'shape_signature': array([ -1, 112, 112,  32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/expanded_conv_depthwise_relu/Relu6;mobilenetv2_1.00_224/expanded_conv_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_depthwise/depthwise;mobilenetv2_1.00_224/block_5_project/Conv2D',\n  'index': 110,\n  'shape': array([  1, 112, 112,  32], dtype=int32),\n  'shape_signature': array([ -1, 112, 112,  32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/expanded_conv_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/expanded_conv_project/Conv2D1',\n  'index': 111,\n  'shape': array([  1, 112, 112,  16], dtype=int32),\n  'shape_signature': array([ -1, 112, 112,  16], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_expand_relu/Relu6;mobilenetv2_1.00_224/block_1_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_depthwise/depthwise;mobilenetv2_1.00_224/block_12_project/Conv2D;mobilenetv2_1.00_224/block_1_expand/Conv2D',\n  'index': 112,\n  'shape': array([  1, 112, 112,  96], dtype=int32),\n  'shape_signature': array([ -1, 112, 112,  96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_pad/Pad',\n  'index': 113,\n  'shape': array([  1, 113, 113,  96], dtype=int32),\n  'shape_signature': array([ -1, 113, 113,  96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_1_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_1_depthwise/depthwise;mobilenetv2_1.00_224/block_12_project/Conv2D',\n  'index': 114,\n  'shape': array([ 1, 56, 56, 96], dtype=int32),\n  'shape_signature': array([-1, 56, 56, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_1_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_project/Conv2D;mobilenetv2_1.00_224/block_1_project/Conv2D1',\n  'index': 115,\n  'shape': array([ 1, 56, 56, 24], dtype=int32),\n  'shape_signature': array([-1, 56, 56, 24], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_expand_relu/Relu6;mobilenetv2_1.00_224/block_2_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise/depthwise;mobilenetv2_1.00_224/block_2_expand/Conv2D',\n  'index': 116,\n  'shape': array([  1,  56,  56, 144], dtype=int32),\n  'shape_signature': array([ -1,  56,  56, 144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_2_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise/depthwise;mobilenetv2_1.00_224/block_2_depthwise/depthwise',\n  'index': 117,\n  'shape': array([  1,  56,  56, 144], dtype=int32),\n  'shape_signature': array([ -1,  56,  56, 144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_2_project/Conv2D1',\n  'index': 118,\n  'shape': array([ 1, 56, 56, 24], dtype=int32),\n  'shape_signature': array([-1, 56, 56, 24], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_2_add/add',\n  'index': 119,\n  'shape': array([ 1, 56, 56, 24], dtype=int32),\n  'shape_signature': array([-1, 56, 56, 24], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_expand_relu/Relu6;mobilenetv2_1.00_224/block_3_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise/depthwise;mobilenetv2_1.00_224/block_3_expand/Conv2D',\n  'index': 120,\n  'shape': array([  1,  56,  56, 144], dtype=int32),\n  'shape_signature': array([ -1,  56,  56, 144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_pad/Pad',\n  'index': 121,\n  'shape': array([  1,  57,  57, 144], dtype=int32),\n  'shape_signature': array([ -1,  57,  57, 144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_3_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_3_depthwise/depthwise',\n  'index': 122,\n  'shape': array([  1,  28,  28, 144], dtype=int32),\n  'shape_signature': array([ -1,  28,  28, 144], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_3_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D;mobilenetv2_1.00_224/block_3_project/Conv2D1',\n  'index': 123,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([-1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_expand_relu/Relu6;mobilenetv2_1.00_224/block_4_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise;mobilenetv2_1.00_224/block_4_expand/Conv2D',\n  'index': 124,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([ -1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_4_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise;mobilenetv2_1.00_224/block_4_depthwise/depthwise',\n  'index': 125,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([ -1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D;mobilenetv2_1.00_224/block_4_project/Conv2D1',\n  'index': 126,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([-1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_4_add/add',\n  'index': 127,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([-1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_expand_relu/Relu6;mobilenetv2_1.00_224/block_5_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise;mobilenetv2_1.00_224/block_5_expand/Conv2D',\n  'index': 128,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([ -1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_5_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise;mobilenetv2_1.00_224/block_5_depthwise/depthwise',\n  'index': 129,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([ -1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_5_project/Conv2D1',\n  'index': 130,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([-1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_5_add/add',\n  'index': 131,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([-1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_expand_relu/Relu6;mobilenetv2_1.00_224/block_6_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise;mobilenetv2_1.00_224/block_6_expand/Conv2D',\n  'index': 132,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([ -1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_pad/Pad',\n  'index': 133,\n  'shape': array([  1,  29,  29, 192], dtype=int32),\n  'shape_signature': array([ -1,  29,  29, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_6_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_6_depthwise/depthwise',\n  'index': 134,\n  'shape': array([  1,  14,  14, 192], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 192], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_6_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D;mobilenetv2_1.00_224/block_6_project/Conv2D1',\n  'index': 135,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_expand_relu/Relu6;mobilenetv2_1.00_224/block_7_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_7_expand/Conv2D',\n  'index': 136,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_7_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_7_depthwise/depthwise',\n  'index': 137,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D;mobilenetv2_1.00_224/block_7_project/Conv2D1',\n  'index': 138,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_7_add/add',\n  'index': 139,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_expand_relu/Relu6;mobilenetv2_1.00_224/block_8_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_8_expand/Conv2D',\n  'index': 140,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_8_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_8_depthwise/depthwise',\n  'index': 141,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D;mobilenetv2_1.00_224/block_8_project/Conv2D1',\n  'index': 142,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_8_add/add',\n  'index': 143,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_expand_relu/Relu6;mobilenetv2_1.00_224/block_9_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_9_expand/Conv2D',\n  'index': 144,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_9_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_9_depthwise/depthwise',\n  'index': 145,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_9_project/Conv2D1',\n  'index': 146,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_9_add/add',\n  'index': 147,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_expand_relu/Relu6;mobilenetv2_1.00_224/block_10_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise;mobilenetv2_1.00_224/block_10_expand/Conv2D',\n  'index': 148,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_10_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_10_depthwise/depthwise',\n  'index': 149,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_10_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_project/Conv2D;mobilenetv2_1.00_224/block_10_project/Conv2D1',\n  'index': 150,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_expand_relu/Relu6;mobilenetv2_1.00_224/block_11_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise;mobilenetv2_1.00_224/block_11_expand/Conv2D',\n  'index': 151,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_11_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise;mobilenetv2_1.00_224/block_11_depthwise/depthwise',\n  'index': 152,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_project/Conv2D;mobilenetv2_1.00_224/block_11_project/Conv2D1',\n  'index': 153,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_11_add/add',\n  'index': 154,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_expand_relu/Relu6;mobilenetv2_1.00_224/block_12_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise;mobilenetv2_1.00_224/block_12_expand/Conv2D',\n  'index': 155,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_12_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise;mobilenetv2_1.00_224/block_12_depthwise/depthwise',\n  'index': 156,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_12_project/Conv2D1',\n  'index': 157,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_12_add/add',\n  'index': 158,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([-1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_expand_relu/Relu6;mobilenetv2_1.00_224/block_13_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise;mobilenetv2_1.00_224/block_13_expand/Conv2D',\n  'index': 159,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([ -1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_pad/Pad',\n  'index': 160,\n  'shape': array([  1,  15,  15, 576], dtype=int32),\n  'shape_signature': array([ -1,  15,  15, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_13_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_13_depthwise/depthwise',\n  'index': 161,\n  'shape': array([  1,   7,   7, 576], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 576], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_13_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_project/Conv2D;mobilenetv2_1.00_224/block_13_project/Conv2D1',\n  'index': 162,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_expand_relu/Relu6;mobilenetv2_1.00_224/block_14_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise;mobilenetv2_1.00_224/block_14_expand/Conv2D',\n  'index': 163,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_14_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise;mobilenetv2_1.00_224/block_14_depthwise/depthwise',\n  'index': 164,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_project/Conv2D;mobilenetv2_1.00_224/block_14_project/Conv2D1',\n  'index': 165,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_14_add/add',\n  'index': 166,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_expand_relu/Relu6;mobilenetv2_1.00_224/block_15_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise;mobilenetv2_1.00_224/block_15_expand/Conv2D',\n  'index': 167,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_15_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise;mobilenetv2_1.00_224/block_15_depthwise/depthwise',\n  'index': 168,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_15_project/Conv2D1',\n  'index': 169,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_15_add/add',\n  'index': 170,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_expand_relu/Relu6;mobilenetv2_1.00_224/block_16_expand_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise;mobilenetv2_1.00_224/block_16_expand/Conv2D',\n  'index': 171,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_depthwise_relu/Relu6;mobilenetv2_1.00_224/block_16_depthwise_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_depthwise/depthwise',\n  'index': 172,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/block_16_project_BN/FusedBatchNormV3;mobilenetv2_1.00_224/block_16_project/Conv2D1',\n  'index': 173,\n  'shape': array([  1,   7,   7, 320], dtype=int32),\n  'shape_signature': array([ -1,   7,   7, 320], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/out_relu/Relu6;mobilenetv2_1.00_224/Conv_1_bn/FusedBatchNormV3;mobilenetv2_1.00_224/Conv_1/Conv2D',\n  'index': 174,\n  'shape': array([   1,    7,    7, 1280], dtype=int32),\n  'shape_signature': array([  -1,    7,    7, 1280], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/global_average_pooling2d/Mean',\n  'index': 175,\n  'shape': array([   1, 1280], dtype=int32),\n  'shape_signature': array([  -1, 1280], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'mobilenetv2_1.00_224/predictions/MatMul;mobilenetv2_1.00_224/predictions/BiasAdd',\n  'index': 176,\n  'shape': array([   1, 1000], dtype=int32),\n  'shape_signature': array([  -1, 1000], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': 'Identity',\n  'index': 177,\n  'shape': array([   1, 1000], dtype=int32),\n  'shape_signature': array([  -1, 1000], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 178,\n  'shape': array([4], dtype=int32),\n  'shape_signature': array([4], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 179,\n  'shape': array([2], dtype=int32),\n  'shape_signature': array([2], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 180,\n  'shape': array([1280], dtype=int32),\n  'shape_signature': array([1280], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 181,\n  'shape': array([   1, 1280], dtype=int32),\n  'shape_signature': array([   1, 1280], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 182,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 183,\n  'shape': array([1000,    1], dtype=int32),\n  'shape_signature': array([1000,    1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 184,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 185,\n  'shape': array([1000], dtype=int32),\n  'shape_signature': array([1000], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 186,\n  'shape': array([27, 32], dtype=int32),\n  'shape_signature': array([27, 32], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 187,\n  'shape': array([32, 16], dtype=int32),\n  'shape_signature': array([32, 16], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 188,\n  'shape': array([  1, 112, 112,  16], dtype=int32),\n  'shape_signature': array([  1, 112, 112,  16], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 189,\n  'shape': array([12544], dtype=int32),\n  'shape_signature': array([12544], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 190,\n  'shape': array([   96, 12544], dtype=int32),\n  'shape_signature': array([   96, 12544], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 191,\n  'shape': array([12544], dtype=int32),\n  'shape_signature': array([12544], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 192,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 193,\n  'shape': array([ 1, 56, 56, 96], dtype=int32),\n  'shape_signature': array([ 1, 56, 56, 96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 194,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 195,\n  'shape': array([  24, 3136], dtype=int32),\n  'shape_signature': array([  24, 3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 196,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 197,\n  'shape': array([24], dtype=int32),\n  'shape_signature': array([24], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 198,\n  'shape': array([ 1, 56, 56, 24], dtype=int32),\n  'shape_signature': array([ 1, 56, 56, 24], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 199,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 200,\n  'shape': array([ 144, 3136], dtype=int32),\n  'shape_signature': array([ 144, 3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 201,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 202,\n  'shape': array([144], dtype=int32),\n  'shape_signature': array([144], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 203,\n  'shape': array([  1,  56,  56, 144], dtype=int32),\n  'shape_signature': array([  1,  56,  56, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 204,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 205,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 206,\n  'shape': array([  1,  56,  56, 144], dtype=int32),\n  'shape_signature': array([  1,  56,  56, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 207,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 208,\n  'shape': array([  24, 3136], dtype=int32),\n  'shape_signature': array([  24, 3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 209,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 210,\n  'shape': array([24], dtype=int32),\n  'shape_signature': array([24], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 211,\n  'shape': array([ 1, 56, 56, 24], dtype=int32),\n  'shape_signature': array([ 1, 56, 56, 24], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 212,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 213,\n  'shape': array([ 144, 3136], dtype=int32),\n  'shape_signature': array([ 144, 3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 214,\n  'shape': array([3136], dtype=int32),\n  'shape_signature': array([3136], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 215,\n  'shape': array([144], dtype=int32),\n  'shape_signature': array([144], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 216,\n  'shape': array([  1,  57,  57, 144], dtype=int32),\n  'shape_signature': array([  1,  57,  57, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 217,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 218,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 219,\n  'shape': array([  1,  28,  28, 144], dtype=int32),\n  'shape_signature': array([  1,  28,  28, 144], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 220,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 221,\n  'shape': array([ 32, 784], dtype=int32),\n  'shape_signature': array([ 32, 784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 222,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 223,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 224,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([ 1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 225,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 226,\n  'shape': array([192, 784], dtype=int32),\n  'shape_signature': array([192, 784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 227,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 228,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 229,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([  1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 230,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 231,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 232,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([  1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 233,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 234,\n  'shape': array([ 32, 784], dtype=int32),\n  'shape_signature': array([ 32, 784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 235,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 236,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 237,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([ 1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 238,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 239,\n  'shape': array([192, 784], dtype=int32),\n  'shape_signature': array([192, 784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 240,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 241,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 242,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([  1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 243,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 244,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 245,\n  'shape': array([  1,  28,  28, 192], dtype=int32),\n  'shape_signature': array([  1,  28,  28, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 246,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 247,\n  'shape': array([ 32, 784], dtype=int32),\n  'shape_signature': array([ 32, 784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 248,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 249,\n  'shape': array([32], dtype=int32),\n  'shape_signature': array([32], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 250,\n  'shape': array([ 1, 28, 28, 32], dtype=int32),\n  'shape_signature': array([ 1, 28, 28, 32], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 251,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 252,\n  'shape': array([192, 784], dtype=int32),\n  'shape_signature': array([192, 784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 253,\n  'shape': array([784], dtype=int32),\n  'shape_signature': array([784], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 254,\n  'shape': array([192], dtype=int32),\n  'shape_signature': array([192], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 255,\n  'shape': array([  1,  29,  29, 192], dtype=int32),\n  'shape_signature': array([  1,  29,  29, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 256,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 257,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 258,\n  'shape': array([  1,  14,  14, 192], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 192], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 259,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 260,\n  'shape': array([ 64, 196], dtype=int32),\n  'shape_signature': array([ 64, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 261,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 262,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 263,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 264,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 265,\n  'shape': array([384, 196], dtype=int32),\n  'shape_signature': array([384, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 266,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 267,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 268,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 269,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 270,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 271,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 272,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 273,\n  'shape': array([ 64, 196], dtype=int32),\n  'shape_signature': array([ 64, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 274,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 275,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 276,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 277,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 278,\n  'shape': array([384, 196], dtype=int32),\n  'shape_signature': array([384, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 279,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 280,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 281,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 282,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 283,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 284,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 285,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 286,\n  'shape': array([ 64, 196], dtype=int32),\n  'shape_signature': array([ 64, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 287,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 288,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 289,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 290,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 291,\n  'shape': array([384, 196], dtype=int32),\n  'shape_signature': array([384, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 292,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 293,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 294,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 295,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 296,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 297,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 298,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 299,\n  'shape': array([ 64, 196], dtype=int32),\n  'shape_signature': array([ 64, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 300,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 301,\n  'shape': array([64], dtype=int32),\n  'shape_signature': array([64], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 302,\n  'shape': array([ 1, 14, 14, 64], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 64], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 303,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 304,\n  'shape': array([384, 196], dtype=int32),\n  'shape_signature': array([384, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 305,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 306,\n  'shape': array([384], dtype=int32),\n  'shape_signature': array([384], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 307,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 308,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 309,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 310,\n  'shape': array([  1,  14,  14, 384], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 384], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 311,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 312,\n  'shape': array([ 96, 196], dtype=int32),\n  'shape_signature': array([ 96, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 313,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 314,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 315,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 316,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 317,\n  'shape': array([576, 196], dtype=int32),\n  'shape_signature': array([576, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 318,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 319,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 320,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 321,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 322,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 323,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 324,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 325,\n  'shape': array([ 96, 196], dtype=int32),\n  'shape_signature': array([ 96, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 326,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 327,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 328,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 329,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 330,\n  'shape': array([576, 196], dtype=int32),\n  'shape_signature': array([576, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 331,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 332,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 333,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 334,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 335,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 336,\n  'shape': array([  1,  14,  14, 576], dtype=int32),\n  'shape_signature': array([  1,  14,  14, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 337,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 338,\n  'shape': array([ 96, 196], dtype=int32),\n  'shape_signature': array([ 96, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 339,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 340,\n  'shape': array([96], dtype=int32),\n  'shape_signature': array([96], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 341,\n  'shape': array([ 1, 14, 14, 96], dtype=int32),\n  'shape_signature': array([ 1, 14, 14, 96], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 342,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 343,\n  'shape': array([576, 196], dtype=int32),\n  'shape_signature': array([576, 196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 344,\n  'shape': array([196], dtype=int32),\n  'shape_signature': array([196], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 345,\n  'shape': array([576], dtype=int32),\n  'shape_signature': array([576], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 346,\n  'shape': array([  1,  15,  15, 576], dtype=int32),\n  'shape_signature': array([  1,  15,  15, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 347,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 348,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 349,\n  'shape': array([  1,   7,   7, 576], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 576], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 350,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 351,\n  'shape': array([160,  49], dtype=int32),\n  'shape_signature': array([160,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 352,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 353,\n  'shape': array([160], dtype=int32),\n  'shape_signature': array([160], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 354,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 355,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 356,\n  'shape': array([960,  49], dtype=int32),\n  'shape_signature': array([960,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 357,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 358,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 359,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 360,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 361,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 362,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 363,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 364,\n  'shape': array([160,  49], dtype=int32),\n  'shape_signature': array([160,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 365,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 366,\n  'shape': array([160], dtype=int32),\n  'shape_signature': array([160], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 367,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 368,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 369,\n  'shape': array([960,  49], dtype=int32),\n  'shape_signature': array([960,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 370,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 371,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 372,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 373,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 374,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 375,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 376,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 377,\n  'shape': array([160,  49], dtype=int32),\n  'shape_signature': array([160,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 378,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 379,\n  'shape': array([160], dtype=int32),\n  'shape_signature': array([160], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 380,\n  'shape': array([  1,   7,   7, 160], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 160], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 381,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 382,\n  'shape': array([960,  49], dtype=int32),\n  'shape_signature': array([960,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 383,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 384,\n  'shape': array([960], dtype=int32),\n  'shape_signature': array([960], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 385,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 386,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 387,\n  'shape': array([1], dtype=int32),\n  'shape_signature': array([1], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 388,\n  'shape': array([  1,   7,   7, 960], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 960], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 389,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 390,\n  'shape': array([320,  49], dtype=int32),\n  'shape_signature': array([320,  49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 391,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 392,\n  'shape': array([320], dtype=int32),\n  'shape_signature': array([320], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 393,\n  'shape': array([  1,   7,   7, 320], dtype=int32),\n  'shape_signature': array([  1,   7,   7, 320], dtype=int32),\n  'dtype': numpy.int8,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 394,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.float32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 395,\n  'shape': array([1280,   49], dtype=int32),\n  'shape_signature': array([1280,   49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 396,\n  'shape': array([49], dtype=int32),\n  'shape_signature': array([49], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}},\n {'name': '',\n  'index': 397,\n  'shape': array([1280], dtype=int32),\n  'shape_signature': array([1280], dtype=int32),\n  'dtype': numpy.int32,\n  'quantization': (0.0, 0),\n  'quantization_parameters': {'scales': array([], dtype=float32),\n   'zero_points': array([], dtype=int32),\n   'quantized_dimension': 0},\n  'sparsity_parameters': {}}]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter =  tf.lite.Interpreter(model_content=quant)\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.get_input_details()\n",
    "interpreter.get_tensor_details()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "seq = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}